{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc99e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches as mpatches\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import scipy.stats as st\n",
    "\n",
    "from analysis_utils import metric_analysis\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "# display multiple outputs within a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\";\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7553eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.regression.mixed_linear_model as smr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "from statsmodels.stats.multitest import fdrcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee45d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cde13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with patient data\n",
    "clinical_file=r'C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hgcn\\data\\MEG\\MEG.clinical.csv'\n",
    "clinical_df = pd.read_csv(clinical_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0c6b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def digest_stat_df(stat_df,stat_type):\n",
    "    \"\"\"\n",
    "    function will get all of the cluster stats of each type\n",
    "    stat_df- a data frame with a row for each scan and columns for the embedding stats\n",
    "    stat_type- rad,coh,or btw\n",
    "    \"\"\"\n",
    "    # function to get the columns related to\n",
    "    cols_to_use=[c for c in stat_df.columns if stat_type.lower() in c.lower()]\n",
    "    return np.array(stat_df[cols_to_use]),cols_to_use\n",
    "\n",
    "def slice_metric_df(stat_df_full,label_col,conditionals):\n",
    "    \"\"\"\n",
    "    this function will do a statistical analysis based on embedding statistics vs the values in label_col\n",
    "            and will plot the results \n",
    "    \n",
    "    stat_df_full- a dataframe with all of the patient data, as well as columns for all of\n",
    "                the cluster rad,cohesion, btw cluster data\n",
    "    label_col-what metric will we consider to be our label? (diagnosis, CogTr, Pre/Post)\n",
    "    conditionals-a true/false array of what data to include\n",
    "    \"\"\"\n",
    "    conditional_df=stat_df_full[conditionals]\n",
    "    scan_labels = conditional_df[label_col].values\n",
    "    # subtracts 1 from columns that are labeled 1,2 (diagnosis, CogTr)\n",
    "    if min(scan_labels)>0:\n",
    "        scan_labels=scan_labels-1  \n",
    "        \n",
    "    if label_col in ('diagnosis','diagnosis_inv'):\n",
    "        group_labels = ['Healthy Control', 'SCD']\n",
    "    if label_col == 'CogTr':\n",
    "        # group_labels=['Control','CogTr']\n",
    "        group_labels=['CogTr','Control']\n",
    "    if label_col == 'Pre':\n",
    "        group_labels=['Post','Pre']\n",
    "        \n",
    "        \n",
    "    rc,rc_labels=digest_stat_df(conditional_df,stat_type='rad')\n",
    "    wc,wc_labels=digest_stat_df(conditional_df,stat_type='coh')\n",
    "    bc,bc_labels=digest_stat_df(conditional_df,stat_type='btw')\n",
    "    \n",
    "    metric_analysis(wc,wc_labels,scan_labels,column_name=['Cluster Cohesion'],\n",
    "                    graph_label_names=group_labels,sort_vals=True,max_plot=8)\n",
    "    print('rad')\n",
    "    metric_analysis(rc,rc_labels, scan_labels,column_name=['Cluster Radius from Origin'],\n",
    "                    plot_title='',graph_label_names=group_labels,sort_vals=True,max_plot=8)\n",
    "    print('btw clust')\n",
    "    metric_analysis(bc,bc_labels,scan_labels,column_name=['Dist Btw Clusters'],\n",
    "                    plot_title='',graph_label_names=group_labels,sort_vals=True,max_plot=6)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7f6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diagnosis_label(row):\n",
    "    \"\"\"\n",
    "    this will create a unique label for each diagnosis/cogtr combo\n",
    "    \"\"\"\n",
    "    if row['diagnosis']==1:\n",
    "        if row['CogTr']==1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if row['CogTr']==1:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b673a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_analysis(stat_df_full,stat_type,dist_or_prob='dist',use_difference=False,package='smf'):\n",
    "    \"\"\"\n",
    "    stat_df_full- a data frame with all patient information and associciated embedding cluster stats in each row\n",
    "    stat_type=- 'rad','coh','btw' what kind of stat are we looking at\n",
    "    dist_or_prob- for each of those stats, \n",
    "        should we look at the hyperbolic or the hyperbolic connectivity probability'dist' or 'prob'\n",
    "    use_difference- if True, we look at the difference between Post-Pre. Otherwise, we look at the mixed model\n",
    "    package- what package of analysis should we use (smf or pg). Only smf can do mixed nova w/ >1 between variable\n",
    "        \n",
    "    Here is where I need help.\n",
    "    I have been trying to emulate the analysis from the paper doing mixed ANOVA models\n",
    "    I wanted to avoid this kind of analysis, but now it seems like the right place to go instead of trying to manufacture\n",
    "    results with different slices of the data.\n",
    "    \n",
    "    Mixed model is related to a repeated measure ANOVA but adds in analysis of between groups as well as within subject\n",
    "    https://www.datanovia.com/en/lessons/mixed-anova-in-r/ (here is a primer on mixed effects anova)\n",
    "    \n",
    "    Here's what they say in the paper:\n",
    "    \"We performed a mixed-effects ANOVA with two between-subjects factors, \n",
    "        (i) cognitive status (i.e., HC or SCD) and\n",
    "        (ii) CogTr (i.e., trained or non-trained),and \n",
    "        one within-subject factor (i) stage (i.e., pre-stage or post-stage) indicating the time point of the MEG recording\n",
    "    We tested the main effects of all three factors and every second- and third-order interaction\n",
    "        (stage × CogTr, stage × cognitive status, CogTr × cognitive status, stage × CogTr × cognitive status).\n",
    "        \n",
    "        \n",
    "    Here are my problems:\n",
    "    1. \n",
    "     I'm having problems doing a proper mixed effects analysis.\n",
    "        There are two packages with the options:\n",
    "            statsmodel-https://www.statsmodels.org/dev/generated/statsmodels.formula.api.mixedlm.html\n",
    "            pingouin-https://pingouin-stats.org/generated/pingouin.mixed_anova.html\n",
    "            \n",
    "        pingouin will only accept a single between group variable (CogTr OR diagnosis),\n",
    "             which seems to be very significant for us.\n",
    "\n",
    "        statsmodel accepts 2 group variables, but does not give values for the interaction \n",
    "            between the within variable (time) and the between group variables. it only looks at interactions \n",
    "            between the between group variable and uses a fixed effect for the group\n",
    "\n",
    "        there must be an easy solution, but I can't find it on python. our collaborators do their analysis in matlab, \n",
    "          which I could do with some guidance if any of y'all have experience\n",
    "\n",
    "\n",
    "    2.\n",
    "      Results- In general, there is a strong interaction effect between diagnosis and cognitive score\n",
    "              and even some primary effects of diagnosis. It doesn't really match up with our collaborators' paper\n",
    "                  which described heavy changes between pre->post.\n",
    "                I don't understand how to make these into a story.\n",
    "                \n",
    "    3. Checking my work- there are all sorts of assumptions to make sure ANOVAs are valid. I want to make sure that I'm\n",
    "        doing clean work, but I'm out of my depth.\n",
    "        \n",
    "    4. With all that said about the \"Mixed Anova\", I did a standard anova with the value being the difference between pre and\n",
    "        post scan. This loses some information, but is similar to what I've done in the past. There are significances\n",
    "        for FPN,VAN and DAN in the interaction between CogTr and Diagnosis. Hopefully we can find a compelling story.\n",
    "        . Maybe this is the right way to go. (you can do this by adding \"use_difference\" in anova_analysis)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    # TODO go back and check the chain of command for every fucking individual.\n",
    "    # make sure you know every step of getting their data to your plate.\n",
    "    assert stat_type in ('rad','coh','btw')\n",
    "    assert dist_or_prob in ('dist','prob')\n",
    "    rad_str = 'radprob' if dist_or_prob=='prob' else 'rad'\n",
    "    coh_str = 'cohprob' if dist_or_prob=='prob' else 'coh'\n",
    "    dist_str = 'distprob' if dist_or_prob=='prob' else 'dist'\n",
    "#     conditionals=((stat_df_full['Pre']==1)) ## this would only analyze the pretraining scans\n",
    "    conditionals=((stat_df_full['CogTr']<20))\n",
    "    stat_df_full=stat_df_full[conditionals]\n",
    "    patient_cols = ['ID','diagnosis','CogTr','Pre']\n",
    "    rad_cols = [c for c in stat_df_full.columns if 'rad' in c.lower()]\n",
    "    coh_cols = [c for c in stat_df_full.columns if 'coh' in c.lower()]\n",
    "    bc_cols = [c for c in stat_df_full.columns if 'btw' in c.lower()]\n",
    "    \n",
    "    type_to_cols={'rad':rad_cols , 'coh':coh_cols, 'btw':bc_cols}\n",
    "    cols=type_to_cols[stat_type]\n",
    "    if dist_or_prob=='prob':\n",
    "        cols=[c for c in cols if 'prob' in c.lower()]\n",
    "    else:\n",
    "        cols=[c for c in cols if 'prob' not in c.lower()]\n",
    "    first=True\n",
    "    # this defines what package we will use\n",
    "    if (use_difference) and package=='smf':\n",
    "        print('\\\"use difference\\\" not implemented with package smf yet')\n",
    "        print('switching to package pg')\n",
    "        package='pg'\n",
    "    \n",
    "    stat_df_full=stat_df_full.sort_values('Scan Index')\n",
    "    pre_df=stat_df_full[stat_df_full['Pre']==1].sort_values('Scan Index')\n",
    "    post_df=stat_df_full[stat_df_full['Pre']==0].sort_values('Scan Index')\n",
    "    \n",
    "    # make sure cols isn't empty\n",
    "    assert cols\n",
    "    for c in cols:\n",
    "        print(c)\n",
    "        if use_difference:\n",
    "            c_use=c+'_dif'\n",
    "            post_df[c_use]=post_df[c]-pre_df[c]\n",
    "#             stat_df_full=post_df\n",
    "        else:\n",
    "            stat_df_full[c]=stat_df_full[c].astype(float)\n",
    "            stat_df_full=stat_df_full\n",
    "            c_use=c\n",
    "        if package=='smf':\n",
    "            assert not use_difference  ### should only use smf if we are doing mixed anova\n",
    "            #here I added a age as\n",
    "            # to check and make sure we weren't taking any of the influence from the uneven distribution of age\n",
    "            # we end up with the same  error corrected q values-- there we're many more corrections, \n",
    "#                 but the p values were even lower\n",
    "            # suggesting the analysis is robust (i think)\n",
    "            #additionally, the age itself becomes significant... which could tell a new story\n",
    "            \n",
    "            \n",
    "#            Here the C(x) tells the model that it is a categorial variable\n",
    "#             res = smf.mixedlm(c+\"~ C(diagnosis)*C(CogTr)\", stat_df_full, groups=stat_df_full[\"ID\"]).fit()\n",
    "#             sjsjsj\n",
    "#             smf.lm\n",
    "#             res = smf.mixedlm(c+\"~ C(diagnosis)\", stat_df_full, groups=stat_df_full[\"ID\"]).fit()\n",
    "            res = smf.ols(c+\"~ C(diagnosis)\", data=stat_df_full).fit()\n",
    "            print(stat_df_full[stat_df_full['diagnosis']==2][c].mean(),'SCD MEAN')\n",
    "            print(stat_df_full[stat_df_full['diagnosis']==1][c].mean(),'HC MEAN')\n",
    "            \n",
    "            print(stat_df_full[stat_df_full['CogTr']==1][c].mean(),'Training MEAN')\n",
    "            print(stat_df_full[stat_df_full['CogTr']==2][c].mean(),'NO TRAINING MEAN')\n",
    "#             res = smf.mixedlm(c+\"~ C(CogTr)\", stat_df, groups=stat_df[\"ID\"]).fit()\n",
    "            # formatting table, eliminates rows row *intercept and *group value which do not have p values\n",
    "            print(res.summary())\n",
    "            res=res.summary().tables[1][1:-1] # eliminates rows w/o pvalues\n",
    "            res=pd.DataFrame(res)  \n",
    "            print(res,'res')\n",
    "            try:\n",
    "                res['p-unc']=res['P>|z|'].astype(float)\n",
    "            except:\n",
    "                res['p-unc']=res['P>|t|'].astype(float)\n",
    "            \n",
    "\n",
    "            \n",
    "        else:\n",
    "            # pg.mixed anova does not support analyzing multiple between columns\n",
    "            #however, it does give you a p-value for the interaction terms related to the within group\n",
    "            \n",
    "            print(stat_df_full[stat_df_full['diagnosis']==2][c].mean(),'SCD MEAN')\n",
    "            print(stat_df_full[stat_df_full['diagnosis']==1][c].mean(),'HC MEAN')\n",
    "            print(stat_df_full[stat_df_full['CogTr']==1][c].mean(),'Training MEAN')\n",
    "            print(stat_df_full[stat_df_full['CogTr']==2][c].mean(),'NO TRAINING MEAN')\n",
    "            print(stat_df_full[stat_df_full['Pre']==0][c].mean(),'AFTER MEAN')\n",
    "            print(stat_df_full[stat_df_full['Pre']==1][c].mean(),'BEFORE MEAN')\n",
    "            \n",
    "            if use_difference:\n",
    "                print('use difference in pg')\n",
    "                res = pg.anova(dv=c, between=['diagnosis'], data=stat_df)\n",
    "#                 res = pg.anova(dv=c, between=['diagnosis'], data=stat_df_full)\n",
    "#                 res = pg.rm_anova(dv=c, within=['Pre'],subject='ID', data=stat_df_full,detailed=True)[:-1]\n",
    "#                 print(res,'RESULUTE')\n",
    "        \n",
    "#         res = pg.rm_anova(dv='num_leaves', within=['time', 'year'], subject='plants', \n",
    "#                   data=df, detailed=True)\n",
    "        \n",
    "    \n",
    "            else:\n",
    "                res = pg.mixed_anova(dv=c, between='diagnosis',within='Pre',subject='ID', data=stat_df_full,correction=True)\n",
    "#                 res = pg.mixed_anova(dv=c, between='CogTr',within='Pre',subject='ID', data=stat_df_full)\n",
    "                ## this is what we would like to be able to do, but only takes one between term\n",
    "#                 res = pg.mixed_anova(dv=c, between=['diagnosis','CogTr'],within='Pre',subject='ID', data=stat_df)\n",
    "            print(res)\n",
    "#             sds\n",
    "\n",
    "\n",
    "        res['metric']=c\n",
    "\n",
    "#         print(res)\n",
    "        if first:\n",
    "            combined_results=res\n",
    "            first=False\n",
    "        else:\n",
    "            combined_results=pd.concat([combined_results,res],axis=0)\n",
    "\n",
    "    print(combined_results,'COMBINED RESULTS')\n",
    "    fdr=fdrcorrection(pvals=combined_results['p-unc'].values,alpha=.05)    \n",
    "    combined_results['Q Sig']=fdr[0]\n",
    "    combined_results['Q Val']=fdr[1]\n",
    "\n",
    "    return combined_results\n",
    "#     print(fdrcorrection(pvals=combined_results['p-unc'].values,alpha=.05))\n",
    "#     print(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b1e4e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_anova(stat_df_full,stat_type,label,dist_or_prob='dist',anova_type='anova'):\n",
    "    \"\"\"\n",
    "    anova- (anova,rm,mixed)\n",
    "    label- )'diagnosis', 'CogTr')\n",
    "    \"\"\"\n",
    "\n",
    "    assert stat_type in ('rad','coh','btw')\n",
    "    assert dist_or_prob in ('dist','prob')\n",
    "    if type(label)==list and anova_type=='mixed':\n",
    "        raise Exception('CANNOT DO MIXED ANOVA with more than one between effect in pg package')\n",
    "    rad_str = 'radprob' if dist_or_prob=='prob' else 'rad'\n",
    "    coh_str = 'cohprob' if dist_or_prob=='prob' else 'coh'\n",
    "    dist_str = 'distprob' if dist_or_prob=='prob' else 'dist'\n",
    "#     conditionals=((stat_df_full['Pre']==1)) ## this would only analyze the pretraining scans\n",
    "    conditionals=((stat_df_full['CogTr']<20))\n",
    "    stat_df_full=stat_df_full[conditionals]\n",
    "    patient_cols = ['ID','diagnosis','CogTr','Pre']\n",
    "    rad_cols = [c for c in stat_df_full.columns if 'rad' in c.lower()]\n",
    "    coh_cols = [c for c in stat_df_full.columns if 'coh' in c.lower()]\n",
    "    bc_cols = [c for c in stat_df_full.columns if 'btw' in c.lower()]\n",
    "    \n",
    "    type_to_cols={'rad':rad_cols , 'coh':coh_cols, 'btw':bc_cols}\n",
    "    cols=type_to_cols[stat_type]\n",
    "    if dist_or_prob=='prob':\n",
    "        cols=[c for c in cols if 'prob' in c.lower()]\n",
    "    else:\n",
    "        cols=[c for c in cols if 'prob' not in c.lower()]\n",
    "    first=True\n",
    "    # this defines what package we will use\n",
    "\n",
    "    stat_df_full=stat_df_full.sort_values('Scan Index')\n",
    "\n",
    "    for c in cols:\n",
    "        if anova_type=='anova':\n",
    "            if type(label)==list:\n",
    "                res = pg.anova(dv=c, between=label, data=stat_df_full)\n",
    "                res=res[:-1]\n",
    "            else:\n",
    "                res = pg.anova(dv=c, between=[label], data=stat_df_full)\n",
    "            \n",
    "        elif anova_type=='rm':\n",
    "            res = pg.rm_anova(dv=c, within=['Pre'], subject='ID', data=stat_df_full, detailed=True)[:1]\n",
    "        elif anova_type=='mixed':\n",
    "            res = pg.mixed_anova(dv=c, between=label,within='Pre',subject='ID', data=stat_df_full)\n",
    "        else:\n",
    "            raise Exception('anova type must be anova rm or mixed not {}'.format(anova_tye))\n",
    "        \n",
    "        res['metric']=c\n",
    "\n",
    "        if first:\n",
    "            combined_results=res\n",
    "            first=False\n",
    "        else:\n",
    "            combined_results=pd.concat([combined_results,res],axis=0)\n",
    "\n",
    "    print(combined_results,'COMBINED RESULTS')\n",
    "    fdr=fdrcorrection(pvals=combined_results['p-unc'].values,alpha=.05)    \n",
    "    combined_results['Q Sig']=fdr[0]\n",
    "    combined_results['Q Val']=fdr[1]\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ef034673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mixed_anova(data,split_labels,time_labels,ids):\n",
    "def mixed_anova(data,split_labels,clinical_df):\n",
    "    df = pd.DataFrame(data)\n",
    "    stat_columns=df.columns\n",
    "    df['label']=split_labels\n",
    "    df['time_labels']=clinical_df['Pre']\n",
    "    df['ID']=clinical_df['ID']\n",
    "    \n",
    "    print(df)\n",
    "    first=True\n",
    "    for c in stat_columns:\n",
    "        print(c,'C')\n",
    "        res = pg.mixed_anova(dv=c, between='label',within='time_labels',subject='ID', data=df)\n",
    "        res['metric']=c\n",
    "        if first:\n",
    "            combined_results=res\n",
    "            first=False\n",
    "        else:\n",
    "            combined_results=pd.concat([combined_results,res],axis=0)\n",
    "    \n",
    "    fdr=fdrcorrection(pvals=combined_results['p-unc'].values,alpha=.05)    \n",
    "    combined_results['Q Sig']=fdr[0]\n",
    "    combined_results['Q Val']=fdr[1]\n",
    "    \n",
    "    label_only=combined_results[combined_results['Source']=='label']\n",
    "\n",
    "    return label_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "068fac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df=pd.read_csv(os.path.join(os.getcwd(),'embedding_stats_avg5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0e4f34f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if clinical_df is not None and len(stat_df_use['ID'].unique())*2<=len(stat_df_use['ID']):\n",
    "    repeated=True\n",
    "else:\n",
    "    repeated=False\n",
    "repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d6e4d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6  \\\n",
      "0   0.695409  0.476373  0.457375  0.518196  0.683547  0.488161  0.635774   \n",
      "1   0.693673  0.485168  0.448937  0.478577  0.653848  0.477987  0.628902   \n",
      "2   0.674865  0.503121  0.489607  0.521319  0.661555  0.524615  0.654986   \n",
      "3   0.707007  0.512073  0.394902  0.492551  0.646397  0.478060  0.685068   \n",
      "4   0.701885  0.540213  0.549953  0.535716  0.689908  0.550854  0.670898   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "87  0.654021  0.513796  0.498532  0.533503  0.720123  0.476602  0.602962   \n",
      "88  0.690217  0.607102  0.610435  0.594593  0.651247  0.594111  0.694050   \n",
      "89  0.710229  0.632334  0.601329  0.602869  0.667757  0.609225  0.698211   \n",
      "90  0.697216  0.534120  0.574257  0.574912  0.698601  0.549484  0.655954   \n",
      "91  0.733224  0.547590  0.584119  0.571188  0.683851  0.586361  0.696303   \n",
      "\n",
      "           7  label  time_labels        ID  \n",
      "0   0.438276      1            1  UMEC-002  \n",
      "1   0.420001      1            0  UMEC-002  \n",
      "2   0.503046      1            1  UMEC-020  \n",
      "3   0.451104      1            0  UMEC-020  \n",
      "4   0.521582      1            1  UMEC-022  \n",
      "..       ...    ...          ...       ...  \n",
      "87  0.499093      2            0  UMEC-206  \n",
      "88  0.609314      2            1  UMEC-217  \n",
      "89  0.616721      2            0  UMEC-217  \n",
      "90  0.537752      2            1  UMEC-219  \n",
      "91  0.584876      2            0  UMEC-219  \n",
      "\n",
      "[92 rows x 11 columns]\n",
      "0 C\n",
      "1 C\n",
      "2 C\n",
      "3 C\n",
      "4 C\n",
      "5 C\n",
      "6 C\n",
      "7 C\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF1</th>\n",
       "      <th>DF2</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>np2</th>\n",
       "      <th>eps</th>\n",
       "      <th>metric</th>\n",
       "      <th>Q Sig</th>\n",
       "      <th>Q Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.559735</td>\n",
       "      <td>0.458347</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.785738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.903431</td>\n",
       "      <td>0.347055</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>10.499876</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.192659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>9.571804</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.178672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.081754</td>\n",
       "      <td>0.776277</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.931532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>8.753782</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.165937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>1.036162</td>\n",
       "      <td>0.314281</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>4.988532</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.101831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.147113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source        SS  DF1  DF2        MS          F     p-unc       np2  eps  \\\n",
       "0  label  0.000438    1   44  0.000438   0.559735  0.458347  0.012561  NaN   \n",
       "0  label  0.004244    1   44  0.004244   0.903431  0.347055  0.020119  NaN   \n",
       "0  label  0.031606    1   44  0.031606  10.499876  0.002277  0.192659  NaN   \n",
       "0  label  0.010797    1   44  0.010797   9.571804  0.003428  0.178672  NaN   \n",
       "0  label  0.000079    1   44  0.000079   0.081754  0.776277  0.001855  NaN   \n",
       "0  label  0.014317    1   44  0.014317   8.753782  0.004958  0.165937  NaN   \n",
       "0  label  0.002112    1   44  0.002112   1.036162  0.314281  0.023007  NaN   \n",
       "0  label  0.020581    1   44  0.020581   4.988532  0.030649  0.101831  NaN   \n",
       "\n",
       "   metric  Q Sig     Q Val  \n",
       "0       0  False  0.785738  \n",
       "0       1  False  0.750015  \n",
       "0       2   True  0.039662  \n",
       "0       3   True  0.039662  \n",
       "0       4  False  0.931532  \n",
       "0       5   True  0.039662  \n",
       "0       6  False  0.750015  \n",
       "0       7  False  0.147113  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we just need to add all of this to embedding utils\n",
    "# and MAKE SURE THAT CLINICAL DATA MAKES IT IN MATCHED UP!!!!\n",
    "stat_df_use=stat_df[stat_df['CogTr']==1]\n",
    "data=stat_df_use[[c for c in stat_df.columns if 'radprob' in c.lower()]]\n",
    "# time_labels=stat_df['Pre'] c.lower()]]\n",
    "labels=stat_df['diagnosis']\n",
    "data=np.array(data)\n",
    "combined_results=mixed_anova(data,labels,stat_df)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6529d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra columns\n",
    "stat_df['age_stand']=(stat_df['age']-stat_df['age'].mean())*stat_df['age'].std()\n",
    "stat_df['diag_train']=stat_df.apply(lambda row: train_diagnosis_label(row),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8ddf3c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Source        SS   DF        MS          F     p-unc       np2  \\\n",
      "0          diagnosis  0.017510  1.0  0.017510   0.871768  0.353080  0.010035   \n",
      "1              CogTr  0.001127  1.0  0.001127   0.056106  0.813324  0.000652   \n",
      "2  diagnosis * CogTr  0.048910  1.0  0.048910   2.435065  0.122322  0.027535   \n",
      "0          diagnosis  0.156366  1.0  0.156366   2.056406  0.155193  0.023353   \n",
      "1              CogTr  0.114383  1.0  0.114383   1.504277  0.223362  0.017191   \n",
      "2  diagnosis * CogTr  0.294847  1.0  0.294847   3.877603  0.052154  0.043143   \n",
      "0          diagnosis  0.046926  1.0  0.046926   1.156310  0.285240  0.013267   \n",
      "1              CogTr  0.015212  1.0  0.015212   0.374847  0.541989  0.004340   \n",
      "2  diagnosis * CogTr  0.589326  1.0  0.589326  14.521791  0.000260  0.144464   \n",
      "0          diagnosis  0.000199  1.0  0.000199   0.015699  0.900583  0.000183   \n",
      "1              CogTr  0.001179  1.0  0.001179   0.092864  0.761303  0.001079   \n",
      "2  diagnosis * CogTr  0.197104  1.0  0.197104  15.529028  0.000165  0.152952   \n",
      "0          diagnosis  0.053897  1.0  0.053897   2.282971  0.134467  0.025860   \n",
      "1              CogTr  0.024079  1.0  0.024079   1.019913  0.315373  0.011720   \n",
      "2  diagnosis * CogTr  0.006835  1.0  0.006835   0.289513  0.591922  0.003355   \n",
      "0          diagnosis  0.010240  1.0  0.010240   0.426895  0.515260  0.004939   \n",
      "1              CogTr  0.001829  1.0  0.001829   0.076238  0.783125  0.000886   \n",
      "2  diagnosis * CogTr  0.277957  1.0  0.277957  11.587382  0.001011  0.118739   \n",
      "0          diagnosis  0.012718  1.0  0.012718   0.324595  0.570345  0.003760   \n",
      "1              CogTr  0.014094  1.0  0.014094   0.359724  0.550237  0.004165   \n",
      "2  diagnosis * CogTr  0.152331  1.0  0.152331   3.888008  0.051846  0.043254   \n",
      "0          diagnosis  0.011565  1.0  0.011565   0.171708  0.679630  0.001993   \n",
      "1              CogTr  0.029740  1.0  0.029740   0.441565  0.508146  0.005108   \n",
      "2  diagnosis * CogTr  0.471141  1.0  0.471141   6.995268  0.009714  0.075222   \n",
      "\n",
      "     metric  \n",
      "0  pDMN_Rad  \n",
      "1  pDMN_Rad  \n",
      "2  pDMN_Rad  \n",
      "0  aDMN_Rad  \n",
      "1  aDMN_Rad  \n",
      "2  aDMN_Rad  \n",
      "0   DAN_Rad  \n",
      "1   DAN_Rad  \n",
      "2   DAN_Rad  \n",
      "0   FPN_Rad  \n",
      "1   FPN_Rad  \n",
      "2   FPN_Rad  \n",
      "0    VN_Rad  \n",
      "1    VN_Rad  \n",
      "2    VN_Rad  \n",
      "0   VAN_Rad  \n",
      "1   VAN_Rad  \n",
      "2   VAN_Rad  \n",
      "0    SN_Rad  \n",
      "1    SN_Rad  \n",
      "2    SN_Rad  \n",
      "0   SMN_Rad  \n",
      "1   SMN_Rad  \n",
      "2   SMN_Rad   COMBINED RESULTS\n",
      "significant results only\n",
      "              Source        SS   DF        MS          F     p-unc       np2  \\\n",
      "0          diagnosis  0.017510  1.0  0.017510   0.871768  0.353080  0.010035   \n",
      "1              CogTr  0.001127  1.0  0.001127   0.056106  0.813324  0.000652   \n",
      "2  diagnosis * CogTr  0.048910  1.0  0.048910   2.435065  0.122322  0.027535   \n",
      "0          diagnosis  0.156366  1.0  0.156366   2.056406  0.155193  0.023353   \n",
      "1              CogTr  0.114383  1.0  0.114383   1.504277  0.223362  0.017191   \n",
      "2  diagnosis * CogTr  0.294847  1.0  0.294847   3.877603  0.052154  0.043143   \n",
      "0          diagnosis  0.046926  1.0  0.046926   1.156310  0.285240  0.013267   \n",
      "1              CogTr  0.015212  1.0  0.015212   0.374847  0.541989  0.004340   \n",
      "2  diagnosis * CogTr  0.589326  1.0  0.589326  14.521791  0.000260  0.144464   \n",
      "0          diagnosis  0.000199  1.0  0.000199   0.015699  0.900583  0.000183   \n",
      "1              CogTr  0.001179  1.0  0.001179   0.092864  0.761303  0.001079   \n",
      "2  diagnosis * CogTr  0.197104  1.0  0.197104  15.529028  0.000165  0.152952   \n",
      "0          diagnosis  0.053897  1.0  0.053897   2.282971  0.134467  0.025860   \n",
      "1              CogTr  0.024079  1.0  0.024079   1.019913  0.315373  0.011720   \n",
      "2  diagnosis * CogTr  0.006835  1.0  0.006835   0.289513  0.591922  0.003355   \n",
      "0          diagnosis  0.010240  1.0  0.010240   0.426895  0.515260  0.004939   \n",
      "1              CogTr  0.001829  1.0  0.001829   0.076238  0.783125  0.000886   \n",
      "2  diagnosis * CogTr  0.277957  1.0  0.277957  11.587382  0.001011  0.118739   \n",
      "0          diagnosis  0.012718  1.0  0.012718   0.324595  0.570345  0.003760   \n",
      "1              CogTr  0.014094  1.0  0.014094   0.359724  0.550237  0.004165   \n",
      "2  diagnosis * CogTr  0.152331  1.0  0.152331   3.888008  0.051846  0.043254   \n",
      "0          diagnosis  0.011565  1.0  0.011565   0.171708  0.679630  0.001993   \n",
      "1              CogTr  0.029740  1.0  0.029740   0.441565  0.508146  0.005108   \n",
      "2  diagnosis * CogTr  0.471141  1.0  0.471141   6.995268  0.009714  0.075222   \n",
      "\n",
      "     metric  Q Sig     Q Val  \n",
      "0  pDMN_Rad  False  0.651841  \n",
      "1  pDMN_Rad  False  0.848686  \n",
      "2  pDMN_Rad  False  0.403401  \n",
      "0  aDMN_Rad  False  0.413849  \n",
      "1  aDMN_Rad  False  0.536069  \n",
      "2  aDMN_Rad  False  0.208616  \n",
      "0   DAN_Rad  False  0.622341  \n",
      "1   DAN_Rad  False  0.747691  \n",
      "2   DAN_Rad   True  0.003115  \n",
      "0   FPN_Rad  False  0.900583  \n",
      "1   FPN_Rad  False  0.848686  \n",
      "2   FPN_Rad   True  0.003115  \n",
      "0    VN_Rad  False  0.403401  \n",
      "1    VN_Rad  False  0.630746  \n",
      "2    VN_Rad  False  0.747691  \n",
      "0   VAN_Rad  False  0.747691  \n",
      "1   VAN_Rad  False  0.848686  \n",
      "2   VAN_Rad   True  0.008084  \n",
      "0    SN_Rad  False  0.747691  \n",
      "1    SN_Rad  False  0.747691  \n",
      "2    SN_Rad  False  0.208616  \n",
      "0   SMN_Rad  False  0.815556  \n",
      "1   SMN_Rad  False  0.747691  \n",
      "2   SMN_Rad  False  0.058285  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>np2</th>\n",
       "      <th>metric</th>\n",
       "      <th>Q Sig</th>\n",
       "      <th>Q Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>0.871768</td>\n",
       "      <td>0.353080</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>pDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.651841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.813324</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>pDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.848686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.048910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048910</td>\n",
       "      <td>2.435065</td>\n",
       "      <td>0.122322</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>pDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.156366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156366</td>\n",
       "      <td>2.056406</td>\n",
       "      <td>0.155193</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>aDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.413849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.114383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114383</td>\n",
       "      <td>1.504277</td>\n",
       "      <td>0.223362</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>aDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.536069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.294847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294847</td>\n",
       "      <td>3.877603</td>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>aDMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.208616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.046926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046926</td>\n",
       "      <td>1.156310</td>\n",
       "      <td>0.285240</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>DAN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.622341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>0.374847</td>\n",
       "      <td>0.541989</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>DAN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.589326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589326</td>\n",
       "      <td>14.521791</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.144464</td>\n",
       "      <td>DAN_Rad</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>0.900583</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>FPN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.092864</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>FPN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.848686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.197104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197104</td>\n",
       "      <td>15.529028</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.152952</td>\n",
       "      <td>FPN_Rad</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>2.282971</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>VN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>1.019913</td>\n",
       "      <td>0.315373</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>VN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.630746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.289513</td>\n",
       "      <td>0.591922</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>VN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010240</td>\n",
       "      <td>0.426895</td>\n",
       "      <td>0.515260</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>VAN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.076238</td>\n",
       "      <td>0.783125</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>VAN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.848686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.277957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277957</td>\n",
       "      <td>11.587382</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.118739</td>\n",
       "      <td>VAN_Rad</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012718</td>\n",
       "      <td>0.324595</td>\n",
       "      <td>0.570345</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>SN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>0.359724</td>\n",
       "      <td>0.550237</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>SN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.152331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152331</td>\n",
       "      <td>3.888008</td>\n",
       "      <td>0.051846</td>\n",
       "      <td>0.043254</td>\n",
       "      <td>SN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.208616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.171708</td>\n",
       "      <td>0.679630</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>SMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.815556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CogTr</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.441565</td>\n",
       "      <td>0.508146</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>SMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.747691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>0.471141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471141</td>\n",
       "      <td>6.995268</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.075222</td>\n",
       "      <td>SMN_Rad</td>\n",
       "      <td>False</td>\n",
       "      <td>0.058285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Source        SS   DF        MS          F     p-unc       np2  \\\n",
       "0          diagnosis  0.017510  1.0  0.017510   0.871768  0.353080  0.010035   \n",
       "1              CogTr  0.001127  1.0  0.001127   0.056106  0.813324  0.000652   \n",
       "2  diagnosis * CogTr  0.048910  1.0  0.048910   2.435065  0.122322  0.027535   \n",
       "0          diagnosis  0.156366  1.0  0.156366   2.056406  0.155193  0.023353   \n",
       "1              CogTr  0.114383  1.0  0.114383   1.504277  0.223362  0.017191   \n",
       "2  diagnosis * CogTr  0.294847  1.0  0.294847   3.877603  0.052154  0.043143   \n",
       "0          diagnosis  0.046926  1.0  0.046926   1.156310  0.285240  0.013267   \n",
       "1              CogTr  0.015212  1.0  0.015212   0.374847  0.541989  0.004340   \n",
       "2  diagnosis * CogTr  0.589326  1.0  0.589326  14.521791  0.000260  0.144464   \n",
       "0          diagnosis  0.000199  1.0  0.000199   0.015699  0.900583  0.000183   \n",
       "1              CogTr  0.001179  1.0  0.001179   0.092864  0.761303  0.001079   \n",
       "2  diagnosis * CogTr  0.197104  1.0  0.197104  15.529028  0.000165  0.152952   \n",
       "0          diagnosis  0.053897  1.0  0.053897   2.282971  0.134467  0.025860   \n",
       "1              CogTr  0.024079  1.0  0.024079   1.019913  0.315373  0.011720   \n",
       "2  diagnosis * CogTr  0.006835  1.0  0.006835   0.289513  0.591922  0.003355   \n",
       "0          diagnosis  0.010240  1.0  0.010240   0.426895  0.515260  0.004939   \n",
       "1              CogTr  0.001829  1.0  0.001829   0.076238  0.783125  0.000886   \n",
       "2  diagnosis * CogTr  0.277957  1.0  0.277957  11.587382  0.001011  0.118739   \n",
       "0          diagnosis  0.012718  1.0  0.012718   0.324595  0.570345  0.003760   \n",
       "1              CogTr  0.014094  1.0  0.014094   0.359724  0.550237  0.004165   \n",
       "2  diagnosis * CogTr  0.152331  1.0  0.152331   3.888008  0.051846  0.043254   \n",
       "0          diagnosis  0.011565  1.0  0.011565   0.171708  0.679630  0.001993   \n",
       "1              CogTr  0.029740  1.0  0.029740   0.441565  0.508146  0.005108   \n",
       "2  diagnosis * CogTr  0.471141  1.0  0.471141   6.995268  0.009714  0.075222   \n",
       "\n",
       "     metric  Q Sig     Q Val  \n",
       "0  pDMN_Rad  False  0.651841  \n",
       "1  pDMN_Rad  False  0.848686  \n",
       "2  pDMN_Rad  False  0.403401  \n",
       "0  aDMN_Rad  False  0.413849  \n",
       "1  aDMN_Rad  False  0.536069  \n",
       "2  aDMN_Rad  False  0.208616  \n",
       "0   DAN_Rad  False  0.622341  \n",
       "1   DAN_Rad  False  0.747691  \n",
       "2   DAN_Rad   True  0.003115  \n",
       "0   FPN_Rad  False  0.900583  \n",
       "1   FPN_Rad  False  0.848686  \n",
       "2   FPN_Rad   True  0.003115  \n",
       "0    VN_Rad  False  0.403401  \n",
       "1    VN_Rad  False  0.630746  \n",
       "2    VN_Rad  False  0.747691  \n",
       "0   VAN_Rad  False  0.747691  \n",
       "1   VAN_Rad  False  0.848686  \n",
       "2   VAN_Rad   True  0.008084  \n",
       "0    SN_Rad  False  0.747691  \n",
       "1    SN_Rad  False  0.747691  \n",
       "2    SN_Rad  False  0.208616  \n",
       "0   SMN_Rad  False  0.815556  \n",
       "1   SMN_Rad  False  0.747691  \n",
       "2   SMN_Rad  False  0.058285  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>metric</th>\n",
       "      <th>P Val</th>\n",
       "      <th>Q Sig</th>\n",
       "      <th>Q Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>DAN_Rad</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>FPN_Rad</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis * CogTr</td>\n",
       "      <td>VAN_Rad</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Source   metric     P Val  Q Sig     Q Val\n",
       "2  diagnosis * CogTr  DAN_Rad  0.000260   True  0.003115\n",
       "2  diagnosis * CogTr  FPN_Rad  0.000165   True  0.003115\n",
       "2  diagnosis * CogTr  VAN_Rad  0.001011   True  0.008084"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mixed anova with Pre indicator as within group variable\n",
    "# stat_df_use=stat_df[stat_df['CogTr']==1]\n",
    "# stat_df_use=stat_df[((stat_df['Pre']==1) & (stat_df['CogTr']==1))]\n",
    "# stat_df_use=stat_df[( (stat_df['CogTr']==1 ))]\n",
    "# stat_df_use=stat_df[((stat_df['diagnosis']==1))]\n",
    "stat_df_use=stat_df[((stat_df['Pre']==0))]\n",
    "# stat_df_use=stat_df\n",
    "# results=anova_analysis(stat_df_use,stat_type='rad',dist_or_prob='dist',use_difference=True,package='pg')\n",
    "# results=simple_anova(stat_df_use,stat_type='rad',label='diagnosis',dist_or_prob='prob',anova_type='mixed')\n",
    "results=simple_anova(stat_df_use,stat_type='rad',label=['diagnosis','CogTr'],dist_or_prob='dist',anova_type='anova')\n",
    "# results=simple_anova(stat_df_use,stat_type='rad',label=['diagnosis'],dist_or_prob='dist',anova_type='anova')\n",
    "\n",
    "print('significant results only')\n",
    "print(results)\n",
    "results\n",
    "results['P Val']=results['p-unc']\n",
    "results[results['Q Sig']==True][['Source','metric','P Val','Q Sig','Q Val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "260ea89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDMN_Rad\n",
      "1.1464417400918367 SCD MEAN\n",
      "1.1216149170487804 HC MEAN\n",
      "1.1318267604456522 Training MEAN\n",
      "1.1385869518863638 NO TRAINING MEAN\n",
      "1.126768850611111 AFTER MEAN\n",
      "1.1434946352444444 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.012589   1  0.012589  1.456069  0.230754  0.003887  1.0\n",
      "aDMN_Rad\n",
      "1.8282300313979591 SCD MEAN\n",
      "1.7663054559634142 HC MEAN\n",
      "1.8177406145000001 Training MEAN\n",
      "1.7814937946818181 NO TRAINING MEAN\n",
      "1.7904081215888885 AFTER MEAN\n",
      "1.809631772477778 BEFORE MEAN\n",
      "  Source       SS  DF       MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.01663   1  0.01663  0.654986  0.420494  0.001332  1.0\n",
      "DAN_Rad\n",
      "1.8855045060918365 SCD MEAN\n",
      "1.9049916081097562 HC MEAN\n",
      "1.8631536356630434 Training MEAN\n",
      "1.9270297611477274 NO TRAINING MEAN\n",
      "1.8863504602888892 AFTER MEAN\n",
      "1.9024134670666668 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.011611   1  0.011611  0.823281  0.366673  0.001298  1.0\n",
      "FPN_Rad\n",
      "1.8049649691020409 SCD MEAN\n",
      "1.8149516652682927 HC MEAN\n",
      "1.7970195510869562 Training MEAN\n",
      "1.8225773275454544 NO TRAINING MEAN\n",
      "1.8050637288111113 AFTER MEAN\n",
      "1.8139651992333332 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F    p-unc       ng2  eps\n",
      "0    Pre  0.003566   1  0.003566  0.649582  0.42241  0.001412  1.0\n",
      "VN_Rad\n",
      "1.2341564451632654 SCD MEAN\n",
      "1.2697101637195123 HC MEAN\n",
      "1.2668079285543477 Training MEAN\n",
      "1.2331504048181818 NO TRAINING MEAN\n",
      "1.263905911988889 AFTER MEAN\n",
      "1.2368003663555553 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.033062   1  0.033062  4.055209  0.047055  0.009159  1.0\n",
      "VAN_Rad\n",
      "1.8179168416836737 SCD MEAN\n",
      "1.8206097407804878 HC MEAN\n",
      "1.8033514212499997 Training MEAN\n",
      "1.8356536190227275 NO TRAINING MEAN\n",
      "1.8059549368333336 AFTER MEAN\n",
      "1.8323322768222223 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.031309   1  0.031309  4.092658  0.046071  0.006652  1.0\n",
      "SN_Rad\n",
      "1.3062042975612245 SCD MEAN\n",
      "1.2740022247439022 HC MEAN\n",
      "1.290493338347826 Training MEAN\n",
      "1.2926229143409091 NO TRAINING MEAN\n",
      "1.2783914321555556 AFTER MEAN\n",
      "1.304677496622222 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.031093   1  0.031093  2.420459  0.123309  0.004695  1.0\n",
      "SMN_Rad\n",
      "1.8056951535612245 SCD MEAN\n",
      "1.80099641452439 HC MEAN\n",
      "1.7990284650869561 Training MEAN\n",
      "1.8082865028636363 NO TRAINING MEAN\n",
      "1.786554423322222 AFTER MEAN\n",
      "1.8205548104555558 BEFORE MEAN\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps\n",
      "0    Pre  0.052021   1  0.052021  1.881636  0.173596  0.004391  1.0\n",
      "  Source        SS  DF        MS         F     p-unc       ng2  eps    metric\n",
      "0    Pre  0.012589   1  0.012589  1.456069  0.230754  0.003887  1.0  pDMN_Rad\n",
      "0    Pre  0.016630   1  0.016630  0.654986  0.420494  0.001332  1.0  aDMN_Rad\n",
      "0    Pre  0.011611   1  0.011611  0.823281  0.366673  0.001298  1.0   DAN_Rad\n",
      "0    Pre  0.003566   1  0.003566  0.649582  0.422410  0.001412  1.0   FPN_Rad\n",
      "0    Pre  0.033062   1  0.033062  4.055209  0.047055  0.009159  1.0    VN_Rad\n",
      "0    Pre  0.031309   1  0.031309  4.092658  0.046071  0.006652  1.0   VAN_Rad\n",
      "0    Pre  0.031093   1  0.031093  2.420459  0.123309  0.004695  1.0    SN_Rad\n",
      "0    Pre  0.052021   1  0.052021  1.881636  0.173596  0.004391  1.0   SMN_Rad COMBINED RESULTS\n",
      "significant results only\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>ng2</th>\n",
       "      <th>eps</th>\n",
       "      <th>metric</th>\n",
       "      <th>Q Sig</th>\n",
       "      <th>Q Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Source, SS, DF, MS, F, p-unc, ng2, eps, metric, Q Sig, Q Val]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looks at change over time\n",
    "# standard anova with Change~ CogTr*Diagnosis\n",
    "results=anova_analysis(stat_df,stat_type='rad',dist_or_prob='dist',use_difference=True,package='pg')\n",
    "print('significant results only')\n",
    "results[results['Q Sig']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559682d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict,GridSearchCV,StratifiedKFold,LeaveOneOut,train_test_split,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27dd4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(scan_df,k,seed=100):\n",
    "#     KFold(n_splits=5,shuffle=True, random_state=seed)\n",
    "\n",
    "    pre_df=scan_df[scan_df['Pre']==1]\n",
    "    post_df=scan_df[scan_df['Pre']==0]\n",
    "    patients=scan_df['ID'].unique()\n",
    "    train_pats,test_pats=train_test_split(patients)\n",
    "    \n",
    "    kf = KFold(n_splits=k)\n",
    "    fold_split=kf.get_n_splits(scan_df)\n",
    "    print(fold_split)\n",
    "    train_pats=patients\n",
    "    stat_cols=[c for c in scan_df if 'adprob' in c]\n",
    "    meta_cols=['PreID','PostID','Same']\n",
    "    data=[]\n",
    "    for ti in train_pats:\n",
    "        print(ti,'TI')\n",
    "        t_pre=pre_df[pre_df['ID']==ti]\n",
    "        t_pre_stat=t_pre[stat_cols]\n",
    "        for tj in train_pats:\n",
    "            t_post=pre_df[pre_df['ID']==tj]\n",
    "            t_post_stat=t_post[stat_cols]\n",
    "            difference=t_post_stat-t_pre_stat\n",
    "            label=1 if tj==ti else 0\n",
    "            meta=[ti,tj,label]\n",
    "            difference[['ti',tj,label]]=meta\n",
    "            \n",
    "\n",
    "            data.append(difference)\n",
    "    print(data.shape,'DATA SHAPE')\n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d43cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "UMEC-002 TI\n",
      "UMEC-020 TI\n",
      "UMEC-022 TI\n",
      "UMEC-026 TI\n",
      "UMEC-028 TI\n",
      "UMEC-031 TI\n",
      "UMEC-038 TI\n",
      "UMEC-066 TI\n",
      "UMEC-073 TI\n",
      "UMEC-075 TI\n",
      "UMEC-079 TI\n",
      "UMEC-082 TI\n",
      "UMEC-083 TI\n",
      "UMEC-124 TI\n",
      "UMEC-125 TI\n",
      "UMEC-147 TI\n",
      "UMEC-160 TI\n",
      "UMEC-161 TI\n",
      "UMEC-186 TI\n",
      "UMEC-208 TI\n",
      "UMEC-225 TI\n",
      "UMEC-226 TI\n",
      "UMEC-004 TI\n",
      "UMEC-005 TI\n",
      "UMEC-017 TI\n",
      "UMEC-030 TI\n",
      "UMEC-032 TI\n",
      "UMEC-053 TI\n",
      "UMEC-115 TI\n",
      "UMEC-132 TI\n",
      "UMEC-146 TI\n",
      "UMEC-155 TI\n",
      "UMEC-157 TI\n",
      "UMEC-159 TI\n",
      "UMEC-162 TI\n",
      "UMEC-164 TI\n",
      "UMEC-168 TI\n",
      "UMEC-173 TI\n",
      "UMEC-174 TI\n",
      "UMEC-176 TI\n",
      "UMEC-192 TI\n",
      "UMEC-194 TI\n",
      "UMEC-201 TI\n",
      "UMEC-206 TI\n",
      "UMEC-217 TI\n",
      "UMEC-219 TI\n",
      "UMEC-008 TI\n",
      "UMEC-009 TI\n",
      "UMEC-076 TI\n",
      "UMEC-078 TI\n",
      "UMEC-080 TI\n",
      "UMEC-081 TI\n",
      "UMEC-127 TI\n",
      "UMEC-136 TI\n",
      "UMEC-138 TI\n",
      "UMEC-150 TI\n",
      "UMEC-181 TI\n",
      "UMEC-182 TI\n",
      "UMEC-184 TI\n",
      "UMEC-185 TI\n",
      "UMEC-190 TI\n",
      "UMEC-196 TI\n",
      "UMEC-197 TI\n",
      "UMEC-210 TI\n",
      "UMEC-227 TI\n",
      "UMEC-036 TI\n",
      "UMEC-039 TI\n",
      "UMEC-054 TI\n",
      "UMEC-060 TI\n",
      "UMEC-061 TI\n",
      "UMEC-064 TI\n",
      "UMEC-068 TI\n",
      "UMEC-100 TI\n",
      "UMEC-101 TI\n",
      "UMEC-104 TI\n",
      "UMEC-121 TI\n",
      "UMEC-139 TI\n",
      "UMEC-141 TI\n",
      "UMEC-145 TI\n",
      "UMEC-148 TI\n",
      "UMEC-151 TI\n",
      "UMEC-152 TI\n",
      "UMEC-154 TI\n",
      "UMEC-163 TI\n",
      "UMEC-172 TI\n",
      "UMEC-191 TI\n",
      "UMEC-205 TI\n",
      "UMEC-213 TI\n",
      "UMEC-214 TI\n",
      "UMEC-216 TI\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29212\\982178615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29212\\475771064.py\u001b[0m in \u001b[0;36mcreate_splits\u001b[1;34m(scan_df, k, seed)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'DATA SHAPE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "create_splits(stat_df,k=4,seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a842eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-hgnn]",
   "language": "python",
   "name": "conda-env-anaconda3-hgnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
