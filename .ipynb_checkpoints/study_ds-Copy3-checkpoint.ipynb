{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad3f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported utils\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used for recreating the link prediction results for different parameter settings\n",
    "and dimensionality\n",
    "\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "from params import *\n",
    "# from params import BAND_TO_OPT_C\n",
    "import sys\n",
    "from datetime import date\n",
    "import pickle\n",
    "import train_inductive\n",
    "# should we not make a seperate config for out \"official runnings\"\n",
    "from trials.hyperparam_config import config\n",
    "import pickle\n",
    "import optuna\n",
    "import copy\n",
    "from utils.train_utils import get_dir_name, format_metrics\n",
    "from main import parse_default_args\n",
    "from hyperparam import create_study_output_dir,create_objective_fun,complete_study_one_arg\n",
    "from utils.model_analysis_utils import save_embeddings_all\n",
    "from data.MEG import get_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2502fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trials.hyperparam_config import config\n",
    "from main import parse_default_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480a27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_OPT_C= { \n",
    "           'alpha':.54,\n",
    "           'gamma':.66,\n",
    "           'beta': .74,\n",
    "            'theta':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_arch_dict={'model':'HGCN','optimizer':'RiemannianAdam','manifold':'PoincareBall'}\n",
    "euc_arch_dict={'model':'GCN','optimizer':'Adam','manifold':'Euclidean'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 'set'},\n",
       " 'findc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': None},\n",
       " '1c': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 1},\n",
       " 'euc': {'model': 'GCN', 'optimizer': 'Adam', 'manifold': 'Euclidean', 'c': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_types={'full':{'use_weight':1,'use_virtual':1},\n",
    "            'no_virt':{'use_weight':1,'use_virtual':0},\n",
    "                'no_weight':{'use_weight':0,'use_virtual':1}}\n",
    "\n",
    "input_types={'plv':{'use_plv':1,'use_identity':0,'num_feature':91},\n",
    "             'id':{'use_plv':0,'use_identity':1,'num_feature':91},\n",
    "             'id_plv':{'use_plv':1,'use_identity':1,'num_feature':181}}\n",
    "\n",
    "\n",
    "curve_types={'setc':{**hyp_arch_dict,'c':'set'},\n",
    "            'findc':{**hyp_arch_dict,'c':None},\n",
    "            '1c':{**hyp_arch_dict,'c':1},\n",
    "             'euc':{**euc_arch_dict,'c':0},\n",
    "            }\n",
    "curve_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72779412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 1, PLV 0\n",
      "C: None, ID: 1, PLV 0\n",
      "\n",
      "\n",
      "HGCN_full_findc_id_dp model\n",
      "HGCN_full_findc_id_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq study directory!\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.1, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_18_24_44_862433', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=1, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166]\n",
      "92 17 71 lengths\n",
      "180 unique lenths\n",
      "92 17 71 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166], 'test': [161, 158, 132, 122, 101, 138, 112, 117, 104, 137, 156, 152, 179, 136, 120, 167, 159, 96, 154, 176, 105, 164, 92, 177, 99, 110, 142, 162, 95, 150, 175, 134, 119, 144, 107, 169, 163, 143, 174, 127, 108, 148, 97, 151, 170, 155, 146, 98, 116, 157, 128, 93, 160, 133, 130, 115, 168, 102, 125, 94, 140, 118, 114, 121, 124, 100, 147, 165, 145, 139, 172], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "92 71 17 length\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166], 'test': [161, 158, 132, 122, 101, 138, 112, 117, 104, 137, 156, 152, 179, 136, 120, 167, 159, 96, 154, 176, 105, 164, 92, 177, 99, 110, 142, 162, 95, 150, 175, 134, 119, 144, 107, 169, 163, 143, 174, 127, 108, 148, 97, 151, 170, 155, 146, 98, 116, 157, 128, 93, 160, 133, 130, 115, 168, 102, 125, 94, 140, 118, 114, 121, 124, 100, 147, 165, 145, 139, 172], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '103', '106', '109', '111', '113', '123', '126', '129', '131', '135', '141', '149', '153', '166', '171', '173', '178', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '104', '105', '107', '108', '110', '112', '114', '115', '116', '117', '118', '119', '120', '121', '122', '124', '125', '127', '128', '130', '132', '133', '134', '136', '137', '138', '139', '140', '142', '143', '144', '145', '146', '147', '148', '150', '151', '152', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '167', '168', '169', '170', '172', '174', '175', '176', '177', '179'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '103', '106', '109', '111', '113', '123', '126', '129', '131', '135', '141', '149', '153', '166', '171', '173', '178', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '104', '105', '107', '108', '110', '112', '114', '115', '116', '117', '118', '119', '120', '121', '122', '124', '125', '127', '128', '130', '132', '133', '134', '136', '137', '138', '139', '140', '142', '143', '144', '145', '146', '147', '148', '150', '151', '152', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '167', '168', '169', '170', '172', '174', '175', '176', '177', '179'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[161, 158, 132, 122, 101, 138, 112, 117, 104, 137, 156, 152, 179, 136, 120, 167, 159, 96, 154, 176, 105, 164, 92, 177, 99, 110, 142, 162, 95, 150, 175, 134, 119, 144, 107, 169, 163, 143, 174, 127, 108, 148, 97, 151, 170, 155, 146, 98, 116, 157, 128, 93, 160, 133, 130, 115, 168, 102, 125, 94, 140, 118, 114, 121, 124, 100, 147, 165, 145, 139, 172] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '103', '106', '109', '111', '113', '123', '126', '129', '131', '135', '141', '149', '153', '166', '171', '173', '178', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '104', '105', '107', '108', '110', '112', '114', '115', '116', '117', '118', '119', '120', '121', '122', '124', '125', '127', '128', '130', '132', '133', '134', '136', '137', '138', '139', '140', '142', '143', '144', '145', '146', '147', '148', '150', '151', '152', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '167', '168', '169', '170', '172', '174', '175', '176', '177', '179'] dta set indices\n",
      "92 71 17\n",
      "-1 ARG FREQ\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [153, 149, 129, 113, 109, 171, 123, 173, 106, 126, 111, 135, 131, 141, 103, 178, 166], 'test': [161, 158, 132, 122, 101, 138, 112, 117, 104, 137, 156, 152, 179, 136, 120, 167, 159, 96, 154, 176, 105, 164, 92, 177, 99, 110, 142, 162, 95, 150, 175, 134, 119, 144, 107, 169, 163, 143, 174, 127, 108, 148, 97, 151, 170, 155, 146, 98, 116, 157, 128, 93, 160, 133, 130, 115, 168, 102, 125, 94, 140, 118, 114, 121, 124, 100, 147, 165, 145, 139, 172], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.1, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_18_24_44_862433', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=1, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS???\n",
      "<class 'models.base_models.LPModel'> MODEL??\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "2.0 1.0 FERMI epoch: 0\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "10 train length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7985, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.6360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.7340, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 0: precision 0.547913,roc 0.846379, loss 0.722807, acc 0, ECE 0 #edges 131590, #graphs 30\n",
      "tensor(0.6915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5778, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 0: precision 0.537826,roc 0.839864, loss 0.687533, acc 0, ECE 0 #edges 219950, #graphs 50\n",
      "tensor(0.4719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5825, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 0: precision 0.549303,roc 0.837056, loss 0.641732, acc 0, ECE 0 #edges 311000, #graphs 70\n",
      "tensor(0.3595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3033, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.1 train phase of epoch 0: precision 0.544449,roc 0.830192, loss 0.542392, acc 0, ECE 0 #edges 404320, #graphs 92 time: 195.5347s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2691, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 0: precision 0.544449,roc 0.830192, loss 0.542392, acc 0, ECE 0 #edges 404320, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 195.5503s\n",
      "2.0 1.0 FERMI epoch: 1\n",
      "Parameter containing:\n",
      "tensor([1.4641], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.4164, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3802, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 1: precision 0.536028,roc 0.837303, loss 0.424783, acc 0, ECE 0 #edges 133690, #graphs 30\n",
      "tensor(0.3687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4135, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 1: precision 0.555911,roc 0.823669, loss 0.411305, acc 0, ECE 0 #edges 221000, #graphs 50\n",
      "tensor(0.3408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4783, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 1: precision 0.559451,roc 0.828696, loss 0.410807, acc 0, ECE 0 #edges 311320, #graphs 70\n",
      "tensor(0.3161, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3025, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.1 train phase of epoch 1: precision 0.569055,roc 0.835006, loss 0.377935, acc 0, ECE 0 #edges 404852, #graphs 92 time: 219.7388s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2852, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 1: precision 0.569055,roc 0.835006, loss 0.377935, acc 0, ECE 0 #edges 404852, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 219.7408s\n",
      "10\n",
      "17\n",
      "0.18937003602627694 0.8307703605786885 loss acc\n",
      "17\n",
      "0.18937003602627694 0.8307703605786885 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.639417,roc 0.822813, loss 0.189370, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 2\n",
      "Parameter containing:\n",
      "tensor([1.4312], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3191, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2824, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 2: precision 0.564161,roc 0.843454, loss 0.333021, acc 0, ECE 0 #edges 131050, #graphs 30\n",
      "tensor(0.4281, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2399, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 2: precision 0.568944,roc 0.844982, loss 0.333404, acc 0, ECE 0 #edges 219310, #graphs 50\n",
      "tensor(0.3405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3673, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 2: precision 0.558264,roc 0.841792, loss 0.339263, acc 0, ECE 0 #edges 308870, #graphs 70\n",
      "tensor(0.2594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2871, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.1 train phase of epoch 2: precision 0.567578,roc 0.845767, loss 0.326921, acc 0, ECE 0 #edges 403644, #graphs 92 time: 210.3910s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3479, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 2: precision 0.567578,roc 0.845767, loss 0.326921, acc 0, ECE 0 #edges 403644, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 210.3910s\n",
      "2.0 1.0 FERMI epoch: 3\n",
      "Parameter containing:\n",
      "tensor([1.4188], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3630, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 3: precision 0.580338,roc 0.856915, loss 0.340000, acc 0, ECE 0 #edges 132610, #graphs 30\n",
      "tensor(0.2854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3117, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 3: precision 0.562969,roc 0.849721, loss 0.323414, acc 0, ECE 0 #edges 219510, #graphs 50\n",
      "tensor(0.3463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3662, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 3: precision 0.568025,roc 0.854760, loss 0.332802, acc 0, ECE 0 #edges 308690, #graphs 70\n",
      "tensor(0.3870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3712, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.1 train phase of epoch 3: precision 0.585363,roc 0.857729, loss 0.326282, acc 0, ECE 0 #edges 407548, #graphs 92 time: 222.8362s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1751, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 3: precision 0.585363,roc 0.857729, loss 0.326282, acc 0, ECE 0 #edges 407548, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 222.8362s\n",
      "10\n",
      "17\n",
      "0.14169785053247166 0.6995520305500477 loss acc\n",
      "17\n",
      "0.14169785053247166 0.6995520305500477 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.724705,roc 0.902911, loss 0.141698, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 4\n",
      "Parameter containing:\n",
      "tensor([1.4148], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3304, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 4: precision 0.619234,roc 0.878620, loss 0.326381, acc 0, ECE 0 #edges 132750, #graphs 30\n",
      "tensor(0.3031, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2780, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 4: precision 0.593797,roc 0.872545, loss 0.312050, acc 0, ECE 0 #edges 219940, #graphs 50\n",
      "tensor(0.2543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3442, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 4: precision 0.584106,roc 0.871198, loss 0.308391, acc 0, ECE 0 #edges 307730, #graphs 70\n",
      "tensor(0.3019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3132, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.1 train phase of epoch 4: precision 0.584702,roc 0.869855, loss 0.295115, acc 0, ECE 0 #edges 404276, #graphs 92 time: 228.4962s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1773, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 4: precision 0.584702,roc 0.869855, loss 0.295115, acc 0, ECE 0 #edges 404276, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 228.4962s\n",
      "2.0 1.0 FERMI epoch: 5\n",
      "Parameter containing:\n",
      "tensor([1.3910], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3196, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 5: precision 0.566594,roc 0.870562, loss 0.314628, acc 0, ECE 0 #edges 132730, #graphs 30\n",
      "tensor(0.2473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3601, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 5: precision 0.561814,roc 0.870101, loss 0.310266, acc 0, ECE 0 #edges 220870, #graphs 50\n",
      "tensor(0.2891, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2688, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 5: precision 0.564376,roc 0.868868, loss 0.301315, acc 0, ECE 0 #edges 307510, #graphs 70\n",
      "tensor(0.3056, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3372, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.1 train phase of epoch 5: precision 0.574116,roc 0.870876, loss 0.293550, acc 0, ECE 0 #edges 405254, #graphs 92 time: 222.0418s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1835, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 5: precision 0.574116,roc 0.870876, loss 0.293550, acc 0, ECE 0 #edges 405254, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 222.0418s\n",
      "10\n",
      "17\n",
      "0.11808478743933991 0.8620547844606007 loss acc\n",
      "17\n",
      "0.11808478743933991 0.8620547844606007 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.722093,roc 0.898101, loss 0.118085, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 6\n",
      "Parameter containing:\n",
      "tensor([1.3368], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2488, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 6: precision 0.585972,roc 0.876504, loss 0.270974, acc 0, ECE 0 #edges 130230, #graphs 30\n",
      "tensor(0.2973, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2744, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 6: precision 0.570564,roc 0.873362, loss 0.276922, acc 0, ECE 0 #edges 218460, #graphs 50\n",
      "tensor(0.2208, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2102, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 6: precision 0.587269,roc 0.877615, loss 0.259367, acc 0, ECE 0 #edges 303050, #graphs 70\n",
      "tensor(0.3477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3670, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.1 train phase of epoch 6: precision 0.598647,roc 0.879070, loss 0.267777, acc 0, ECE 0 #edges 402592, #graphs 92 time: 212.2004s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1475, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 6: precision 0.598647,roc 0.879070, loss 0.267777, acc 0, ECE 0 #edges 402592, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 212.2004s\n",
      "2.0 1.0 FERMI epoch: 7\n",
      "Parameter containing:\n",
      "tensor([1.3228], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3303, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2329, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 7: precision 0.615695,roc 0.884887, loss 0.276529, acc 0, ECE 0 #edges 131460, #graphs 30\n",
      "tensor(0.2006, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2677, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 7: precision 0.596008,roc 0.881743, loss 0.259568, acc 0, ECE 0 #edges 217820, #graphs 50\n",
      "tensor(0.3547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3442, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 7: precision 0.605697,roc 0.882012, loss 0.285252, acc 0, ECE 0 #edges 308820, #graphs 70\n",
      "tensor(0.2622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2451, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.1 train phase of epoch 7: precision 0.595934,roc 0.882590, loss 0.267203, acc 0, ECE 0 #edges 403520, #graphs 92 time: 214.1140s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1680, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 7: precision 0.595934,roc 0.882590, loss 0.267203, acc 0, ECE 0 #edges 403520, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 214.1140s\n",
      "10\n",
      "17\n",
      "0.09551437818830429 0.8309466108540795 loss acc\n",
      "17\n",
      "0.09551437818830429 0.8309466108540795 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.745839,roc 0.914655, loss 0.095514, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 8\n",
      "Parameter containing:\n",
      "tensor([1.2637], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2891, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3093, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 8: precision 0.616388,roc 0.881582, loss 0.303547, acc 0, ECE 0 #edges 133270, #graphs 30\n",
      "tensor(0.3127, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2364, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 8: precision 0.624277,roc 0.888019, loss 0.291948, acc 0, ECE 0 #edges 220030, #graphs 50\n",
      "tensor(0.3803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2362, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 8: precision 0.615626,roc 0.885942, loss 0.296608, acc 0, ECE 0 #edges 309740, #graphs 70\n",
      "tensor(0.2960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2591, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.1 train phase of epoch 8: precision 0.609910,roc 0.886127, loss 0.273743, acc 0, ECE 0 #edges 406344, #graphs 92 time: 221.1327s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1060, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 8: precision 0.609910,roc 0.886127, loss 0.273743, acc 0, ECE 0 #edges 406344, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 221.1327s\n",
      "2.0 1.0 FERMI epoch: 9\n",
      "Parameter containing:\n",
      "tensor([1.2235], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3000, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2803, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 9: precision 0.617667,roc 0.889847, loss 0.283310, acc 0, ECE 0 #edges 131000, #graphs 30\n",
      "tensor(0.3634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2604, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 9: precision 0.605846,roc 0.885930, loss 0.294736, acc 0, ECE 0 #edges 221130, #graphs 50\n",
      "tensor(0.3310, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2048, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 9: precision 0.592493,roc 0.883330, loss 0.287058, acc 0, ECE 0 #edges 309310, #graphs 70\n",
      "tensor(0.3708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2511, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.1 train phase of epoch 9: precision 0.594669,roc 0.884805, loss 0.278459, acc 0, ECE 0 #edges 406852, #graphs 92 time: 209.8796s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1534, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 9: precision 0.594669,roc 0.884805, loss 0.278459, acc 0, ECE 0 #edges 406852, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 209.8796s\n",
      "10\n",
      "17\n",
      "0.10569262387418049 0.7696702651097892 loss acc\n",
      "17\n",
      "0.10569262387418049 0.7696702651097892 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.765745,roc 0.925041, loss 0.105693, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 10\n",
      "Parameter containing:\n",
      "tensor([1.1791], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2368, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 10: precision 0.593980,roc 0.884286, loss 0.287082, acc 0, ECE 0 #edges 132190, #graphs 30\n",
      "tensor(0.2974, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2974, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 10: precision 0.586561,roc 0.884081, loss 0.291199, acc 0, ECE 0 #edges 220680, #graphs 50\n",
      "tensor(0.2228, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2721, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 10: precision 0.578857,roc 0.883116, loss 0.278698, acc 0, ECE 0 #edges 307350, #graphs 70\n",
      "tensor(0.1973, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3793, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.1 train phase of epoch 10: precision 0.601481,roc 0.888118, loss 0.281867, acc 0, ECE 0 #edges 404284, #graphs 92 time: 207.9044s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2911, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 10: precision 0.601481,roc 0.888118, loss 0.281867, acc 0, ECE 0 #edges 404284, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 207.9044s\n",
      "2.0 1.0 FERMI epoch: 11\n",
      "Parameter containing:\n",
      "tensor([1.1379], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2416, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 11: precision 0.655671,roc 0.897590, loss 0.316160, acc 0, ECE 0 #edges 134020, #graphs 30\n",
      "tensor(0.2629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2405, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 11: precision 0.618344,roc 0.891563, loss 0.290365, acc 0, ECE 0 #edges 221300, #graphs 50\n",
      "tensor(0.3700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2764, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 11: precision 0.634306,roc 0.895949, loss 0.299743, acc 0, ECE 0 #edges 310860, #graphs 70\n",
      "tensor(0.2478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1551, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.1 train phase of epoch 11: precision 0.644991,roc 0.899550, loss 0.261694, acc 0, ECE 0 #edges 403934, #graphs 92 time: 206.5242s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1159, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 11: precision 0.644991,roc 0.899550, loss 0.261694, acc 0, ECE 0 #edges 403934, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 206.5242s\n",
      "10\n",
      "17\n",
      "0.08394961854300383 0.8407431886612323 loss acc\n",
      "17\n",
      "0.08394961854300383 0.8407431886612323 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.772938,roc 0.928142, loss 0.083950, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 12\n",
      "Parameter containing:\n",
      "tensor([1.1495], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2586, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 12: precision 0.606852,roc 0.894015, loss 0.285181, acc 0, ECE 0 #edges 131080, #graphs 30\n",
      "tensor(0.3864, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2427, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 12: precision 0.630455,roc 0.898567, loss 0.296911, acc 0, ECE 0 #edges 219430, #graphs 50\n",
      "tensor(0.3226, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3052, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 12: precision 0.626015,roc 0.895000, loss 0.301756, acc 0, ECE 0 #edges 308710, #graphs 70\n",
      "tensor(0.3717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3153, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.1 train phase of epoch 12: precision 0.622544,roc 0.894693, loss 0.298926, acc 0, ECE 0 #edges 407344, #graphs 92 time: 207.8515s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1899, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 12: precision 0.622544,roc 0.894693, loss 0.298926, acc 0, ECE 0 #edges 407344, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 207.8671s\n",
      "2.0 1.0 FERMI epoch: 13\n",
      "Parameter containing:\n",
      "tensor([1.1720], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3172, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3253, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2328, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 13: precision 0.662584,roc 0.905077, loss 0.291762, acc 0, ECE 0 #edges 131970, #graphs 30\n",
      "tensor(0.3389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2252, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 13: precision 0.658297,roc 0.903799, loss 0.287884, acc 0, ECE 0 #edges 219830, #graphs 50\n",
      "tensor(0.3236, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2296, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 13: precision 0.624975,roc 0.896254, loss 0.284654, acc 0, ECE 0 #edges 308610, #graphs 70\n",
      "tensor(0.3334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3067, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.1 train phase of epoch 13: precision 0.630386,roc 0.897911, loss 0.272898, acc 0, ECE 0 #edges 406460, #graphs 92 time: 204.0316s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 13: precision 0.630386,roc 0.897911, loss 0.272898, acc 0, ECE 0 #edges 406460, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 204.0316s\n",
      "10\n",
      "17\n",
      "0.09318947590874427 0.8890651391642801 loss acc\n",
      "17\n",
      "0.09318947590874427 0.8890651391642801 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.772803,roc 0.925737, loss 0.093189, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 14\n",
      "Parameter containing:\n",
      "tensor([1.1638], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3155, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2447, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 14: precision 0.639756,roc 0.902860, loss 0.274427, acc 0, ECE 0 #edges 131120, #graphs 30\n",
      "tensor(0.2377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2319, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 14: precision 0.645614,roc 0.904498, loss 0.258584, acc 0, ECE 0 #edges 216870, #graphs 50\n",
      "tensor(0.2919, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3410, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 14: precision 0.633893,roc 0.900781, loss 0.275114, acc 0, ECE 0 #edges 306790, #graphs 70\n",
      "tensor(0.3447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2462, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.1 train phase of epoch 14: precision 0.634240,roc 0.900085, loss 0.262110, acc 0, ECE 0 #edges 404170, #graphs 92 time: 202.6795s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1044, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 14: precision 0.634240,roc 0.900085, loss 0.262110, acc 0, ECE 0 #edges 404170, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 202.6795s\n",
      "2.0 1.0 FERMI epoch: 15\n",
      "Parameter containing:\n",
      "tensor([1.1870], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3260, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 15: precision 0.620050,roc 0.897938, loss 0.281244, acc 0, ECE 0 #edges 131900, #graphs 30\n",
      "tensor(0.2480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2291, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 15: precision 0.592863,roc 0.893255, loss 0.264157, acc 0, ECE 0 #edges 219130, #graphs 50\n",
      "tensor(0.3712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3062, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 15: precision 0.615073,roc 0.895510, loss 0.285450, acc 0, ECE 0 #edges 309960, #graphs 70\n",
      "tensor(0.2643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2968, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.1 train phase of epoch 15: precision 0.613219,roc 0.896339, loss 0.269761, acc 0, ECE 0 #edges 407020, #graphs 92 time: 202.9184s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1384, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 15: precision 0.613219,roc 0.896339, loss 0.269761, acc 0, ECE 0 #edges 407020, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 202.9184s\n",
      "10\n",
      "17\n",
      "0.08206624533722617 0.8848498200778439 loss acc\n",
      "17\n",
      "0.08206624533722617 0.8848498200778439 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.785822,roc 0.930882, loss 0.082066, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 16\n",
      "Parameter containing:\n",
      "tensor([1.1627], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2198, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 16: precision 0.627343,roc 0.902057, loss 0.282030, acc 0, ECE 0 #edges 132590, #graphs 30\n",
      "tensor(0.1797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2358, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 16: precision 0.595846,roc 0.894966, loss 0.252315, acc 0, ECE 0 #edges 218990, #graphs 50\n",
      "tensor(0.2920, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3137, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 16: precision 0.610323,roc 0.896285, loss 0.266757, acc 0, ECE 0 #edges 308700, #graphs 70\n",
      "tensor(0.1807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2062, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.1 train phase of epoch 16: precision 0.610556,roc 0.897182, loss 0.236256, acc 0, ECE 0 #edges 402610, #graphs 92 time: 204.4404s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1084, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 16: precision 0.610556,roc 0.897182, loss 0.236256, acc 0, ECE 0 #edges 402610, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 204.4404s\n",
      "2.0 1.0 FERMI epoch: 17\n",
      "Parameter containing:\n",
      "tensor([1.1532], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2070, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3038, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2191, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 17: precision 0.624392,roc 0.901811, loss 0.243297, acc 0, ECE 0 #edges 130410, #graphs 30\n",
      "tensor(0.3173, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2797, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 17: precision 0.620636,roc 0.898623, loss 0.265370, acc 0, ECE 0 #edges 220380, #graphs 50\n",
      "tensor(0.3645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2989, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 17: precision 0.620440,roc 0.898079, loss 0.284319, acc 0, ECE 0 #edges 311410, #graphs 70\n",
      "tensor(0.2841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2269, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.1 train phase of epoch 17: precision 0.615754,roc 0.899083, loss 0.267223, acc 0, ECE 0 #edges 407488, #graphs 92 time: 203.0290s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1710, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 17: precision 0.615754,roc 0.899083, loss 0.267223, acc 0, ECE 0 #edges 407488, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 203.0290s\n",
      "10\n",
      "17\n",
      "0.0748697321559458 0.8815010648454138 loss acc\n",
      "17\n",
      "0.0748697321559458 0.8815010648454138 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.797705,roc 0.936315, loss 0.074870, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 18\n",
      "Parameter containing:\n",
      "tensor([1.1286], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3305, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2247, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 18: precision 0.615552,roc 0.898753, loss 0.279782, acc 0, ECE 0 #edges 133130, #graphs 30\n",
      "tensor(0.2653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1975, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 18: precision 0.628478,roc 0.903002, loss 0.260428, acc 0, ECE 0 #edges 219350, #graphs 50\n",
      "tensor(0.3142, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3112, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 18: precision 0.637562,roc 0.905298, loss 0.275367, acc 0, ECE 0 #edges 308910, #graphs 70\n",
      "tensor(0.2794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3030, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.1 train phase of epoch 18: precision 0.644283,roc 0.907776, loss 0.267638, acc 0, ECE 0 #edges 405564, #graphs 92 time: 200.7701s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1665, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 18: precision 0.644283,roc 0.907776, loss 0.267638, acc 0, ECE 0 #edges 405564, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 200.7701s\n",
      "2.0 1.0 FERMI epoch: 19\n",
      "Parameter containing:\n",
      "tensor([1.1019], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.1859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3178, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2603, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 19: precision 0.580642,roc 0.894240, loss 0.254655, acc 0, ECE 0 #edges 130920, #graphs 30\n",
      "tensor(0.2215, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2050, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 19: precision 0.590984,roc 0.898003, loss 0.238110, acc 0, ECE 0 #edges 216580, #graphs 50\n",
      "tensor(0.3614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2698, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 19: precision 0.591841,roc 0.895941, loss 0.260242, acc 0, ECE 0 #edges 307310, #graphs 70\n",
      "tensor(0.3582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2986, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.1 train phase of epoch 19: precision 0.620148,roc 0.902040, loss 0.259330, acc 0, ECE 0 #edges 405708, #graphs 92 time: 201.3842s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1148, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 19: precision 0.620148,roc 0.902040, loss 0.259330, acc 0, ECE 0 #edges 405708, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 201.3998s\n",
      "10\n",
      "17\n",
      "0.07508219155138617 0.8842182565910259 loss acc\n",
      "17\n",
      "0.07508219155138617 0.8842182565910259 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.797489,roc 0.937673, loss 0.075082, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 20\n",
      "Parameter containing:\n",
      "tensor([1.1004], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3145, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2224, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 20: precision 0.578057,roc 0.893166, loss 0.268307, acc 0, ECE 0 #edges 132760, #graphs 30\n",
      "tensor(0.2184, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3406, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 20: precision 0.609090,roc 0.899287, loss 0.272789, acc 0, ECE 0 #edges 221300, #graphs 50\n",
      "tensor(0.2355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3105, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 20: precision 0.615411,roc 0.901320, loss 0.272846, acc 0, ECE 0 #edges 309580, #graphs 70\n",
      "tensor(0.2804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3101, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.09000000000000001 train phase of epoch 20: precision 0.622343,roc 0.903693, loss 0.267536, acc 0, ECE 0 #edges 407274, #graphs 92 time: 202.5905s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1750, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 20: precision 0.622343,roc 0.903693, loss 0.267536, acc 0, ECE 0 #edges 407274, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 202.6062s\n",
      "2.0 1.0 FERMI epoch: 21\n",
      "Parameter containing:\n",
      "tensor([1.1119], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3204, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2119, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2861, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 21: precision 0.677033,roc 0.916896, loss 0.272815, acc 0, ECE 0 #edges 131520, #graphs 30\n",
      "tensor(0.4080, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2763, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 21: precision 0.653487,roc 0.908557, loss 0.300551, acc 0, ECE 0 #edges 222390, #graphs 50\n",
      "tensor(0.2706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2860, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 21: precision 0.631791,roc 0.905492, loss 0.294193, acc 0, ECE 0 #edges 310810, #graphs 70\n",
      "tensor(0.2672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2192, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.09000000000000001 train phase of epoch 21: precision 0.629723,roc 0.905696, loss 0.277802, acc 0, ECE 0 #edges 405796, #graphs 92 time: 200.7239s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2323, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 21: precision 0.629723,roc 0.905696, loss 0.277802, acc 0, ECE 0 #edges 405796, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 200.7239s\n",
      "10\n",
      "17\n",
      "0.07247668249621031 0.8749944921788941 loss acc\n",
      "17\n",
      "0.07247668249621031 0.8749944921788941 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.798344,roc 0.940285, loss 0.072477, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 22\n",
      "Parameter containing:\n",
      "tensor([1.0974], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1912, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 22: precision 0.633984,roc 0.906036, loss 0.257127, acc 0, ECE 0 #edges 130870, #graphs 30\n",
      "tensor(0.3053, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2445, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 22: precision 0.621168,roc 0.903355, loss 0.264253, acc 0, ECE 0 #edges 219050, #graphs 50\n",
      "tensor(0.2870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2403, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 22: precision 0.621547,roc 0.903814, loss 0.264091, acc 0, ECE 0 #edges 306220, #graphs 70\n",
      "tensor(0.3612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3544, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.09000000000000001 train phase of epoch 22: precision 0.629613,roc 0.905464, loss 0.270673, acc 0, ECE 0 #edges 405606, #graphs 92 time: 201.7439s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1425, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 22: precision 0.629613,roc 0.905464, loss 0.270673, acc 0, ECE 0 #edges 405606, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 201.7439s\n",
      "2.0 1.0 FERMI epoch: 23\n",
      "Parameter containing:\n",
      "tensor([1.0911], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2863, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2352, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 23: precision 0.585313,roc 0.893381, loss 0.294415, acc 0, ECE 0 #edges 133250, #graphs 30\n",
      "tensor(0.2707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1785, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 23: precision 0.582376,roc 0.897278, loss 0.266482, acc 0, ECE 0 #edges 219300, #graphs 50\n",
      "tensor(0.3627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2200, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 23: precision 0.601488,roc 0.900471, loss 0.273592, acc 0, ECE 0 #edges 308130, #graphs 70\n",
      "tensor(0.3229, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1937, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.09000000000000001 train phase of epoch 23: precision 0.612315,roc 0.902877, loss 0.253863, acc 0, ECE 0 #edges 404444, #graphs 92 time: 202.4180s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1069, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 23: precision 0.612315,roc 0.902877, loss 0.253863, acc 0, ECE 0 #edges 404444, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 202.4336s\n",
      "10\n",
      "17\n",
      "0.07955252762179889 0.8928398325622383 loss acc\n",
      "17\n",
      "0.07955252762179889 0.8928398325622383 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.793831,roc 0.940087, loss 0.079553, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 24\n",
      "Parameter containing:\n",
      "tensor([1.1267], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2634, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 24: precision 0.631982,roc 0.908880, loss 0.292014, acc 0, ECE 0 #edges 132840, #graphs 30\n",
      "tensor(0.2052, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2856, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 24: precision 0.634116,roc 0.909118, loss 0.273366, acc 0, ECE 0 #edges 219490, #graphs 50\n",
      "tensor(0.3097, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3321, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 24: precision 0.627140,roc 0.905500, loss 0.286952, acc 0, ECE 0 #edges 310370, #graphs 70\n",
      "tensor(0.2812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1904, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.09000000000000001 train phase of epoch 24: precision 0.643978,roc 0.909836, loss 0.259942, acc 0, ECE 0 #edges 404826, #graphs 92 time: 202.9519s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1192, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 24: precision 0.643978,roc 0.909836, loss 0.259942, acc 0, ECE 0 #edges 404826, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 202.9519s\n",
      "2.0 1.0 FERMI epoch: 25\n",
      "Parameter containing:\n",
      "tensor([1.1698], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2220, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3198, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1971, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 25: precision 0.590173,roc 0.902156, loss 0.246310, acc 0, ECE 0 #edges 130740, #graphs 30\n",
      "tensor(0.3306, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2425, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 25: precision 0.613469,roc 0.904895, loss 0.262408, acc 0, ECE 0 #edges 219450, #graphs 50\n",
      "tensor(0.2631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3147, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 25: precision 0.608723,roc 0.903925, loss 0.269984, acc 0, ECE 0 #edges 308580, #graphs 70\n",
      "tensor(0.3020, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3302, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.09000000000000001 train phase of epoch 25: precision 0.632096,roc 0.909018, loss 0.266842, acc 0, ECE 0 #edges 406338, #graphs 92 time: 201.3986s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1463, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 25: precision 0.632096,roc 0.909018, loss 0.266842, acc 0, ECE 0 #edges 406338, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 201.3986s\n",
      "10\n",
      "17\n",
      "0.0904735847978477 0.7799662186972167 loss acc\n",
      "17\n",
      "0.0904735847978477 0.7799662186972167 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.803244,roc 0.947337, loss 0.090474, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 26\n",
      "Parameter containing:\n",
      "tensor([1.1703], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.1789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2989, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2268, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 26: precision 0.629326,roc 0.911559, loss 0.234851, acc 0, ECE 0 #edges 129910, #graphs 30\n",
      "tensor(0.2228, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3386, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 26: precision 0.620645,roc 0.906091, loss 0.253179, acc 0, ECE 0 #edges 219220, #graphs 50\n",
      "tensor(0.1843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1985, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 26: precision 0.622526,roc 0.909709, loss 0.235525, acc 0, ECE 0 #edges 304110, #graphs 70\n",
      "tensor(0.2817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3535, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.09000000000000001 train phase of epoch 26: precision 0.639245,roc 0.911479, loss 0.247506, acc 0, ECE 0 #edges 402652, #graphs 92 time: 199.8927s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1912, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 26: precision 0.639245,roc 0.911479, loss 0.247506, acc 0, ECE 0 #edges 402652, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 199.8927s\n",
      "2.0 1.0 FERMI epoch: 27\n",
      "Parameter containing:\n",
      "tensor([1.1683], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1735, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2771, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 27: precision 0.655111,roc 0.916487, loss 0.245883, acc 0, ECE 0 #edges 130290, #graphs 30\n",
      "tensor(0.3316, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2212, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 27: precision 0.646380,roc 0.913255, loss 0.258097, acc 0, ECE 0 #edges 219120, #graphs 50\n",
      "tensor(0.2758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2676, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 27: precision 0.637817,roc 0.912219, loss 0.261973, acc 0, ECE 0 #edges 307480, #graphs 70\n",
      "tensor(0.3302, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1942, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.09000000000000001 train phase of epoch 27: precision 0.635353,roc 0.910909, loss 0.247372, acc 0, ECE 0 #edges 404694, #graphs 92 time: 205.2924s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1155, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 27: precision 0.635353,roc 0.910909, loss 0.247372, acc 0, ECE 0 #edges 404694, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 205.2944s\n",
      "10\n",
      "17\n",
      "0.06882630166764354 0.8555335242711317 loss acc\n",
      "17\n",
      "0.06882630166764354 0.8555335242711317 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.807114,roc 0.948316, loss 0.068826, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 28\n",
      "Parameter containing:\n",
      "tensor([1.1532], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2939, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1864, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2841, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 28: precision 0.607014,roc 0.907020, loss 0.254775, acc 0, ECE 0 #edges 132280, #graphs 30\n",
      "tensor(0.2691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2028, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 28: precision 0.584917,roc 0.902280, loss 0.247253, acc 0, ECE 0 #edges 219770, #graphs 50\n",
      "tensor(0.3029, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2517, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 28: precision 0.599101,roc 0.903530, loss 0.255838, acc 0, ECE 0 #edges 308990, #graphs 70\n",
      "tensor(0.3164, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1847, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.09000000000000001 train phase of epoch 28: precision 0.619623,roc 0.909016, loss 0.239701, acc 0, ECE 0 #edges 404780, #graphs 92 time: 200.8515s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1051, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 28: precision 0.619623,roc 0.909016, loss 0.239701, acc 0, ECE 0 #edges 404780, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 200.8515s\n",
      "2.0 1.0 FERMI epoch: 29\n",
      "Parameter containing:\n",
      "tensor([1.1408], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.1748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3464, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 29: precision 0.639681,roc 0.909831, loss 0.260396, acc 0, ECE 0 #edges 132800, #graphs 30\n",
      "tensor(0.2123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2777, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 29: precision 0.624267,roc 0.906053, loss 0.254229, acc 0, ECE 0 #edges 220950, #graphs 50\n",
      "tensor(0.1924, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2483, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 29: precision 0.615113,roc 0.905993, loss 0.244540, acc 0, ECE 0 #edges 307640, #graphs 70\n",
      "tensor(0.2122, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2333, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.09000000000000001 train phase of epoch 29: precision 0.617172,roc 0.908876, loss 0.231336, acc 0, ECE 0 #edges 402576, #graphs 92 time: 198.4200s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1561, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 29: precision 0.617172,roc 0.908876, loss 0.231336, acc 0, ECE 0 #edges 402576, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 198.4200s\n",
      "10\n",
      "17\n",
      "0.07617293070826728 0.8214584710288609 loss acc\n",
      "17\n",
      "0.07617293070826728 0.8214584710288609 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.809175,roc 0.950927, loss 0.076173, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 30\n",
      "Parameter containing:\n",
      "tensor([1.1409], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2966, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2183, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3026, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 30: precision 0.633147,roc 0.911209, loss 0.272466, acc 0, ECE 0 #edges 132950, #graphs 30\n",
      "tensor(0.3639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2145, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 30: precision 0.623220,roc 0.908492, loss 0.279153, acc 0, ECE 0 #edges 222940, #graphs 50\n",
      "tensor(0.1990, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2028, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 30: precision 0.614538,roc 0.908542, loss 0.256793, acc 0, ECE 0 #edges 308600, #graphs 70\n",
      "tensor(0.2443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3077, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.09000000000000001 train phase of epoch 30: precision 0.622255,roc 0.910221, loss 0.252886, acc 0, ECE 0 #edges 406004, #graphs 92 time: 199.5818s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1793, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 30: precision 0.622255,roc 0.910221, loss 0.252886, acc 0, ECE 0 #edges 406004, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 199.5818s\n",
      "2.0 1.0 FERMI epoch: 31\n",
      "Parameter containing:\n",
      "tensor([1.1121], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2468, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 31: precision 0.582764,roc 0.899787, loss 0.263646, acc 0, ECE 0 #edges 132830, #graphs 30\n",
      "tensor(0.3219, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2676, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 31: precision 0.616175,roc 0.906328, loss 0.276082, acc 0, ECE 0 #edges 221990, #graphs 50\n",
      "tensor(0.3142, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3533, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 31: precision 0.637608,roc 0.910079, loss 0.292554, acc 0, ECE 0 #edges 312550, #graphs 70\n",
      "tensor(0.2317, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2156, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.09000000000000001 train phase of epoch 31: precision 0.641333,roc 0.913459, loss 0.263309, acc 0, ECE 0 #edges 406902, #graphs 92 time: 203.5769s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1380, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 31: precision 0.641333,roc 0.913459, loss 0.263309, acc 0, ECE 0 #edges 406902, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 203.5769s\n",
      "10\n",
      "17\n",
      "0.07983593645636888 0.8074612616582213 loss acc\n",
      "17\n",
      "0.07983593645636888 0.8074612616582213 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.813620,roc 0.951811, loss 0.079836, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 32\n",
      "Parameter containing:\n",
      "tensor([1.1245], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3100, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2013, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 32: precision 0.716970,roc 0.927479, loss 0.289522, acc 0, ECE 0 #edges 132460, #graphs 30\n",
      "tensor(0.3320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2719, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 32: precision 0.691009,roc 0.921253, loss 0.294491, acc 0, ECE 0 #edges 222140, #graphs 50\n",
      "tensor(0.2789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2516, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 32: precision 0.660258,roc 0.915784, loss 0.286124, acc 0, ECE 0 #edges 310210, #graphs 70\n",
      "tensor(0.1996, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2987, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.09000000000000001 train phase of epoch 32: precision 0.646111,roc 0.914793, loss 0.275332, acc 0, ECE 0 #edges 405906, #graphs 92 time: 201.5862s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2522, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 32: precision 0.646111,roc 0.914793, loss 0.275332, acc 0, ECE 0 #edges 405906, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 201.5862s\n",
      "2.0 1.0 FERMI epoch: 33\n",
      "Parameter containing:\n",
      "tensor([1.0897], requires_grad=True) MODEL C\n",
      "10\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.3503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2236, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2759, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 33: precision 0.626196,roc 0.906602, loss 0.283258, acc 0, ECE 0 #edges 133080, #graphs 30\n",
      "tensor(0.2482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2446, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 33: precision 0.634703,roc 0.911215, loss 0.268509, acc 0, ECE 0 #edges 219650, #graphs 50\n",
      "tensor(0.2976, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2244, grad_fn=<DivBackward0>) loss by avg\n",
      "7\n",
      "train phase of epoch 33: precision 0.628171,roc 0.908918, loss 0.266355, acc 0, ECE 0 #edges 308130, #graphs 70\n",
      "tensor(0.1710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2653, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.09000000000000001 train phase of epoch 33: precision 0.624538,roc 0.911486, loss 0.249734, acc 0, ECE 0 #edges 402846, #graphs 92 time: 198.7347s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1965, grad_fn=<DivBackward0>) loss by avg\n",
      "10\n",
      "train phase of epoch 33: precision 0.624538,roc 0.911486, loss 0.249734, acc 0, ECE 0 #edges 402846, #graphs 92\n",
      "10\n",
      "training epoch done in  time: 198.7347s\n",
      "10\n",
      "17\n",
      "0.06595608999046393 0.8653888521700817 loss acc\n",
      "17\n",
      "0.06595608999046393 0.8653888521700817 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.813289,roc 0.949916, loss 0.065956, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.1_val_excl_group_strchinp95_strchloss95_b10_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 34\n",
      "Parameter containing:\n",
      "tensor([1.1133], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "10 train length\n",
      "tensor(0.2170, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2421, grad_fn=<DivBackward0>) loss by avg\n",
      "3\n",
      "train phase of epoch 34: precision 0.585118,roc 0.909495, loss 0.218441, acc 0, ECE 0 #edges 129720, #graphs 30\n",
      "tensor(0.2509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2584, grad_fn=<DivBackward0>) loss by avg\n",
      "5\n",
      "train phase of epoch 34: precision 0.626894,roc 0.915220, loss 0.232915, acc 0, ECE 0 #edges 216950, #graphs 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22512\\2937922118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m                 \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_i\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_data_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m                 \u001b[1;31m# embeddings,data_i=run_data_single(data, i,model,no_grad=freeze)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mrun_data_single\u001b[1;34m(data, index, model, skip_embedding, no_grad)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adj_mat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adj_mat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m     \u001b[1;31m# train_metrics = model.compute_metrics(embeddings, data_i, 'train')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;31m# # train_metrics['loss'].backward()  #### NOT YET!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# print(adj,'SHAPED UP')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# print(adj)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\encoders.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mx_hyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpmap0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurvatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mx_hyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurvatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHGCN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\encoders.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\layers\\hyp_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh_singles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mh_singles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\layers\\hyp_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, adj)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;31m# if len(x.shape)>2:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrechet_agg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mman\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrechet_agg_man\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrechet_B\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_recent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\diff_frech_mean\\frechet_agg.py\u001b[0m in \u001b[0;36mfrechet_agg\u001b[1;34m(x, adj, man, B)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# print(x[si],'')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mbatched_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# weight_tensor.append(F.pad(torch.ones_like(si), (0, B - len(si))))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mweight_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':1,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3,4,2]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44ff73b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 1, PLV 0\n",
      "C: None, ID: 1, PLV 0\n",
      "\n",
      "\n",
      "HGCN_full_findc_id_dp model\n",
      "HGCN_full_findc_id_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq study directory!\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169]\n",
      "92 17 71 lengths\n",
      "180 unique lenths\n",
      "92 17 71 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169], 'test': [153, 109, 144, 118, 126, 147, 132, 177, 106, 123, 163, 172, 142, 170, 165, 160, 127, 161, 140, 93, 159, 95, 139, 143, 98, 150, 122, 158, 129, 174, 124, 108, 154, 120, 130, 178, 138, 171, 145, 92, 96, 175, 112, 113, 110, 157, 152, 156, 166, 97, 167, 125, 137, 119, 99, 136, 162, 105, 100, 164, 121, 94, 149, 116, 117, 179, 114, 151, 131, 102, 115], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "92 71 17 length\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169], 'test': [153, 109, 144, 118, 126, 147, 132, 177, 106, 123, 163, 172, 142, 170, 165, 160, 127, 161, 140, 93, 159, 95, 139, 143, 98, 150, 122, 158, 129, 174, 124, 108, 154, 120, 130, 178, 138, 171, 145, 92, 96, 175, 112, 113, 110, 157, 152, 156, 166, 97, 167, 125, 137, 119, 99, 136, 162, 105, 100, 164, 121, 94, 149, 116, 117, 179, 114, 151, 131, 102, 115], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '101', '103', '104', '107', '111', '128', '133', '134', '135', '141', '146', '148', '155', '168', '169', '173', '176', '92', '93', '94', '95', '96', '97', '98', '99', '100', '102', '105', '106', '108', '109', '110', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '129', '130', '131', '132', '136', '137', '138', '139', '140', '142', '143', '144', '145', '147', '149', '150', '151', '152', '153', '154', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '170', '171', '172', '174', '175', '177', '178', '179'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '101', '103', '104', '107', '111', '128', '133', '134', '135', '141', '146', '148', '155', '168', '169', '173', '176', '92', '93', '94', '95', '96', '97', '98', '99', '100', '102', '105', '106', '108', '109', '110', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '129', '130', '131', '132', '136', '137', '138', '139', '140', '142', '143', '144', '145', '147', '149', '150', '151', '152', '153', '154', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '170', '171', '172', '174', '175', '177', '178', '179'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[153, 109, 144, 118, 126, 147, 132, 177, 106, 123, 163, 172, 142, 170, 165, 160, 127, 161, 140, 93, 159, 95, 139, 143, 98, 150, 122, 158, 129, 174, 124, 108, 154, 120, 130, 178, 138, 171, 145, 92, 96, 175, 112, 113, 110, 157, 152, 156, 166, 97, 167, 125, 137, 119, 99, 136, 162, 105, 100, 164, 121, 94, 149, 116, 117, 179, 114, 151, 131, 102, 115] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '101', '103', '104', '107', '111', '128', '133', '134', '135', '141', '146', '148', '155', '168', '169', '173', '176', '92', '93', '94', '95', '96', '97', '98', '99', '100', '102', '105', '106', '108', '109', '110', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '129', '130', '131', '132', '136', '137', '138', '139', '140', '142', '143', '144', '145', '147', '149', '150', '151', '152', '153', '154', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '170', '171', '172', '174', '175', '177', '178', '179'] dta set indices\n",
      "92 71 17\n",
      "-1 ARG FREQ\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [135, 128, 148, 103, 107, 133, 146, 141, 168, 176, 111, 104, 134, 173, 101, 155, 169], 'test': [153, 109, 144, 118, 126, 147, 132, 177, 106, 123, 163, 172, 142, 170, 165, 160, 127, 161, 140, 93, 159, 95, 139, 143, 98, 150, 122, 158, 129, 174, 124, 108, 154, 120, 130, 178, 138, 171, 145, 92, 96, 175, 112, 113, 110, 157, 152, 156, 166, 97, 167, 125, 137, 119, 99, 136, 162, 105, 100, 164, 121, 94, 149, 116, 117, 179, 114, 151, 131, 102, 115], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS???\n",
      "<class 'models.base_models.LPModel'> MODEL??\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "2.0 1.0 FERMI epoch: 0\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "92 train length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5223, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5190, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5013, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5018, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3947, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3247, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3301, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4048, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4193, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3584, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 0: precision 0.572062,roc 0.835307, loss 0.463280, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.2666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3039, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2903, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2865, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2893, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1791, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2185, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2239, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2916, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2461, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 0: precision 0.566914,roc 0.817479, loss 0.368272, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.2296, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2027, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1922, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1888, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1824, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1966, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1552, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 0: precision 0.587487,roc 0.833412, loss 0.305166, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1314, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1312, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1244, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1136, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1245, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1069, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1038, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1140, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0982, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1154, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1146, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1225, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1010, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.01 train phase of epoch 0: precision 0.608933,roc 0.848037, loss 0.260517, acc 0, ECE 0 #edges 368460, #graphs 92 time: 141.9504s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1080, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 0: precision 0.608933,roc 0.848037, loss 0.260517, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 141.9660s\n",
      "2.0 1.0 FERMI epoch: 1\n",
      "Parameter containing:\n",
      "tensor([1.0662], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1035, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1056, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0976, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0953, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0955, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1055, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0913, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1113, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1117, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0919, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0956, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0991, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0978, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0988, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0957, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0996, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 1: precision 0.715356,roc 0.919947, loss 0.097487, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1040, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0972, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0893, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0934, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0869, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1003, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 1: precision 0.731171,roc 0.926133, loss 0.091287, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0858, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0858, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0858, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0872, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0936, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0838, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0873, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 1: precision 0.740668,roc 0.929563, loss 0.087980, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0848, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0795, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.01 train phase of epoch 1: precision 0.748675,roc 0.932563, loss 0.085155, acc 0, ECE 0 #edges 368460, #graphs 92 time: 153.2752s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 1: precision 0.748675,roc 0.932563, loss 0.085155, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 153.2752s\n",
      "92\n",
      "17\n",
      "0.077892251097842 0.8422706910479549 loss acc\n",
      "17\n",
      "0.077892251097842 0.8422706910479549 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.776889,roc 0.942256, loss 0.077892, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 2\n",
      "Parameter containing:\n",
      "tensor([1.0115], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1002, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 2: precision 0.778075,roc 0.943430, loss 0.073954, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0850, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0791, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 2: precision 0.781798,roc 0.945511, loss 0.073086, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 2: precision 0.792176,roc 0.947337, loss 0.071597, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.01 train phase of epoch 2: precision 0.794885,roc 0.948581, loss 0.070581, acc 0, ECE 0 #edges 368460, #graphs 92 time: 189.8492s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 2: precision 0.794885,roc 0.948581, loss 0.070581, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 189.8512s\n",
      "2.0 1.0 FERMI epoch: 3\n",
      "Parameter containing:\n",
      "tensor([0.9751], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 3: precision 0.808184,roc 0.953654, loss 0.064647, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 3: precision 0.814842,roc 0.954360, loss 0.064877, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 3: precision 0.815461,roc 0.955059, loss 0.064833, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.01 train phase of epoch 3: precision 0.817775,roc 0.955227, loss 0.064563, acc 0, ECE 0 #edges 368460, #graphs 92 time: 159.3937s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 3: precision 0.817775,roc 0.955227, loss 0.064563, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 159.3947s\n",
      "92\n",
      "17\n",
      "0.06501534943105579 0.8838216934713959 loss acc\n",
      "17\n",
      "0.06501534943105579 0.8838216934713959 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.828925,roc 0.956262, loss 0.065015, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 4\n",
      "Parameter containing:\n",
      "tensor([0.9650], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 4: precision 0.827047,roc 0.957298, loss 0.062252, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 4: precision 0.828331,roc 0.957784, loss 0.062363, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 4: precision 0.831399,roc 0.958248, loss 0.061927, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.01 train phase of epoch 4: precision 0.831194,roc 0.958830, loss 0.061465, acc 0, ECE 0 #edges 368460, #graphs 92 time: 155.9624s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 4: precision 0.831194,roc 0.958830, loss 0.061465, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 155.9634s\n",
      "2.0 1.0 FERMI epoch: 5\n",
      "Parameter containing:\n",
      "tensor([0.9424], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 5: precision 0.833601,roc 0.959990, loss 0.059722, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0809, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 5: precision 0.837433,roc 0.960543, loss 0.060019, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 5: precision 0.839242,roc 0.960864, loss 0.059444, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.01 train phase of epoch 5: precision 0.840762,roc 0.961331, loss 0.059181, acc 0, ECE 0 #edges 368460, #graphs 92 time: 151.2935s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 5: precision 0.840762,roc 0.961331, loss 0.059181, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 151.2955s\n",
      "92\n",
      "17\n",
      "0.058965582038053965 0.8827641918190497 loss acc\n",
      "17\n",
      "0.058965582038053965 0.8827641918190497 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.851256,roc 0.962543, loss 0.058966, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 6\n",
      "Parameter containing:\n",
      "tensor([0.9352], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 6: precision 0.850173,roc 0.963066, loss 0.057917, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 6: precision 0.848266,roc 0.964106, loss 0.057387, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 6: precision 0.849473,roc 0.964016, loss 0.057026, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.01 train phase of epoch 6: precision 0.849178,roc 0.963419, loss 0.057433, acc 0, ECE 0 #edges 368460, #graphs 92 time: 165.2294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 6: precision 0.849178,roc 0.963419, loss 0.057433, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 165.2314s\n",
      "2.0 1.0 FERMI epoch: 7\n",
      "Parameter containing:\n",
      "tensor([0.9323], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 7: precision 0.859953,roc 0.965631, loss 0.056011, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 7: precision 0.856541,roc 0.965254, loss 0.055664, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 7: precision 0.856559,roc 0.965261, loss 0.055729, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.01 train phase of epoch 7: precision 0.855481,roc 0.965021, loss 0.056108, acc 0, ECE 0 #edges 368460, #graphs 92 time: 155.0483s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 7: precision 0.855481,roc 0.965021, loss 0.056108, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 155.0493s\n",
      "92\n",
      "17\n",
      "0.05591532879106759 0.891841081001689 loss acc\n",
      "17\n",
      "0.05591532879106759 0.891841081001689 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.864469,roc 0.965701, loss 0.055915, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 8\n",
      "Parameter containing:\n",
      "tensor([0.9193], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 8: precision 0.866045,roc 0.967750, loss 0.054849, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 8: precision 0.860626,roc 0.967444, loss 0.054419, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 8: precision 0.859061,roc 0.966558, loss 0.054742, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.01 train phase of epoch 8: precision 0.861264,roc 0.966521, loss 0.054710, acc 0, ECE 0 #edges 368460, #graphs 92 time: 154.7269s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 8: precision 0.861264,roc 0.966521, loss 0.054710, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 154.7299s\n",
      "2.0 1.0 FERMI epoch: 9\n",
      "Parameter containing:\n",
      "tensor([0.9176], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 9: precision 0.864933,roc 0.967608, loss 0.054764, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 9: precision 0.865315,roc 0.967527, loss 0.054407, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 9: precision 0.865173,roc 0.968178, loss 0.053600, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.01 train phase of epoch 9: precision 0.865443,roc 0.967747, loss 0.053863, acc 0, ECE 0 #edges 368460, #graphs 92 time: 153.9707s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 9: precision 0.865443,roc 0.967747, loss 0.053863, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 153.9727s\n",
      "92\n",
      "17\n",
      "0.0546163099452075 0.8834985679665125 loss acc\n",
      "17\n",
      "0.0546163099452075 0.8834985679665125 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.871581,roc 0.968304, loss 0.054616, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 10\n",
      "Parameter containing:\n",
      "tensor([0.8862], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 10: precision 0.868836,roc 0.968745, loss 0.052683, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 10: precision 0.866733,roc 0.968161, loss 0.053045, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 10: precision 0.865448,roc 0.968462, loss 0.052922, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.01 train phase of epoch 10: precision 0.868927,roc 0.968841, loss 0.052802, acc 0, ECE 0 #edges 368460, #graphs 92 time: 153.9261s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 10: precision 0.868927,roc 0.968841, loss 0.052802, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 153.9281s\n",
      "2.0 1.0 FERMI epoch: 11\n",
      "Parameter containing:\n",
      "tensor([0.8841], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 11: precision 0.870389,roc 0.969013, loss 0.052018, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 11: precision 0.870308,roc 0.969179, loss 0.052360, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 11: precision 0.871262,roc 0.969517, loss 0.052353, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.01 train phase of epoch 11: precision 0.871608,roc 0.969805, loss 0.051927, acc 0, ECE 0 #edges 368460, #graphs 92 time: 135.1469s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 11: precision 0.871608,roc 0.969805, loss 0.051927, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 135.1479s\n",
      "92\n",
      "17\n",
      "0.05220429313090556 0.8985092164206507 loss acc\n",
      "17\n",
      "0.05220429313090556 0.8985092164206507 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.873648,roc 0.969662, loss 0.052204, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 12\n",
      "Parameter containing:\n",
      "tensor([0.8630], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 12: precision 0.871539,roc 0.970933, loss 0.051182, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 12: precision 0.870648,roc 0.970588, loss 0.051700, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 12: precision 0.872813,roc 0.970892, loss 0.051232, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.01 train phase of epoch 12: precision 0.873449,roc 0.970536, loss 0.051349, acc 0, ECE 0 #edges 368460, #graphs 92 time: 106.9031s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 12: precision 0.873449,roc 0.970536, loss 0.051349, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 106.9041s\n",
      "2.0 1.0 FERMI epoch: 13\n",
      "Parameter containing:\n",
      "tensor([0.8483], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 13: precision 0.871408,roc 0.971251, loss 0.050924, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 13: precision 0.876919,roc 0.972008, loss 0.050149, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 13: precision 0.874692,roc 0.971596, loss 0.050392, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.01 train phase of epoch 13: precision 0.875152,roc 0.971258, loss 0.050817, acc 0, ECE 0 #edges 368460, #graphs 92 time: 106.7494s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 13: precision 0.875152,roc 0.971258, loss 0.050817, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 106.7494s\n",
      "92\n",
      "17\n",
      "0.05220967186382285 0.9084820445031945 loss acc\n",
      "17\n",
      "0.05220967186382285 0.9084820445031945 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.873658,roc 0.970141, loss 0.052210, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 14\n",
      "Parameter containing:\n",
      "tensor([0.8337], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 14: precision 0.871405,roc 0.971558, loss 0.050604, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 14: precision 0.875214,roc 0.972200, loss 0.049756, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 14: precision 0.874845,roc 0.971557, loss 0.050174, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.01 train phase of epoch 14: precision 0.877039,roc 0.971960, loss 0.049944, acc 0, ECE 0 #edges 368460, #graphs 92 time: 105.9294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 14: precision 0.877039,roc 0.971960, loss 0.049944, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 105.9304s\n",
      "2.0 1.0 FERMI epoch: 15\n",
      "Parameter containing:\n",
      "tensor([0.8028], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 15: precision 0.873241,roc 0.972937, loss 0.048895, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 15: precision 0.878052,roc 0.972441, loss 0.049855, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 15: precision 0.878221,roc 0.971830, loss 0.050608, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.01 train phase of epoch 15: precision 0.878871,roc 0.972449, loss 0.049934, acc 0, ECE 0 #edges 368460, #graphs 92 time: 106.7365s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 15: precision 0.878871,roc 0.972449, loss 0.049934, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 106.7375s\n",
      "92\n",
      "17\n",
      "0.05018834856505291 0.9017257839465376 loss acc\n",
      "17\n",
      "0.05018834856505291 0.9017257839465376 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.878712,roc 0.972098, loss 0.050188, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 16\n",
      "Parameter containing:\n",
      "tensor([0.7902], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 16: precision 0.875353,roc 0.972458, loss 0.049200, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 16: precision 0.881589,roc 0.973161, loss 0.049245, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 16: precision 0.881691,roc 0.973352, loss 0.049200, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.01 train phase of epoch 16: precision 0.881436,roc 0.973115, loss 0.049262, acc 0, ECE 0 #edges 368460, #graphs 92 time: 106.5794s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 16: precision 0.881436,roc 0.973115, loss 0.049262, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 106.5814s\n",
      "2.0 1.0 FERMI epoch: 17\n",
      "Parameter containing:\n",
      "tensor([0.7748], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 17: precision 0.870840,roc 0.972793, loss 0.050013, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 17: precision 0.879643,roc 0.973687, loss 0.048802, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 17: precision 0.881314,roc 0.973883, loss 0.048690, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.01 train phase of epoch 17: precision 0.883778,roc 0.973631, loss 0.048783, acc 0, ECE 0 #edges 368460, #graphs 92 time: 106.2473s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 17: precision 0.883778,roc 0.973631, loss 0.048783, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 106.2483s\n",
      "92\n",
      "17\n",
      "0.04993858784751523 0.8982154659616653 loss acc\n",
      "17\n",
      "0.04993858784751523 0.8982154659616653 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.881348,roc 0.972947, loss 0.049939, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 18\n",
      "Parameter containing:\n",
      "tensor([0.7477], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 18: precision 0.886333,roc 0.975404, loss 0.047405, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 18: precision 0.884234,roc 0.974560, loss 0.048451, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 18: precision 0.885984,roc 0.974538, loss 0.047932, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.01 train phase of epoch 18: precision 0.885976,roc 0.974094, loss 0.048377, acc 0, ECE 0 #edges 368460, #graphs 92 time: 105.3392s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 18: precision 0.885976,roc 0.974094, loss 0.048377, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 105.3402s\n",
      "2.0 1.0 FERMI epoch: 19\n",
      "Parameter containing:\n",
      "tensor([0.7358], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 19: precision 0.888680,roc 0.975796, loss 0.046456, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 19: precision 0.889511,roc 0.974283, loss 0.047763, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 19: precision 0.888061,roc 0.974614, loss 0.047677, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.01 train phase of epoch 19: precision 0.889003,roc 0.974597, loss 0.047946, acc 0, ECE 0 #edges 368460, #graphs 92 time: 116.4404s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 19: precision 0.889003,roc 0.974597, loss 0.047946, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 116.4424s\n",
      "92\n",
      "17\n",
      "0.04864383295407539 0.902151722112066 loss acc\n",
      "17\n",
      "0.04864383295407539 0.902151722112066 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.888594,roc 0.974173, loss 0.048644, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 20\n",
      "Parameter containing:\n",
      "tensor([0.7155], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 20: precision 0.887729,roc 0.974724, loss 0.047858, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 20: precision 0.890233,roc 0.974438, loss 0.047779, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 20: precision 0.889657,roc 0.974718, loss 0.047883, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.009000000000000001 train phase of epoch 20: precision 0.891693,roc 0.975067, loss 0.047570, acc 0, ECE 0 #edges 368460, #graphs 92 time: 111.9633s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 20: precision 0.891693,roc 0.975067, loss 0.047570, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 111.9643s\n",
      "2.0 1.0 FERMI epoch: 21\n",
      "Parameter containing:\n",
      "tensor([0.7000], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 21: precision 0.895652,roc 0.976040, loss 0.046707, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 21: precision 0.894759,roc 0.975744, loss 0.046917, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 21: precision 0.894724,roc 0.975437, loss 0.047200, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.009000000000000001 train phase of epoch 21: precision 0.894233,roc 0.975523, loss 0.047116, acc 0, ECE 0 #edges 368460, #graphs 92 time: 114.9775s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 21: precision 0.894233,roc 0.975523, loss 0.047116, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 114.9800s\n",
      "92\n",
      "17\n",
      "0.04783518308827256 0.9067929793640302 loss acc\n",
      "17\n",
      "0.04783518308827256 0.9067929793640302 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.893368,roc 0.974970, loss 0.047835, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 22\n",
      "Parameter containing:\n",
      "tensor([0.6829], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 22: precision 0.891980,roc 0.973804, loss 0.048129, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 22: precision 0.893571,roc 0.974700, loss 0.047761, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 22: precision 0.895480,roc 0.975465, loss 0.047028, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.009000000000000001 train phase of epoch 22: precision 0.896978,roc 0.975892, loss 0.046776, acc 0, ECE 0 #edges 368460, #graphs 92 time: 150.9351s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 22: precision 0.896978,roc 0.975892, loss 0.046776, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 150.9371s\n",
      "2.0 1.0 FERMI epoch: 23\n",
      "Parameter containing:\n",
      "tensor([0.6708], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 23: precision 0.895156,roc 0.977469, loss 0.046458, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 23: precision 0.896978,roc 0.976295, loss 0.046899, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 23: precision 0.898984,roc 0.976603, loss 0.046428, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.009000000000000001 train phase of epoch 23: precision 0.900003,roc 0.976493, loss 0.046423, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.1540s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 23: precision 0.900003,roc 0.976493, loss 0.046423, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.1560s\n",
      "92\n",
      "17\n",
      "0.04748959816703681 0.9143570536828963 loss acc\n",
      "17\n",
      "0.04748959816703681 0.9143570536828963 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.899728,roc 0.975617, loss 0.047490, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 24\n",
      "Parameter containing:\n",
      "tensor([0.6587], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 24: precision 0.899756,roc 0.977181, loss 0.046668, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 24: precision 0.902707,roc 0.976926, loss 0.046371, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 24: precision 0.902899,roc 0.977016, loss 0.046148, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.009000000000000001 train phase of epoch 24: precision 0.902331,roc 0.976869, loss 0.046285, acc 0, ECE 0 #edges 368460, #graphs 92 time: 194.9760s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 24: precision 0.902331,roc 0.976869, loss 0.046285, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 194.9790s\n",
      "2.0 1.0 FERMI epoch: 25\n",
      "Parameter containing:\n",
      "tensor([0.6377], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 25: precision 0.910921,roc 0.978239, loss 0.044120, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 25: precision 0.906037,roc 0.977229, loss 0.045205, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 25: precision 0.905954,roc 0.977364, loss 0.045642, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.009000000000000001 train phase of epoch 25: precision 0.905773,roc 0.977451, loss 0.045686, acc 0, ECE 0 #edges 368460, #graphs 92 time: 194.1058s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 25: precision 0.905773,roc 0.977451, loss 0.045686, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 194.1078s\n",
      "92\n",
      "17\n",
      "0.04620478201743678 0.9100242344128663 loss acc\n",
      "17\n",
      "0.04620478201743678 0.9100242344128663 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.906475,roc 0.977178, loss 0.046205, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 26\n",
      "Parameter containing:\n",
      "tensor([0.6261], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 26: precision 0.904518,roc 0.977033, loss 0.045477, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 26: precision 0.905234,roc 0.977424, loss 0.045676, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 26: precision 0.908710,roc 0.977920, loss 0.045216, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.009000000000000001 train phase of epoch 26: precision 0.908140,roc 0.977806, loss 0.045692, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.0946s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 26: precision 0.908140,roc 0.977806, loss 0.045692, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.0966s\n",
      "2.0 1.0 FERMI epoch: 27\n",
      "Parameter containing:\n",
      "tensor([0.6020], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 27: precision 0.908990,roc 0.977880, loss 0.046294, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 27: precision 0.911053,roc 0.978490, loss 0.045294, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 27: precision 0.910644,roc 0.978485, loss 0.045190, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.009000000000000001 train phase of epoch 27: precision 0.910550,roc 0.978284, loss 0.045319, acc 0, ECE 0 #edges 368460, #graphs 92 time: 183.8317s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 27: precision 0.910550,roc 0.978284, loss 0.045319, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 183.8337s\n",
      "92\n",
      "17\n",
      "0.045530563027853486 0.9130058015715649 loss acc\n",
      "17\n",
      "0.045530563027853486 0.9130058015715649 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.911966,roc 0.978023, loss 0.045531, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 28\n",
      "Parameter containing:\n",
      "tensor([0.6043], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 28: precision 0.915439,roc 0.979393, loss 0.043927, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 28: precision 0.911513,roc 0.978703, loss 0.045030, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 28: precision 0.913119,roc 0.978655, loss 0.045106, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.009000000000000001 train phase of epoch 28: precision 0.913385,roc 0.978777, loss 0.044927, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.6294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 28: precision 0.913385,roc 0.978777, loss 0.044927, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.6314s\n",
      "2.0 1.0 FERMI epoch: 29\n",
      "Parameter containing:\n",
      "tensor([0.5810], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 29: precision 0.909261,roc 0.979071, loss 0.044028, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 29: precision 0.914359,roc 0.979179, loss 0.044119, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 29: precision 0.915985,roc 0.979441, loss 0.043961, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.009000000000000001 train phase of epoch 29: precision 0.916275,roc 0.979367, loss 0.044101, acc 0, ECE 0 #edges 368460, #graphs 92 time: 192.5224s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 29: precision 0.916275,roc 0.979367, loss 0.044101, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 192.5244s\n",
      "92\n",
      "17\n",
      "0.04454582902484552 0.914401116251744 loss acc\n",
      "17\n",
      "0.04454582902484552 0.914401116251744 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.917051,roc 0.979156, loss 0.044546, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 30\n",
      "Parameter containing:\n",
      "tensor([0.5781], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 30: precision 0.922764,roc 0.981120, loss 0.042159, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 30: precision 0.919673,roc 0.980066, loss 0.043360, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 30: precision 0.919122,roc 0.979846, loss 0.043605, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.009000000000000001 train phase of epoch 30: precision 0.918930,roc 0.979867, loss 0.043679, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.1555s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 30: precision 0.918930,roc 0.979867, loss 0.043679, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.1575s\n",
      "2.0 1.0 FERMI epoch: 31\n",
      "Parameter containing:\n",
      "tensor([0.5609], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 31: precision 0.924079,roc 0.980207, loss 0.042720, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 31: precision 0.922337,roc 0.980764, loss 0.042820, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 31: precision 0.918881,roc 0.979962, loss 0.043672, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.009000000000000001 train phase of epoch 31: precision 0.920127,roc 0.980070, loss 0.043692, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.7801s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 31: precision 0.920127,roc 0.980070, loss 0.043692, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.7801s\n",
      "92\n",
      "17\n",
      "0.04392114537779484 0.9113461114782992 loss acc\n",
      "17\n",
      "0.04392114537779484 0.9113461114782992 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.921118,roc 0.980075, loss 0.043921, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 32\n",
      "Parameter containing:\n",
      "tensor([0.5511], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 32: precision 0.923120,roc 0.980892, loss 0.042786, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 32: precision 0.923071,roc 0.981004, loss 0.042366, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 32: precision 0.924030,roc 0.980593, loss 0.042860, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.009000000000000001 train phase of epoch 32: precision 0.922659,roc 0.980624, loss 0.042948, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.9975s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 32: precision 0.922659,roc 0.980624, loss 0.042948, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.9975s\n",
      "2.0 1.0 FERMI epoch: 33\n",
      "Parameter containing:\n",
      "tensor([0.5350], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 33: precision 0.924912,roc 0.980917, loss 0.042355, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 33: precision 0.925085,roc 0.980764, loss 0.042636, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 33: precision 0.923933,roc 0.980662, loss 0.042937, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.009000000000000001 train phase of epoch 33: precision 0.924076,roc 0.981009, loss 0.042865, acc 0, ECE 0 #edges 368460, #graphs 92 time: 185.1427s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 33: precision 0.924076,roc 0.981009, loss 0.042865, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 185.1447s\n",
      "92\n",
      "17\n",
      "0.04353187710470605 0.9225673790115297 loss acc\n",
      "17\n",
      "0.04353187710470605 0.9225673790115297 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.925423,roc 0.980363, loss 0.043532, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 34\n",
      "Parameter containing:\n",
      "tensor([0.5385], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 34: precision 0.922952,roc 0.981048, loss 0.042902, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 34: precision 0.926140,roc 0.981621, loss 0.042147, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 34: precision 0.925350,roc 0.981267, loss 0.042242, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.009000000000000001 train phase of epoch 34: precision 0.926517,roc 0.981510, loss 0.042211, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.3663s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 34: precision 0.926517,roc 0.981510, loss 0.042211, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.3683s\n",
      "2.0 1.0 FERMI epoch: 35\n",
      "Parameter containing:\n",
      "tensor([0.5156], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 35: precision 0.926628,roc 0.981654, loss 0.042390, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 35: precision 0.928559,roc 0.982262, loss 0.041619, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 35: precision 0.928896,roc 0.982057, loss 0.041701, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.009000000000000001 train phase of epoch 35: precision 0.929303,roc 0.982099, loss 0.041819, acc 0, ECE 0 #edges 368460, #graphs 92 time: 177.7176s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 35: precision 0.929303,roc 0.982099, loss 0.041819, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 177.7176s\n",
      "92\n",
      "17\n",
      "0.041795259403757584 0.9197473746052729 loss acc\n",
      "17\n",
      "0.041795259403757584 0.9197473746052729 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.932823,roc 0.982057, loss 0.041795, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 36\n",
      "Parameter containing:\n",
      "tensor([0.5095], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 36: precision 0.934039,roc 0.983108, loss 0.041282, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 36: precision 0.934435,roc 0.983376, loss 0.041063, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 36: precision 0.934637,roc 0.983060, loss 0.041133, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.009000000000000001 train phase of epoch 36: precision 0.935008,roc 0.982972, loss 0.041033, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.9386s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 36: precision 0.935008,roc 0.982972, loss 0.041033, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.9386s\n",
      "2.0 1.0 FERMI epoch: 37\n",
      "Parameter containing:\n",
      "tensor([0.5048], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 37: precision 0.942600,roc 0.983104, loss 0.041121, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 37: precision 0.940593,roc 0.983535, loss 0.040468, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 37: precision 0.939374,roc 0.983715, loss 0.040194, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.009000000000000001 train phase of epoch 37: precision 0.938815,roc 0.983666, loss 0.040413, acc 0, ECE 0 #edges 368460, #graphs 92 time: 177.8983s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 37: precision 0.938815,roc 0.983666, loss 0.040413, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 177.8983s\n",
      "92\n",
      "17\n",
      "0.04157253349426476 0.9062054784460604 loss acc\n",
      "17\n",
      "0.04157253349426476 0.9062054784460604 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.939260,roc 0.983574, loss 0.041573, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 38\n",
      "Parameter containing:\n",
      "tensor([0.4867], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 38: precision 0.942415,roc 0.983618, loss 0.040066, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 38: precision 0.942045,roc 0.983996, loss 0.040221, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 38: precision 0.940361,roc 0.983935, loss 0.040129, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.009000000000000001 train phase of epoch 38: precision 0.940349,roc 0.984009, loss 0.039891, acc 0, ECE 0 #edges 368460, #graphs 92 time: 185.7487s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 38: precision 0.940349,roc 0.984009, loss 0.039891, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 185.7507s\n",
      "2.0 1.0 FERMI epoch: 39\n",
      "Parameter containing:\n",
      "tensor([0.4847], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 39: precision 0.942910,roc 0.984970, loss 0.039264, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 39: precision 0.941430,roc 0.984382, loss 0.039468, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 39: precision 0.940619,roc 0.983949, loss 0.040033, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.009000000000000001 train phase of epoch 39: precision 0.941180,roc 0.984237, loss 0.039728, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.2850s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 39: precision 0.941180,roc 0.984237, loss 0.039728, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.2850s\n",
      "92\n",
      "17\n",
      "0.03994758618165685 0.918087684512007 loss acc\n",
      "17\n",
      "0.03994758618165685 0.918087684512007 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.941157,roc 0.983937, loss 0.039948, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 40\n",
      "Parameter containing:\n",
      "tensor([0.4851], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 40: precision 0.939728,roc 0.984737, loss 0.039920, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 40: precision 0.942193,roc 0.984230, loss 0.039630, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 40: precision 0.943099,roc 0.984475, loss 0.039490, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.008100000000000001 train phase of epoch 40: precision 0.942126,roc 0.984439, loss 0.039428, acc 0, ECE 0 #edges 368460, #graphs 92 time: 190.9950s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 40: precision 0.942126,roc 0.984439, loss 0.039428, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 190.9970s\n",
      "2.0 1.0 FERMI epoch: 41\n",
      "Parameter containing:\n",
      "tensor([0.4790], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 41: precision 0.936755,roc 0.983735, loss 0.040104, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 41: precision 0.941238,roc 0.984279, loss 0.039607, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 41: precision 0.942013,roc 0.984363, loss 0.039452, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.008100000000000001 train phase of epoch 41: precision 0.942613,roc 0.984496, loss 0.039206, acc 0, ECE 0 #edges 368460, #graphs 92 time: 185.9055s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 41: precision 0.942613,roc 0.984496, loss 0.039206, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 185.9075s\n",
      "92\n",
      "17\n",
      "0.03951276263316401 0.9244473819490342 loss acc\n",
      "17\n",
      "0.03951276263316401 0.9244473819490342 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.941971,roc 0.984132, loss 0.039513, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 42\n",
      "Parameter containing:\n",
      "tensor([0.4761], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 42: precision 0.942236,roc 0.984617, loss 0.038767, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 42: precision 0.943473,roc 0.985030, loss 0.038301, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 42: precision 0.943537,roc 0.984855, loss 0.038611, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.008100000000000001 train phase of epoch 42: precision 0.943390,roc 0.984689, loss 0.039057, acc 0, ECE 0 #edges 368460, #graphs 92 time: 191.6019s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 42: precision 0.943390,roc 0.984689, loss 0.039057, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 191.6039s\n",
      "2.0 1.0 FERMI epoch: 43\n",
      "Parameter containing:\n",
      "tensor([0.4708], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 43: precision 0.943873,roc 0.985465, loss 0.037891, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 43: precision 0.943800,roc 0.984336, loss 0.039468, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 43: precision 0.943403,roc 0.984439, loss 0.039418, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.008100000000000001 train phase of epoch 43: precision 0.943828,roc 0.984776, loss 0.039152, acc 0, ECE 0 #edges 368460, #graphs 92 time: 193.3443s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 43: precision 0.943828,roc 0.984776, loss 0.039152, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 193.3453s\n",
      "92\n",
      "17\n",
      "0.03918591608747612 0.9243592568113389 loss acc\n",
      "17\n",
      "0.03918591608747612 0.9243592568113389 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.943109,roc 0.984346, loss 0.039186, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 44\n",
      "Parameter containing:\n",
      "tensor([0.4700], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 44: precision 0.942912,roc 0.983811, loss 0.039164, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 44: precision 0.944784,roc 0.984853, loss 0.038466, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 44: precision 0.943612,roc 0.984918, loss 0.038549, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.008100000000000001 train phase of epoch 44: precision 0.944434,roc 0.984901, loss 0.038739, acc 0, ECE 0 #edges 368460, #graphs 92 time: 181.6656s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 44: precision 0.944434,roc 0.984901, loss 0.038739, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 181.6686s\n",
      "2.0 1.0 FERMI epoch: 45\n",
      "Parameter containing:\n",
      "tensor([0.4624], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 45: precision 0.944816,roc 0.985795, loss 0.037991, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 45: precision 0.944869,roc 0.985541, loss 0.038337, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 45: precision 0.945699,roc 0.985145, loss 0.038460, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.008100000000000001 train phase of epoch 45: precision 0.945014,roc 0.985016, loss 0.038586, acc 0, ECE 0 #edges 368460, #graphs 92 time: 195.0405s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 45: precision 0.945014,roc 0.985016, loss 0.038586, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 195.0425s\n",
      "92\n",
      "17\n",
      "0.03905602759990398 0.9256811338767719 loss acc\n",
      "17\n",
      "0.03905602759990398 0.9256811338767719 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.943636,roc 0.984452, loss 0.039056, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 46\n",
      "Parameter containing:\n",
      "tensor([0.4639], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 46: precision 0.946963,roc 0.984706, loss 0.038506, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 46: precision 0.945243,roc 0.984925, loss 0.038592, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 46: precision 0.944523,roc 0.984962, loss 0.038828, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0047 lr: 0.008100000000000001 train phase of epoch 46: precision 0.945333,roc 0.985112, loss 0.038530, acc 0, ECE 0 #edges 368460, #graphs 92 time: 187.8212s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 46: precision 0.945333,roc 0.985112, loss 0.038530, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 187.8232s\n",
      "2.0 1.0 FERMI epoch: 47\n",
      "Parameter containing:\n",
      "tensor([0.4527], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 47: precision 0.944262,roc 0.985153, loss 0.038229, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 47: precision 0.946145,roc 0.985246, loss 0.037986, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 47: precision 0.945905,roc 0.985322, loss 0.038198, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0048 lr: 0.008100000000000001 train phase of epoch 47: precision 0.945920,roc 0.985225, loss 0.038363, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.0750s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 47: precision 0.945920,roc 0.985225, loss 0.038363, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.0770s\n",
      "92\n",
      "17\n",
      "0.039125012140183456 0.9202467503855474 loss acc\n",
      "17\n",
      "0.039125012140183456 0.9202467503855474 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0048 dev phase of epoch 47: precision 0.944232,roc 0.984558, loss 0.039125, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 48\n",
      "Parameter containing:\n",
      "tensor([0.4534], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 48: precision 0.946620,roc 0.985344, loss 0.038132, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 48: precision 0.945845,roc 0.984921, loss 0.038571, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 48: precision 0.945881,roc 0.985130, loss 0.038528, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0049 lr: 0.008100000000000001 train phase of epoch 48: precision 0.946188,roc 0.985282, loss 0.038291, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.7148s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 48: precision 0.946188,roc 0.985282, loss 0.038291, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.7168s\n",
      "2.0 1.0 FERMI epoch: 49\n",
      "Parameter containing:\n",
      "tensor([0.4585], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 49: precision 0.949851,roc 0.986868, loss 0.036883, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 49: precision 0.948943,roc 0.985676, loss 0.038142, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 49: precision 0.947506,roc 0.985594, loss 0.037903, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0050 lr: 0.008100000000000001 train phase of epoch 49: precision 0.946221,roc 0.985234, loss 0.038402, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.7563s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 49: precision 0.946221,roc 0.985234, loss 0.038402, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.7589s\n",
      "92\n",
      "17\n",
      "0.04013744848601219 0.9331570830579424 loss acc\n",
      "17\n",
      "0.04013744848601219 0.9331570830579424 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0050 dev phase of epoch 49: precision 0.943327,roc 0.984056, loss 0.040137, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 50\n",
      "Parameter containing:\n",
      "tensor([0.4658], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 50: precision 0.945682,roc 0.985385, loss 0.038357, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 50: precision 0.945112,roc 0.985400, loss 0.038297, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0322, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 50: precision 0.946707,roc 0.985446, loss 0.038343, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0051 lr: 0.008100000000000001 train phase of epoch 50: precision 0.946732,roc 0.985385, loss 0.038321, acc 0, ECE 0 #edges 368460, #graphs 92 time: 182.4683s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 50: precision 0.946732,roc 0.985385, loss 0.038321, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 182.4723s\n",
      "2.0 1.0 FERMI epoch: 51\n",
      "Parameter containing:\n",
      "tensor([0.4557], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0322, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 51: precision 0.946808,roc 0.985808, loss 0.037968, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0322, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 51: precision 0.947543,roc 0.985779, loss 0.037669, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 51: precision 0.947111,roc 0.985640, loss 0.037889, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0052 lr: 0.008100000000000001 train phase of epoch 51: precision 0.947255,roc 0.985494, loss 0.038036, acc 0, ECE 0 #edges 368460, #graphs 92 time: 189.7176s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 51: precision 0.947255,roc 0.985494, loss 0.038036, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 189.7196s\n",
      "92\n",
      "17\n",
      "0.038949074363760744 0.9297789527796138 loss acc\n",
      "17\n",
      "0.038949074363760744 0.9297789527796138 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0052 dev phase of epoch 51: precision 0.944710,roc 0.984565, loss 0.038949, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 52\n",
      "Parameter containing:\n",
      "tensor([0.4594], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 52: precision 0.947170,roc 0.985286, loss 0.038013, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 52: precision 0.947376,roc 0.985153, loss 0.038379, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0319, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 52: precision 0.947522,roc 0.985664, loss 0.038118, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0053 lr: 0.008100000000000001 train phase of epoch 52: precision 0.947401,roc 0.985544, loss 0.038110, acc 0, ECE 0 #edges 368460, #graphs 92 time: 208.7599s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 52: precision 0.947401,roc 0.985544, loss 0.038110, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 208.7599s\n",
      "2.0 1.0 FERMI epoch: 53\n",
      "Parameter containing:\n",
      "tensor([0.4452], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 53: precision 0.948153,roc 0.984996, loss 0.038555, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 53: precision 0.948462,roc 0.985810, loss 0.037853, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0317, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 53: precision 0.948522,roc 0.985454, loss 0.038077, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0054 lr: 0.008100000000000001 train phase of epoch 53: precision 0.947608,roc 0.985564, loss 0.038010, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.5579s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 53: precision 0.947608,roc 0.985564, loss 0.038010, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.5600s\n",
      "92\n",
      "17\n",
      "0.039119868762187364 0.9308805170008079 loss acc\n",
      "17\n",
      "0.039119868762187364 0.9308805170008079 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0054 dev phase of epoch 53: precision 0.945094,roc 0.984501, loss 0.039120, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 54\n",
      "Parameter containing:\n",
      "tensor([0.4619], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 54: precision 0.947992,roc 0.985709, loss 0.038111, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 54: precision 0.947549,roc 0.985357, loss 0.038618, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 54: precision 0.948261,roc 0.985612, loss 0.038135, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0055 lr: 0.008100000000000001 train phase of epoch 54: precision 0.947654,roc 0.985539, loss 0.038083, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.4995s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 54: precision 0.947654,roc 0.985539, loss 0.038083, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.4995s\n",
      "2.0 1.0 FERMI epoch: 55\n",
      "Parameter containing:\n",
      "tensor([0.4493], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 55: precision 0.949535,roc 0.985842, loss 0.037077, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 55: precision 0.947685,roc 0.985561, loss 0.037675, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 55: precision 0.948620,roc 0.985877, loss 0.037700, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0056 lr: 0.008100000000000001 train phase of epoch 55: precision 0.948192,roc 0.985717, loss 0.037925, acc 0, ECE 0 #edges 368460, #graphs 92 time: 183.1595s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 55: precision 0.948192,roc 0.985717, loss 0.037925, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 183.1595s\n",
      "92\n",
      "17\n",
      "0.03861870704221061 0.9308217669090108 loss acc\n",
      "17\n",
      "0.03861870704221061 0.9308217669090108 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0056 dev phase of epoch 55: precision 0.946040,roc 0.984857, loss 0.038619, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 56\n",
      "Parameter containing:\n",
      "tensor([0.4614], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 56: precision 0.948144,roc 0.984594, loss 0.038796, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 56: precision 0.947021,roc 0.985217, loss 0.038269, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 56: precision 0.948184,roc 0.985484, loss 0.037816, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0319, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0057 lr: 0.008100000000000001 train phase of epoch 56: precision 0.948401,roc 0.985777, loss 0.037613, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.7487s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 56: precision 0.948401,roc 0.985777, loss 0.037613, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.7507s\n",
      "2.0 1.0 FERMI epoch: 57\n",
      "Parameter containing:\n",
      "tensor([0.4529], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 57: precision 0.945892,roc 0.985064, loss 0.038659, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 57: precision 0.947052,roc 0.985574, loss 0.038233, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 57: precision 0.947319,roc 0.985500, loss 0.038120, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0316, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0314, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0058 lr: 0.008100000000000001 train phase of epoch 57: precision 0.948572,roc 0.985768, loss 0.037684, acc 0, ECE 0 #edges 368460, #graphs 92 time: 208.2433s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 57: precision 0.948572,roc 0.985768, loss 0.037684, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 208.2443s\n",
      "92\n",
      "17\n",
      "0.03840006533530795 0.9217595652493208 loss acc\n",
      "17\n",
      "0.03840006533530795 0.9217595652493208 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0058 dev phase of epoch 57: precision 0.946579,roc 0.985070, loss 0.038400, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 58\n",
      "Parameter containing:\n",
      "tensor([0.4510], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 58: precision 0.948708,roc 0.986228, loss 0.037777, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0317, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 58: precision 0.947358,roc 0.985115, loss 0.038418, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 58: precision 0.948326,roc 0.985545, loss 0.038002, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0059 lr: 0.008100000000000001 train phase of epoch 58: precision 0.948577,roc 0.985800, loss 0.037753, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.8449s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 58: precision 0.948577,roc 0.985800, loss 0.037753, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.8449s\n",
      "2.0 1.0 FERMI epoch: 59\n",
      "Parameter containing:\n",
      "tensor([0.4484], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 59: precision 0.951770,roc 0.985886, loss 0.038081, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 59: precision 0.949253,roc 0.985886, loss 0.037802, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0312, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0320, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 59: precision 0.948957,roc 0.985882, loss 0.037510, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0060 lr: 0.008100000000000001 train phase of epoch 59: precision 0.949054,roc 0.985882, loss 0.037525, acc 0, ECE 0 #edges 368460, #graphs 92 time: 184.2173s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 59: precision 0.949054,roc 0.985882, loss 0.037525, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 184.2184s\n",
      "92\n",
      "17\n",
      "0.03876110381446178 0.9162958067121981 loss acc\n",
      "17\n",
      "0.03876110381446178 0.9162958067121981 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0060 dev phase of epoch 59: precision 0.946804,roc 0.985053, loss 0.038761, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 60\n",
      "Parameter containing:\n",
      "tensor([0.4482], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 60: precision 0.949645,roc 0.986250, loss 0.036997, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0312, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 60: precision 0.950071,roc 0.986434, loss 0.036869, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0314, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 60: precision 0.949720,roc 0.986186, loss 0.037004, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0061 lr: 0.007290000000000001 train phase of epoch 60: precision 0.949122,roc 0.985906, loss 0.037573, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.8602s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 60: precision 0.949122,roc 0.985906, loss 0.037573, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.8613s\n",
      "2.0 1.0 FERMI epoch: 61\n",
      "Parameter containing:\n",
      "tensor([0.4542], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 61: precision 0.952082,roc 0.986894, loss 0.037278, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0421, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 61: precision 0.950515,roc 0.985990, loss 0.037598, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0317, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 61: precision 0.949447,roc 0.986127, loss 0.037323, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0062 lr: 0.007290000000000001 train phase of epoch 61: precision 0.949373,roc 0.985988, loss 0.037546, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.2717s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 61: precision 0.949373,roc 0.985988, loss 0.037546, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.2717s\n",
      "92\n",
      "17\n",
      "0.03824905744508986 0.9198208122200192 loss acc\n",
      "17\n",
      "0.03824905744508986 0.9198208122200192 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0062 dev phase of epoch 61: precision 0.947218,roc 0.985251, loss 0.038249, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 62\n",
      "Parameter containing:\n",
      "tensor([0.4535], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0312, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 62: precision 0.952868,roc 0.986531, loss 0.036885, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 62: precision 0.950275,roc 0.985836, loss 0.037648, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0317, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 62: precision 0.948893,roc 0.985832, loss 0.037801, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0063 lr: 0.007290000000000001 train phase of epoch 62: precision 0.949356,roc 0.985964, loss 0.037429, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.5146s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 62: precision 0.949356,roc 0.985964, loss 0.037429, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.5156s\n",
      "2.0 1.0 FERMI epoch: 63\n",
      "Parameter containing:\n",
      "tensor([0.4600], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 63: precision 0.947990,roc 0.985979, loss 0.037348, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0316, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 63: precision 0.949298,roc 0.986294, loss 0.037165, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0309, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 63: precision 0.949401,roc 0.985862, loss 0.037395, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0064 lr: 0.007290000000000001 train phase of epoch 63: precision 0.949563,roc 0.986010, loss 0.037422, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.4669s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 63: precision 0.949563,roc 0.986010, loss 0.037422, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.4689s\n",
      "92\n",
      "17\n",
      "0.03819896184553358 0.9206726885510759 loss acc\n",
      "17\n",
      "0.03819896184553358 0.9206726885510759 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0064 dev phase of epoch 63: precision 0.947384,roc 0.985251, loss 0.038199, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 64\n",
      "Parameter containing:\n",
      "tensor([0.4559], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0313, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0308, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 64: precision 0.951356,roc 0.986274, loss 0.036927, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 64: precision 0.949308,roc 0.985676, loss 0.037511, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 64: precision 0.949513,roc 0.985741, loss 0.037413, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0065 lr: 0.007290000000000001 train phase of epoch 64: precision 0.949739,roc 0.986052, loss 0.037332, acc 0, ECE 0 #edges 368460, #graphs 92 time: 186.3812s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 64: precision 0.949739,roc 0.986052, loss 0.037332, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 186.3822s\n",
      "2.0 1.0 FERMI epoch: 65\n",
      "Parameter containing:\n",
      "tensor([0.4549], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0433, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 65: precision 0.948513,roc 0.985944, loss 0.037981, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0425, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 65: precision 0.949287,roc 0.985938, loss 0.037617, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0400, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0313, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 65: precision 0.949086,roc 0.986067, loss 0.037408, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0326, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0066 lr: 0.007290000000000001 train phase of epoch 65: precision 0.949794,roc 0.986062, loss 0.037283, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.4392s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 65: precision 0.949794,roc 0.986062, loss 0.037283, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.4412s\n",
      "92\n",
      "17\n",
      "0.037880133011720954 0.9238451935081148 loss acc\n",
      "17\n",
      "0.037880133011720954 0.9238451935081148 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0066 dev phase of epoch 65: precision 0.947919,roc 0.985340, loss 0.037880, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 66\n",
      "Parameter containing:\n",
      "tensor([0.4636], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0310, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 66: precision 0.949202,roc 0.986757, loss 0.036205, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0322, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 66: precision 0.950016,roc 0.986490, loss 0.036616, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0415, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 66: precision 0.950395,roc 0.986120, loss 0.037120, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0067 lr: 0.007290000000000001 train phase of epoch 66: precision 0.949907,roc 0.986110, loss 0.037206, acc 0, ECE 0 #edges 368460, #graphs 92 time: 177.9370s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 66: precision 0.949907,roc 0.986110, loss 0.037206, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 177.9390s\n",
      "2.0 1.0 FERMI epoch: 67\n",
      "Parameter containing:\n",
      "tensor([0.4736], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0312, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0316, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 67: precision 0.948802,roc 0.986870, loss 0.036919, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0322, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 67: precision 0.948725,roc 0.986111, loss 0.037301, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0399, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 67: precision 0.949414,roc 0.986281, loss 0.037110, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0428, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0068 lr: 0.007290000000000001 train phase of epoch 67: precision 0.949999,roc 0.986101, loss 0.037207, acc 0, ECE 0 #edges 368460, #graphs 92 time: 177.6550s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 67: precision 0.949999,roc 0.986101, loss 0.037207, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 177.6550s\n",
      "92\n",
      "17\n",
      "0.037971687686429556 0.9271058236028493 loss acc\n",
      "17\n",
      "0.037971687686429556 0.9271058236028493 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0068 dev phase of epoch 67: precision 0.947810,roc 0.985207, loss 0.037972, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 68\n",
      "Parameter containing:\n",
      "tensor([0.4747], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0342, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0387, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 68: precision 0.952291,roc 0.985612, loss 0.037557, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0427, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 68: precision 0.951719,roc 0.986150, loss 0.037185, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0430, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 68: precision 0.950072,roc 0.986076, loss 0.037244, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0323, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0069 lr: 0.007290000000000001 train phase of epoch 68: precision 0.950072,roc 0.986128, loss 0.037228, acc 0, ECE 0 #edges 368460, #graphs 92 time: 186.9547s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 68: precision 0.950072,roc 0.986128, loss 0.037228, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 186.9547s\n",
      "2.0 1.0 FERMI epoch: 69\n",
      "Parameter containing:\n",
      "tensor([0.4690], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 69: precision 0.948630,roc 0.985369, loss 0.037994, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0405, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0309, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 69: precision 0.949162,roc 0.985773, loss 0.037302, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0419, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0341, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 69: precision 0.950581,roc 0.985893, loss 0.037342, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0335, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0070 lr: 0.007290000000000001 train phase of epoch 69: precision 0.950313,roc 0.986210, loss 0.037100, acc 0, ECE 0 #edges 368460, #graphs 92 time: 178.2819s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 69: precision 0.950313,roc 0.986210, loss 0.037100, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 178.2819s\n",
      "92\n",
      "17\n",
      "0.0380835641846583 0.918381434970992 loss acc\n",
      "17\n",
      "0.0380835641846583 0.918381434970992 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0070 dev phase of epoch 69: precision 0.948348,roc 0.985433, loss 0.038084, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 70\n",
      "Parameter containing:\n",
      "tensor([0.4682], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0388, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0386, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 70: precision 0.949406,roc 0.986606, loss 0.036347, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0354, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0411, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0398, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0333, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 70: precision 0.950291,roc 0.986453, loss 0.036651, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0417, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0402, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0377, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0376, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0369, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0394, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 70: precision 0.949935,roc 0.986225, loss 0.037202, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0346, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0311, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0071 lr: 0.007290000000000001 train phase of epoch 70: precision 0.950382,roc 0.986208, loss 0.037123, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.5704s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 70: precision 0.950382,roc 0.986208, loss 0.037123, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.5714s\n",
      "2.0 1.0 FERMI epoch: 71\n",
      "Parameter containing:\n",
      "tensor([0.4759], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0385, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0414, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0403, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0379, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0339, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0364, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0353, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0337, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0355, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0373, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 71: precision 0.950159,roc 0.987057, loss 0.036258, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0356, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0331, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0407, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0306, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0451, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0393, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0426, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0432, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0401, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0313, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 71: precision 0.949881,roc 0.985946, loss 0.037317, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0413, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0368, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0314, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0378, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0321, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0418, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0391, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0374, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0381, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0330, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0409, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 71: precision 0.949759,roc 0.986013, loss 0.037418, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0390, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0362, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0360, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0357, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0352, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0363, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0392, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0382, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0343, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0370, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0072 lr: 0.007290000000000001 train phase of epoch 71: precision 0.950383,roc 0.986196, loss 0.037204, acc 0, ECE 0 #edges 368460, #graphs 92 time: 179.2385s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0358, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 71: precision 0.950383,roc 0.986196, loss 0.037204, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 179.2405s\n",
      "92\n",
      "17\n",
      "0.03799845705118001 0.9196592494675775 loss acc\n",
      "17\n",
      "0.03799845705118001 0.9196592494675775 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0072 dev phase of epoch 71: precision 0.948373,roc 0.985467, loss 0.037998, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 13553.2595s\n",
      "INFO:root:Val set results: dev phase of epoch 65: precision 0.947919,roc 0.985340, loss 0.037880, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Test set results: test phase of epoch 65: precision 0.947868,roc 0.985660, loss 0.037822, acc 0, ECE 0 #edges 284355, #graphs 71\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\0\n",
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "{'prefix': 'dev', 'epoch': 65, 'loss': 0.037880133011720954, 'roc': 0.9853403456312748, 'ap': 0.9479192779851128, 'acc': 0.9238451935081148, 'ECE': 0.0}\n",
      "0.037880133011720954 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq study directory!\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\1', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113]\n",
      "92 17 71 lengths\n",
      "180 unique lenths\n",
      "92 17 71 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113], 'test': [166, 126, 100, 118, 112, 162, 143, 158, 170, 168, 136, 111, 95, 155, 153, 174, 97, 152, 149, 104, 165, 169, 163, 137, 127, 138, 161, 154, 159, 119, 129, 94, 105, 109, 157, 99, 142, 146, 131, 178, 139, 151, 93, 150, 121, 132, 177, 175, 167, 140, 122, 141, 145, 179, 134, 123, 103, 101, 96, 125, 124, 156, 172, 133, 160, 116, 114, 106, 176, 92, 147], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "92 71 17 length\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113], 'test': [166, 126, 100, 118, 112, 162, 143, 158, 170, 168, 136, 111, 95, 155, 153, 174, 97, 152, 149, 104, 165, 169, 163, 137, 127, 138, 161, 154, 159, 119, 129, 94, 105, 109, 157, 99, 142, 146, 131, 178, 139, 151, 93, 150, 121, 132, 177, 175, 167, 140, 122, 141, 145, 179, 134, 123, 103, 101, 96, 125, 124, 156, 172, 133, 160, 116, 114, 106, 176, 92, 147], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '98', '102', '107', '108', '110', '113', '115', '117', '120', '128', '130', '135', '144', '148', '164', '171', '173', '92', '93', '94', '95', '96', '97', '99', '100', '101', '103', '104', '105', '106', '109', '111', '112', '114', '116', '118', '119', '121', '122', '123', '124', '125', '126', '127', '129', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '145', '146', '147', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '165', '166', '167', '168', '169', '170', '172', '174', '175', '176', '177', '178', '179'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '98', '102', '107', '108', '110', '113', '115', '117', '120', '128', '130', '135', '144', '148', '164', '171', '173', '92', '93', '94', '95', '96', '97', '99', '100', '101', '103', '104', '105', '106', '109', '111', '112', '114', '116', '118', '119', '121', '122', '123', '124', '125', '126', '127', '129', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '145', '146', '147', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '165', '166', '167', '168', '169', '170', '172', '174', '175', '176', '177', '178', '179'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[166, 126, 100, 118, 112, 162, 143, 158, 170, 168, 136, 111, 95, 155, 153, 174, 97, 152, 149, 104, 165, 169, 163, 137, 127, 138, 161, 154, 159, 119, 129, 94, 105, 109, 157, 99, 142, 146, 131, 178, 139, 151, 93, 150, 121, 132, 177, 175, 167, 140, 122, 141, 145, 179, 134, 123, 103, 101, 96, 125, 124, 156, 172, 133, 160, 116, 114, 106, 176, 92, 147] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '98', '102', '107', '108', '110', '113', '115', '117', '120', '128', '130', '135', '144', '148', '164', '171', '173', '92', '93', '94', '95', '96', '97', '99', '100', '101', '103', '104', '105', '106', '109', '111', '112', '114', '116', '118', '119', '121', '122', '123', '124', '125', '126', '127', '129', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '145', '146', '147', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '165', '166', '167', '168', '169', '170', '172', '174', '175', '176', '177', '178', '179'] dta set indices\n",
      "92 71 17\n",
      "-1 ARG FREQ\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [117, 144, 135, 148, 115, 107, 102, 164, 130, 128, 173, 98, 171, 108, 110, 120, 113], 'test': [166, 126, 100, 118, 112, 162, 143, 158, 170, 168, 136, 111, 95, 155, 153, 174, 97, 152, 149, 104, 165, 169, 163, 137, 127, 138, 161, 154, 159, 119, 129, 94, 105, 109, 157, 99, 142, 146, 131, 178, 139, 151, 93, 150, 121, 132, 177, 175, 167, 140, 122, 141, 145, 179, 134, 123, 103, 101, 96, 125, 124, 156, 172, 133, 160, 116, 114, 106, 176, 92, 147], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\1', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS???\n",
      "<class 'models.base_models.LPModel'> MODEL??\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "2.0 1.0 FERMI epoch: 0\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "92 train length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5848, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5251, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4945, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5349, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3916, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3190, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3089, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3011, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 0: precision 0.633021,roc 0.851582, loss 0.451638, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.4200, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4223, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4237, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2979, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2334, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2942, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4034, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2018, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1974, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3375, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3068, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3034, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2086, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2188, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 0: precision 0.553848,roc 0.817579, loss 0.375319, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.2723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3201, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2157, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2173, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2113, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2275, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2071, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2075, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1832, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1956, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1647, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 0: precision 0.565580,roc 0.823189, loss 0.315728, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1424, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1416, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1431, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1404, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1347, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2310, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1288, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1367, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1528, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.01 train phase of epoch 0: precision 0.582205,roc 0.832311, loss 0.275824, acc 0, ECE 0 #edges 368460, #graphs 92 time: 176.2937s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1394, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 0: precision 0.582205,roc 0.832311, loss 0.275824, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 176.2937s\n",
      "2.0 1.0 FERMI epoch: 1\n",
      "Parameter containing:\n",
      "tensor([1.3686], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1297, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1169, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1161, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1155, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1365, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1881, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1394, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1252, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1194, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1389, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1067, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1160, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1136, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1207, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1437, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1556, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 1: precision 0.686371,roc 0.882719, loss 0.136801, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.1278, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1093, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1052, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1174, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1066, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1074, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1380, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1146, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0989, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1009, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0948, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1361, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1211, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1222, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0924, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1190, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1104, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1183, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1002, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 1: precision 0.689396,roc 0.892731, loss 0.124751, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.1091, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0912, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0924, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1146, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0954, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1169, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1024, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1005, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0892, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0994, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0955, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1081, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0910, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0929, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1003, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1102, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1080, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1691, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 1: precision 0.706360,roc 0.900524, loss 0.117625, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0844, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1049, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1158, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1061, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0855, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1196, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0978, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1177, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1182, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0844, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1059, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1087, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.01 train phase of epoch 1: precision 0.718558,roc 0.905626, loss 0.113784, acc 0, ECE 0 #edges 368460, #graphs 92 time: 186.1849s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1524, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 1: precision 0.718558,roc 0.905626, loss 0.113784, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 186.1869s\n",
      "92\n",
      "17\n",
      "0.11339798385481573 0.7400749063670411 loss acc\n",
      "17\n",
      "0.11339798385481573 0.7400749063670411 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.755884,roc 0.924593, loss 0.113398, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 2\n",
      "Parameter containing:\n",
      "tensor([1.3501], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1119, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0863, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1015, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0869, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1080, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0968, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1096, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0950, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0838, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1133, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0832, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1079, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1227, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0864, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 2: precision 0.767868,roc 0.924533, loss 0.093246, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.1204, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1026, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0957, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0906, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1023, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1158, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0821, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0905, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0943, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1290, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0979, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0950, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0874, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1088, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1044, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 2: precision 0.763595,roc 0.924916, loss 0.094571, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0897, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1000, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1241, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0991, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0958, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0846, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0840, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0911, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0864, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0879, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 2: precision 0.762946,roc 0.925390, loss 0.092697, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0976, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0864, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0795, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0934, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1291, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0952, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0976, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0981, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1127, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.01 train phase of epoch 2: precision 0.760634,roc 0.925512, loss 0.091517, acc 0, ECE 0 #edges 368460, #graphs 92 time: 173.4517s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 2: precision 0.760634,roc 0.925512, loss 0.091517, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 173.4517s\n",
      "2.0 1.0 FERMI epoch: 3\n",
      "Parameter containing:\n",
      "tensor([1.3118], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0874, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0913, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0923, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0824, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 3: precision 0.775750,roc 0.932173, loss 0.078389, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0832, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0850, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0903, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0887, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0971, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1061, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 3: precision 0.770895,roc 0.931254, loss 0.080603, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1094, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0870, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0906, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 3: precision 0.773777,roc 0.932094, loss 0.080533, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0948, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0939, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1261, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0881, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.01 train phase of epoch 3: precision 0.773030,roc 0.931955, loss 0.081548, acc 0, ECE 0 #edges 368460, #graphs 92 time: 174.1065s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1304, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 3: precision 0.773030,roc 0.931955, loss 0.081548, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 174.1085s\n",
      "92\n",
      "17\n",
      "0.09419628314020283 0.778541528971139 loss acc\n",
      "17\n",
      "0.09419628314020283 0.778541528971139 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.780550,roc 0.935344, loss 0.094196, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 4\n",
      "Parameter containing:\n",
      "tensor([1.2992], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0910, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0873, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0845, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 4: precision 0.781331,roc 0.936742, loss 0.078516, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0865, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0977, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0930, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 4: precision 0.777942,roc 0.935224, loss 0.078792, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0928, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 4: precision 0.784170,roc 0.936741, loss 0.077484, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0864, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0909, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.01 train phase of epoch 4: precision 0.785105,roc 0.937160, loss 0.077309, acc 0, ECE 0 #edges 368460, #graphs 92 time: 171.4547s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 4: precision 0.785105,roc 0.937160, loss 0.077309, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 171.4567s\n",
      "2.0 1.0 FERMI epoch: 5\n",
      "Parameter containing:\n",
      "tensor([1.2727], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0936, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0806, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0968, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0974, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 5: precision 0.788333,roc 0.939380, loss 0.076852, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0994, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1018, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1096, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 5: precision 0.788919,roc 0.940951, loss 0.077509, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0951, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0942, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 5: precision 0.789772,roc 0.940484, loss 0.077706, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1135, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.01 train phase of epoch 5: precision 0.794214,roc 0.941443, loss 0.075859, acc 0, ECE 0 #edges 368460, #graphs 92 time: 184.4744s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 5: precision 0.794214,roc 0.941443, loss 0.075859, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 184.4744s\n",
      "92\n",
      "17\n",
      "0.09739674111564896 0.7562458691341707 loss acc\n",
      "17\n",
      "0.09739674111564896 0.7562458691341707 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.794653,roc 0.944238, loss 0.097397, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 6\n",
      "Parameter containing:\n",
      "tensor([1.2688], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0978, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0892, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0934, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0877, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0916, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1203, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1115, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1075, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0935, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 6: precision 0.794093,roc 0.941289, loss 0.086602, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.1408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0969, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0946, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1061, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0903, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0869, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 6: precision 0.795601,roc 0.942155, loss 0.083787, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.1026, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0990, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0887, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1102, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0994, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 6: precision 0.797171,roc 0.943082, loss 0.081215, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0922, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.01 train phase of epoch 6: precision 0.800486,roc 0.943853, loss 0.078288, acc 0, ECE 0 #edges 368460, #graphs 92 time: 171.7855s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 6: precision 0.800486,roc 0.943853, loss 0.078288, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 171.7855s\n",
      "2.0 1.0 FERMI epoch: 7\n",
      "Parameter containing:\n",
      "tensor([1.2457], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0924, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1002, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 7: precision 0.798626,roc 0.943046, loss 0.076404, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0871, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 7: precision 0.802956,roc 0.945876, loss 0.073638, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 7: precision 0.806716,roc 0.946288, loss 0.072220, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0954, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1048, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.01 train phase of epoch 7: precision 0.808358,roc 0.946568, loss 0.072203, acc 0, ECE 0 #edges 368460, #graphs 92 time: 174.6489s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 7: precision 0.808358,roc 0.946568, loss 0.072203, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 174.6499s\n",
      "92\n",
      "17\n",
      "0.09424794786900736 0.759726812073144 loss acc\n",
      "17\n",
      "0.09424794786900736 0.759726812073144 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.807800,roc 0.948030, loss 0.094248, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 8\n",
      "Parameter containing:\n",
      "tensor([1.2441], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1007, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0884, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0987, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1060, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0879, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0819, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 8: precision 0.813006,roc 0.949071, loss 0.079640, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0868, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 8: precision 0.815652,roc 0.948069, loss 0.075686, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0990, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 8: precision 0.816254,roc 0.948017, loss 0.073743, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0845, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.01 train phase of epoch 8: precision 0.816002,roc 0.948117, loss 0.072677, acc 0, ECE 0 #edges 368460, #graphs 92 time: 170.3903s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 8: precision 0.816002,roc 0.948117, loss 0.072677, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 170.3903s\n",
      "2.0 1.0 FERMI epoch: 9\n",
      "Parameter containing:\n",
      "tensor([1.2245], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0953, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0922, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0877, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 9: precision 0.824501,roc 0.948670, loss 0.069593, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 9: precision 0.820980,roc 0.949142, loss 0.068443, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0958, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 9: precision 0.821560,roc 0.949333, loss 0.069169, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.01 train phase of epoch 9: precision 0.822503,roc 0.949780, loss 0.067971, acc 0, ECE 0 #edges 368460, #graphs 92 time: 171.0980s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 9: precision 0.822503,roc 0.949780, loss 0.067971, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 171.0980s\n",
      "92\n",
      "17\n",
      "0.0667249743506592 0.8541235220680033 loss acc\n",
      "17\n",
      "0.0667249743506592 0.8541235220680033 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.820847,roc 0.949746, loss 0.066725, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 10\n",
      "Parameter containing:\n",
      "tensor([1.2170], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 10: precision 0.825226,roc 0.950182, loss 0.065334, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 10: precision 0.828075,roc 0.950743, loss 0.065931, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0840, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0821, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 10: precision 0.828176,roc 0.951174, loss 0.066689, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0946, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0958, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.01 train phase of epoch 10: precision 0.827511,roc 0.951115, loss 0.067109, acc 0, ECE 0 #edges 368460, #graphs 92 time: 180.1078s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 10: precision 0.827511,roc 0.951115, loss 0.067109, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 180.1078s\n",
      "2.0 1.0 FERMI epoch: 11\n",
      "Parameter containing:\n",
      "tensor([1.2095], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0934, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 11: precision 0.828874,roc 0.951408, loss 0.067093, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 11: precision 0.828375,roc 0.952728, loss 0.065532, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0819, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1037, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0987, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 11: precision 0.832126,roc 0.952118, loss 0.067496, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0944, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.01 train phase of epoch 11: precision 0.832789,roc 0.952211, loss 0.067115, acc 0, ECE 0 #edges 368460, #graphs 92 time: 172.0436s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 11: precision 0.832789,roc 0.952211, loss 0.067115, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 172.0436s\n",
      "92\n",
      "17\n",
      "0.06495645130146357 0.860233531614893 loss acc\n",
      "17\n",
      "0.06495645130146357 0.860233531614893 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.827811,roc 0.950923, loss 0.064956, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 12\n",
      "Parameter containing:\n",
      "tensor([1.1992], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 12: precision 0.831701,roc 0.953229, loss 0.065063, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 12: precision 0.834520,roc 0.953523, loss 0.063807, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 12: precision 0.833005,roc 0.953616, loss 0.063706, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0832, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0809, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.01 train phase of epoch 12: precision 0.835140,roc 0.953013, loss 0.064606, acc 0, ECE 0 #edges 368460, #graphs 92 time: 173.7715s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0800, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 12: precision 0.835140,roc 0.953013, loss 0.064606, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 173.7735s\n",
      "2.0 1.0 FERMI epoch: 13\n",
      "Parameter containing:\n",
      "tensor([1.1885], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 13: precision 0.833045,roc 0.954419, loss 0.067351, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0795, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0989, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 13: precision 0.835135,roc 0.952813, loss 0.068732, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0806, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0995, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0809, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 13: precision 0.833961,roc 0.952719, loss 0.068645, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.01 train phase of epoch 13: precision 0.834969,roc 0.953178, loss 0.067548, acc 0, ECE 0 #edges 368460, #graphs 92 time: 171.2562s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0865, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 13: precision 0.834969,roc 0.953178, loss 0.067548, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 171.2562s\n",
      "92\n",
      "17\n",
      "0.07104180516277564 0.8273187926856137 loss acc\n",
      "17\n",
      "0.07104180516277564 0.8273187926856137 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.831625,roc 0.952494, loss 0.071042, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 14\n",
      "Parameter containing:\n",
      "tensor([1.1877], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 14: precision 0.837735,roc 0.954250, loss 0.064525, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 14: precision 0.838145,roc 0.953625, loss 0.064212, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0882, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0921, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 14: precision 0.836324,roc 0.953407, loss 0.064938, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.01 train phase of epoch 14: precision 0.837293,roc 0.953668, loss 0.064832, acc 0, ECE 0 #edges 368460, #graphs 92 time: 154.9134s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 14: precision 0.837293,roc 0.953668, loss 0.064832, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 154.9144s\n",
      "2.0 1.0 FERMI epoch: 15\n",
      "Parameter containing:\n",
      "tensor([1.1788], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 15: precision 0.843654,roc 0.955961, loss 0.061161, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0855, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 15: precision 0.841227,roc 0.954474, loss 0.062865, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0795, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 15: precision 0.840673,roc 0.954932, loss 0.065040, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0921, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.01 train phase of epoch 15: precision 0.840320,roc 0.954332, loss 0.065786, acc 0, ECE 0 #edges 368460, #graphs 92 time: 151.2736s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 15: precision 0.840320,roc 0.954332, loss 0.065786, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 151.2756s\n",
      "92\n",
      "17\n",
      "0.06369927593201419 0.8836748182419035 loss acc\n",
      "17\n",
      "0.06369927593201419 0.8836748182419035 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.835187,roc 0.951485, loss 0.063699, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 16\n",
      "Parameter containing:\n",
      "tensor([1.1678], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 16: precision 0.837834,roc 0.954634, loss 0.060909, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 16: precision 0.840364,roc 0.954402, loss 0.062693, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 16: precision 0.840409,roc 0.954174, loss 0.063170, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.01 train phase of epoch 16: precision 0.840653,roc 0.954886, loss 0.063008, acc 0, ECE 0 #edges 368460, #graphs 92 time: 141.1823s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 16: precision 0.840653,roc 0.954886, loss 0.063008, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 141.1833s\n",
      "2.0 1.0 FERMI epoch: 17\n",
      "Parameter containing:\n",
      "tensor([1.1560], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 17: precision 0.849688,roc 0.955509, loss 0.064433, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 17: precision 0.842782,roc 0.955761, loss 0.063138, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0806, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 17: precision 0.839886,roc 0.954748, loss 0.063502, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.01 train phase of epoch 17: precision 0.841099,roc 0.955046, loss 0.063079, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.2026s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 17: precision 0.841099,roc 0.955046, loss 0.063079, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.2046s\n",
      "92\n",
      "17\n",
      "0.06205852701700337 0.8698685466696039 loss acc\n",
      "17\n",
      "0.06205852701700337 0.8698685466696039 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.836872,roc 0.953651, loss 0.062059, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 18\n",
      "Parameter containing:\n",
      "tensor([1.1570], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0818, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 18: precision 0.843941,roc 0.955815, loss 0.064110, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 18: precision 0.844322,roc 0.956367, loss 0.063771, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 18: precision 0.841731,roc 0.955567, loss 0.063561, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0844, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0863, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.01 train phase of epoch 18: precision 0.842613,roc 0.955579, loss 0.064718, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.4648s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0998, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 18: precision 0.842613,roc 0.955579, loss 0.064718, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.4668s\n",
      "2.0 1.0 FERMI epoch: 19\n",
      "Parameter containing:\n",
      "tensor([1.1583], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 19: precision 0.839571,roc 0.956453, loss 0.060724, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 19: precision 0.841494,roc 0.955196, loss 0.062169, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0884, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0916, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 19: precision 0.842207,roc 0.954891, loss 0.064165, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.01 train phase of epoch 19: precision 0.843994,roc 0.955687, loss 0.063206, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.3828s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 19: precision 0.843994,roc 0.955687, loss 0.063206, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.3828s\n",
      "92\n",
      "17\n",
      "0.062095071029668186 0.8671366674010428 loss acc\n",
      "17\n",
      "0.062095071029668186 0.8671366674010428 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.839062,roc 0.954307, loss 0.062095, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 20\n",
      "Parameter containing:\n",
      "tensor([1.1468], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 20: precision 0.841285,roc 0.957526, loss 0.058484, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 20: precision 0.843185,roc 0.957112, loss 0.061555, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0920, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0879, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0897, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1007, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 20: precision 0.843757,roc 0.956214, loss 0.063928, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.009000000000000001 train phase of epoch 20: precision 0.845757,roc 0.956040, loss 0.062937, acc 0, ECE 0 #edges 368460, #graphs 92 time: 146.6837s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 20: precision 0.845757,roc 0.956040, loss 0.062937, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 146.6857s\n",
      "2.0 1.0 FERMI epoch: 21\n",
      "Parameter containing:\n",
      "tensor([1.1408], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 21: precision 0.840580,roc 0.954655, loss 0.062132, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 21: precision 0.843554,roc 0.955165, loss 0.062964, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1001, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0985, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0815, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0938, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 21: precision 0.845715,roc 0.955803, loss 0.064838, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.009000000000000001 train phase of epoch 21: precision 0.844794,roc 0.956091, loss 0.064765, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.4813s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 21: precision 0.844794,roc 0.956091, loss 0.064765, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.4813s\n",
      "92\n",
      "17\n",
      "0.06434750219154838 0.8949695233898803 loss acc\n",
      "17\n",
      "0.06434750219154838 0.8949695233898803 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.839037,roc 0.953110, loss 0.064348, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 22\n",
      "Parameter containing:\n",
      "tensor([1.1323], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 22: precision 0.843701,roc 0.956548, loss 0.060489, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 22: precision 0.844395,roc 0.956220, loss 0.062809, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 22: precision 0.846514,roc 0.957217, loss 0.062137, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.009000000000000001 train phase of epoch 22: precision 0.845689,roc 0.956363, loss 0.062485, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.4408s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 22: precision 0.845689,roc 0.956363, loss 0.062485, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.4408s\n",
      "2.0 1.0 FERMI epoch: 23\n",
      "Parameter containing:\n",
      "tensor([1.1341], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 23: precision 0.846283,roc 0.955839, loss 0.063054, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 23: precision 0.844289,roc 0.956976, loss 0.062690, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 23: precision 0.845933,roc 0.957664, loss 0.062591, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0831, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.009000000000000001 train phase of epoch 23: precision 0.845237,roc 0.956578, loss 0.062654, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.2217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 23: precision 0.845237,roc 0.956578, loss 0.062654, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.2217s\n",
      "92\n",
      "17\n",
      "0.06195947847212731 0.8630241609752515 loss acc\n",
      "17\n",
      "0.06195947847212731 0.8630241609752515 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.841774,roc 0.955368, loss 0.061959, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 24\n",
      "Parameter containing:\n",
      "tensor([1.1282], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0922, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 24: precision 0.844864,roc 0.954998, loss 0.067748, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 24: precision 0.847056,roc 0.956233, loss 0.066202, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 24: precision 0.847464,roc 0.956459, loss 0.064654, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.009000000000000001 train phase of epoch 24: precision 0.846566,roc 0.956805, loss 0.063811, acc 0, ECE 0 #edges 368460, #graphs 92 time: 143.8335s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 24: precision 0.846566,roc 0.956805, loss 0.063811, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 143.8335s\n",
      "2.0 1.0 FERMI epoch: 25\n",
      "Parameter containing:\n",
      "tensor([1.1225], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 25: precision 0.852306,roc 0.959974, loss 0.059384, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 25: precision 0.850367,roc 0.957747, loss 0.060825, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 25: precision 0.849336,roc 0.957500, loss 0.061479, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.009000000000000001 train phase of epoch 25: precision 0.848801,roc 0.957214, loss 0.061289, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.0941s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 25: precision 0.848801,roc 0.957214, loss 0.061289, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.0961s\n",
      "92\n",
      "17\n",
      "0.06048621399091236 0.880296687963575 loss acc\n",
      "17\n",
      "0.06048621399091236 0.880296687963575 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.842746,roc 0.954960, loss 0.060486, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 26\n",
      "Parameter containing:\n",
      "tensor([1.1173], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 26: precision 0.841625,roc 0.956512, loss 0.062209, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 26: precision 0.845643,roc 0.956654, loss 0.061254, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 26: precision 0.848116,roc 0.957707, loss 0.060565, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0907, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1062, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.009000000000000001 train phase of epoch 26: precision 0.849007,roc 0.957449, loss 0.061466, acc 0, ECE 0 #edges 368460, #graphs 92 time: 148.1536s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 26: precision 0.849007,roc 0.957449, loss 0.061466, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 148.1546s\n",
      "2.0 1.0 FERMI epoch: 27\n",
      "Parameter containing:\n",
      "tensor([1.1135], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1003, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 27: precision 0.850751,roc 0.957568, loss 0.063091, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0840, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1009, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 27: precision 0.850677,roc 0.957444, loss 0.066307, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 27: precision 0.847761,roc 0.956845, loss 0.064928, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.009000000000000001 train phase of epoch 27: precision 0.849600,roc 0.957487, loss 0.063308, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.1502s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 27: precision 0.849600,roc 0.957487, loss 0.063308, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.1502s\n",
      "92\n",
      "17\n",
      "0.06555607001495034 0.8446353822427848 loss acc\n",
      "17\n",
      "0.06555607001495034 0.8446353822427848 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.845291,roc 0.956069, loss 0.065556, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 28\n",
      "Parameter containing:\n",
      "tensor([1.1133], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 28: precision 0.848014,roc 0.955431, loss 0.060676, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1026, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 28: precision 0.850719,roc 0.957551, loss 0.060876, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 28: precision 0.850714,roc 0.957669, loss 0.060830, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.009000000000000001 train phase of epoch 28: precision 0.850574,roc 0.957639, loss 0.060681, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.1929s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 28: precision 0.850574,roc 0.957639, loss 0.060681, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.1949s\n",
      "2.0 1.0 FERMI epoch: 29\n",
      "Parameter containing:\n",
      "tensor([1.1055], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 29: precision 0.850362,roc 0.955369, loss 0.064410, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 29: precision 0.852781,roc 0.957706, loss 0.063811, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0909, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0800, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 29: precision 0.852633,roc 0.958633, loss 0.064914, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0824, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.009000000000000001 train phase of epoch 29: precision 0.850903,roc 0.957951, loss 0.064453, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.0807s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 29: precision 0.850903,roc 0.957951, loss 0.064453, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.0817s\n",
      "92\n",
      "17\n",
      "0.0663011833900924 0.8400528750826173 loss acc\n",
      "17\n",
      "0.0663011833900924 0.8400528750826173 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.844631,roc 0.956272, loss 0.066301, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 30\n",
      "Parameter containing:\n",
      "tensor([1.1057], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 30: precision 0.846281,roc 0.954940, loss 0.062690, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 30: precision 0.847919,roc 0.956818, loss 0.060891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 30: precision 0.850094,roc 0.957123, loss 0.060647, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.009000000000000001 train phase of epoch 30: precision 0.850785,roc 0.957813, loss 0.060488, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.3849s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 30: precision 0.850785,roc 0.957813, loss 0.060488, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.3869s\n",
      "2.0 1.0 FERMI epoch: 31\n",
      "Parameter containing:\n",
      "tensor([1.0935], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 31: precision 0.858825,roc 0.959061, loss 0.059652, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 31: precision 0.853051,roc 0.957784, loss 0.060655, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 31: precision 0.854643,roc 0.958064, loss 0.061081, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.009000000000000001 train phase of epoch 31: precision 0.852369,roc 0.958266, loss 0.061220, acc 0, ECE 0 #edges 368460, #graphs 92 time: 142.4949s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 31: precision 0.852369,roc 0.958266, loss 0.061220, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 142.4974s\n",
      "92\n",
      "17\n",
      "0.061761733410540254 0.861335095836087 loss acc\n",
      "17\n",
      "0.061761733410540254 0.861335095836087 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.847606,roc 0.956500, loss 0.061762, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 5569.9944s\n",
      "INFO:root:Val set results: dev phase of epoch 25: precision 0.842746,roc 0.954960, loss 0.060486, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Test set results: test phase of epoch 25: precision 0.847976,roc 0.957341, loss 0.059358, acc 0, ECE 0 #edges 284355, #graphs 71\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\1\n",
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "{'prefix': 'dev', 'epoch': 25, 'loss': 0.06048621399091236, 'roc': 0.9549597714084976, 'ap': 0.8427457392449663, 'acc': 0.880296687963575, 'ECE': 0.0}\n",
      "0.06048621399091236 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq study directory!\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\2', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129]\n",
      "92 17 71 lengths\n",
      "180 unique lenths\n",
      "92 17 71 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129], 'test': [159, 134, 107, 152, 133, 119, 92, 171, 118, 97, 149, 98, 158, 144, 122, 143, 178, 150, 162, 99, 138, 111, 156, 124, 170, 110, 100, 103, 164, 120, 141, 163, 168, 140, 93, 179, 112, 147, 95, 154, 145, 113, 142, 174, 108, 155, 106, 109, 165, 161, 148, 102, 151, 105, 115, 130, 128, 96, 117, 114, 132, 173, 104, 136, 160, 137, 139, 126, 169, 116, 131], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "92 71 17 length\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129], 'test': [159, 134, 107, 152, 133, 119, 92, 171, 118, 97, 149, 98, 158, 144, 122, 143, 178, 150, 162, 99, 138, 111, 156, 124, 170, 110, 100, 103, 164, 120, 141, 163, 168, 140, 93, 179, 112, 147, 95, 154, 145, 113, 142, 174, 108, 155, 106, 109, 165, 161, 148, 102, 151, 105, 115, 130, 128, 96, 117, 114, 132, 173, 104, 136, 160, 137, 139, 126, 169, 116, 131], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '94', '101', '121', '123', '125', '127', '129', '135', '146', '153', '157', '166', '167', '172', '175', '176', '177', '92', '93', '95', '96', '97', '98', '99', '100', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '122', '124', '126', '128', '130', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '147', '148', '149', '150', '151', '152', '154', '155', '156', '158', '159', '160', '161', '162', '163', '164', '165', '168', '169', '170', '171', '173', '174', '178', '179'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '94', '101', '121', '123', '125', '127', '129', '135', '146', '153', '157', '166', '167', '172', '175', '176', '177', '92', '93', '95', '96', '97', '98', '99', '100', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '122', '124', '126', '128', '130', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '147', '148', '149', '150', '151', '152', '154', '155', '156', '158', '159', '160', '161', '162', '163', '164', '165', '168', '169', '170', '171', '173', '174', '178', '179'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[159, 134, 107, 152, 133, 119, 92, 171, 118, 97, 149, 98, 158, 144, 122, 143, 178, 150, 162, 99, 138, 111, 156, 124, 170, 110, 100, 103, 164, 120, 141, 163, 168, 140, 93, 179, 112, 147, 95, 154, 145, 113, 142, 174, 108, 155, 106, 109, 165, 161, 148, 102, 151, 105, 115, 130, 128, 96, 117, 114, 132, 173, 104, 136, 160, 137, 139, 126, 169, 116, 131] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '94', '101', '121', '123', '125', '127', '129', '135', '146', '153', '157', '166', '167', '172', '175', '176', '177', '92', '93', '95', '96', '97', '98', '99', '100', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '122', '124', '126', '128', '130', '131', '132', '133', '134', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '147', '148', '149', '150', '151', '152', '154', '155', '156', '158', '159', '160', '161', '162', '163', '164', '165', '168', '169', '170', '171', '173', '174', '178', '179'] dta set indices\n",
      "92 71 17\n",
      "-1 ARG FREQ\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=10, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=2, eval_train=False, feat_dim=91, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], 'valid': [123, 172, 125, 135, 177, 167, 175, 94, 101, 127, 176, 121, 146, 153, 157, 166, 129], 'test': [159, 134, 107, 152, 133, 119, 92, 171, 118, 97, 149, 98, 158, 144, 122, 143, 178, 150, 162, 99, 138, 111, 156, 124, 170, 110, 100, 103, 164, 120, 141, 163, 168, 140, 93, 179, 112, 147, 95, 154, 145, 113, 142, 174, 108, 155, 106, 109, 165, 161, 148, 102, 151, 105, 115, 130, 128, 96, 117, 114, 132, 173, 104, 136, 160, 137, 139, 126, 169, 116, 131], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.01, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_03_21_09_07_320786', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=3, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\\\2', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\test\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS???\n",
      "<class 'models.base_models.LPModel'> MODEL??\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000018089E30048>, <function selu at 0x0000018089E30048>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "2.0 1.0 FERMI epoch: 0\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "92 train length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.6092, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.6015, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5140, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4918, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4336, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1903, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4063, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3181, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5059, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5168, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.5115, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.4664, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 0: precision 0.594753,roc 0.847577, loss 0.485565, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.3964, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3344, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3028, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3308, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2968, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3004, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2219, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2332, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2866, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2800, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2143, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1905, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2964, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2119, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2429, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2853, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 0: precision 0.587228,roc 0.823930, loss 0.385244, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.2056, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1996, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2001, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.3147, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2930, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2045, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2316, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2012, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2315, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2282, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2328, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1844, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1990, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1983, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 0: precision 0.595915,roc 0.823489, loss 0.327623, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1809, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2049, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2197, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1267, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1219, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1351, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1218, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1366, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1435, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.01 train phase of epoch 0: precision 0.604075,roc 0.832097, loss 0.284679, acc 0, ECE 0 #edges 368460, #graphs 92 time: 152.0192s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1637, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 0: precision 0.604075,roc 0.832097, loss 0.284679, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 152.0192s\n",
      "2.0 1.0 FERMI epoch: 1\n",
      "Parameter containing:\n",
      "tensor([1.2288], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1329, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1372, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1324, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2345, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2054, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1436, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1253, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1096, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1195, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2124, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.2202, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1001, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1134, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1226, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1211, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1406, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1439, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 1: precision 0.646575,roc 0.881219, loss 0.150966, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.1154, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1169, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1153, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1024, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1205, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1105, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1167, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1383, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1049, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1094, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1105, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1145, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1089, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0981, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1251, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1158, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1333, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 1: precision 0.675511,roc 0.886448, loss 0.138292, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.1412, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1104, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1397, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1280, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1242, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1235, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1095, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1127, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0973, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1073, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0972, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1119, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1029, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0917, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1073, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1143, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1001, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1218, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 1: precision 0.688159,roc 0.890547, loss 0.131889, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1251, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1175, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1267, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1005, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1384, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1138, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1135, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1097, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1204, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1408, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1243, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1039, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0863, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1107, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1102, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0883, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0892, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1169, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1077, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1444, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.01 train phase of epoch 1: precision 0.696995,roc 0.894325, loss 0.127207, acc 0, ECE 0 #edges 368460, #graphs 92 time: 145.4153s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1063, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 1: precision 0.696995,roc 0.894325, loss 0.127207, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 145.4153s\n",
      "92\n",
      "17\n",
      "0.1263330197066345 0.7297642652566646 loss acc\n",
      "17\n",
      "0.1263330197066345 0.7297642652566646 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.732272,roc 0.909659, loss 0.126333, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 2\n",
      "Parameter containing:\n",
      "tensor([1.2487], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1303, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1104, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1122, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1043, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1041, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1151, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1027, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1079, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1189, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1085, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1055, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0895, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1066, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1036, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1092, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1082, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0954, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1101, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 2: precision 0.731316,roc 0.909436, loss 0.105001, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1131, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1026, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0959, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1102, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0911, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1070, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1213, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1120, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1011, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1084, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1152, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1147, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1017, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0877, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0948, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0959, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0948, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 2: precision 0.745348,roc 0.912857, loss 0.103453, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1138, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0961, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1057, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1260, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0977, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0882, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0866, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0993, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0881, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1131, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1304, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0981, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1106, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1008, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0989, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 2: precision 0.749867,roc 0.914333, loss 0.103560, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0988, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1087, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1947, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1314, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0907, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0925, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1338, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0953, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1036, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1141, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0947, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1021, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1020, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1001, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0978, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0938, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.01 train phase of epoch 2: precision 0.754347,roc 0.914523, loss 0.105433, acc 0, ECE 0 #edges 368460, #graphs 92 time: 147.2503s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 2: precision 0.754347,roc 0.914523, loss 0.105433, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 147.2523s\n",
      "2.0 1.0 FERMI epoch: 3\n",
      "Parameter containing:\n",
      "tensor([1.2397], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0996, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1000, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0969, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0957, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0971, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0868, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0945, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0973, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1053, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0918, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0924, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1283, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1061, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1396, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1033, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0959, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0987, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1189, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1215, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 3: precision 0.761109,roc 0.918556, loss 0.102744, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.1269, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1249, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0890, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1395, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1053, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1226, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0923, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1005, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0909, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1067, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1132, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1191, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0792, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 3: precision 0.767149,roc 0.920229, loss 0.101694, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1105, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1156, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0884, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0891, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0897, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1298, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1011, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0961, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0933, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0950, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1123, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0942, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0917, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1060, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 3: precision 0.769690,roc 0.920694, loss 0.099160, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1066, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0953, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0872, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1027, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0863, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0994, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0966, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0926, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0792, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.01 train phase of epoch 3: precision 0.770981,roc 0.922131, loss 0.096302, acc 0, ECE 0 #edges 368460, #graphs 92 time: 143.9174s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1081, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 3: precision 0.770981,roc 0.922131, loss 0.096302, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 143.9194s\n",
      "92\n",
      "17\n",
      "0.09920061896395276 0.792274362928692 loss acc\n",
      "17\n",
      "0.09920061896395276 0.792274362928692 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.769331,roc 0.924941, loss 0.099201, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 4\n",
      "Parameter containing:\n",
      "tensor([1.2509], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0887, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1039, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0954, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0893, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1224, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1192, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0918, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0982, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 4: precision 0.777934,roc 0.926069, loss 0.087169, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0930, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0896, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1018, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0983, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0869, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0879, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0952, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0925, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0792, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 4: precision 0.782981,roc 0.927647, loss 0.085293, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0853, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0866, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0906, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0969, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0918, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1182, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0888, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1340, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1278, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1035, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1169, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0964, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 4: precision 0.784104,roc 0.928830, loss 0.088261, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.1127, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0931, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1166, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0952, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1208, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1035, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.01 train phase of epoch 4: precision 0.787613,roc 0.930361, loss 0.087724, acc 0, ECE 0 #edges 368460, #graphs 92 time: 146.6788s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0802, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 4: precision 0.787613,roc 0.930361, loss 0.087724, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 146.6788s\n",
      "2.0 1.0 FERMI epoch: 5\n",
      "Parameter containing:\n",
      "tensor([1.2379], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0874, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1006, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0795, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1052, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0809, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0873, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1192, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0944, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1012, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 5: precision 0.795442,roc 0.931957, loss 0.084003, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0923, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0792, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1084, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0904, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 5: precision 0.793426,roc 0.933518, loss 0.080723, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0818, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1050, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 5: precision 0.794292,roc 0.935210, loss 0.078785, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0888, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0925, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1152, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0841, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1124, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0926, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0868, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.01 train phase of epoch 5: precision 0.796146,roc 0.935428, loss 0.079743, acc 0, ECE 0 #edges 368460, #graphs 92 time: 148.1596s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1027, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 5: precision 0.796146,roc 0.935428, loss 0.079743, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 148.1596s\n",
      "92\n",
      "17\n",
      "0.08780181878595895 0.8087243886318571 loss acc\n",
      "17\n",
      "0.08780181878595895 0.8087243886318571 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.784139,roc 0.935156, loss 0.087802, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 6\n",
      "Parameter containing:\n",
      "tensor([1.2335], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1024, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1350, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1087, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0881, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1069, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1054, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0950, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0979, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1114, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 6: precision 0.787960,roc 0.932727, loss 0.089010, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0868, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0957, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 6: precision 0.794774,roc 0.934705, loss 0.081586, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1120, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0951, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0912, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1100, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0918, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1024, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 6: precision 0.798028,roc 0.936412, loss 0.081465, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0867, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0995, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0939, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0800, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1107, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0850, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.01 train phase of epoch 6: precision 0.800322,roc 0.937745, loss 0.080563, acc 0, ECE 0 #edges 368460, #graphs 92 time: 147.1177s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0844, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 6: precision 0.800322,roc 0.937745, loss 0.080563, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 147.1197s\n",
      "2.0 1.0 FERMI epoch: 7\n",
      "Parameter containing:\n",
      "tensor([1.2218], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0911, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1035, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 7: precision 0.802772,roc 0.941775, loss 0.074884, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0891, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0966, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1135, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0838, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1130, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 7: precision 0.801570,roc 0.940361, loss 0.077407, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0819, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0914, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 7: precision 0.803403,roc 0.940807, loss 0.075870, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0791, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1254, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0944, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1287, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0861, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.01 train phase of epoch 7: precision 0.804913,roc 0.940502, loss 0.076379, acc 0, ECE 0 #edges 368460, #graphs 92 time: 142.4692s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 7: precision 0.804913,roc 0.940502, loss 0.076379, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 142.4692s\n",
      "92\n",
      "17\n",
      "0.08176656096472858 0.872336050525079 loss acc\n",
      "17\n",
      "0.08176656096472858 0.872336050525079 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.790103,roc 0.934726, loss 0.081767, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 8\n",
      "Parameter containing:\n",
      "tensor([1.2061], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0819, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0802, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1230, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1003, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 8: precision 0.799604,roc 0.941471, loss 0.077277, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0846, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0931, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0950, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0896, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 8: precision 0.807694,roc 0.942384, loss 0.075439, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0917, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1033, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1113, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0848, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 8: precision 0.806055,roc 0.941955, loss 0.075087, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0905, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1027, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.01 train phase of epoch 8: precision 0.806950,roc 0.942060, loss 0.074900, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.6489s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 8: precision 0.806950,roc 0.942060, loss 0.074900, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.6489s\n",
      "2.0 1.0 FERMI epoch: 9\n",
      "Parameter containing:\n",
      "tensor([1.1978], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0842, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0871, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0959, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0791, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0919, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 9: precision 0.802986,roc 0.941843, loss 0.075766, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0970, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 9: precision 0.807758,roc 0.943296, loss 0.073303, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1065, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0826, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1146, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1080, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1286, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0968, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0912, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 9: precision 0.806906,roc 0.943061, loss 0.076042, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0840, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1371, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0865, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0980, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0955, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1348, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0999, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1194, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.01 train phase of epoch 9: precision 0.806880,roc 0.942234, loss 0.078581, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.4566s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 9: precision 0.806880,roc 0.942234, loss 0.078581, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.4566s\n",
      "92\n",
      "17\n",
      "0.07852659768335736 0.8747888668576044 loss acc\n",
      "17\n",
      "0.07852659768335736 0.8747888668576044 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.790512,roc 0.937183, loss 0.078527, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 10\n",
      "Parameter containing:\n",
      "tensor([1.1811], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1273, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1056, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 10: precision 0.807919,roc 0.942500, loss 0.075487, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1070, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1022, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0915, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 10: precision 0.808373,roc 0.942770, loss 0.075483, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0912, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 10: precision 0.808728,roc 0.943107, loss 0.073762, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0979, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0874, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0964, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0859, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0909, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1100, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.01 train phase of epoch 10: precision 0.809978,roc 0.943441, loss 0.074649, acc 0, ECE 0 #edges 368460, #graphs 92 time: 142.5021s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 10: precision 0.809978,roc 0.943441, loss 0.074649, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 142.5021s\n",
      "2.0 1.0 FERMI epoch: 11\n",
      "Parameter containing:\n",
      "tensor([1.1803], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0906, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0877, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 11: precision 0.810968,roc 0.944015, loss 0.069554, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0858, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0886, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0904, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1211, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 11: precision 0.819357,roc 0.945361, loss 0.070811, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1141, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0921, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 11: precision 0.819299,roc 0.945909, loss 0.070948, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1032, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1125, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.01 train phase of epoch 11: precision 0.816556,roc 0.945809, loss 0.071110, acc 0, ECE 0 #edges 368460, #graphs 92 time: 157.3327s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 11: precision 0.816556,roc 0.945809, loss 0.071110, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 157.3337s\n",
      "92\n",
      "17\n",
      "0.07440470432076278 0.8422119409561578 loss acc\n",
      "17\n",
      "0.07440470432076278 0.8422119409561578 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.802597,roc 0.943158, loss 0.074405, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 12\n",
      "Parameter containing:\n",
      "tensor([1.1692], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0833, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1105, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0895, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0892, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0933, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1173, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0808, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1227, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 12: precision 0.811023,roc 0.943666, loss 0.077305, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 12: precision 0.814989,roc 0.946053, loss 0.073290, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0979, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0855, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 12: precision 0.816423,roc 0.946034, loss 0.072048, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0949, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.01 train phase of epoch 12: precision 0.818259,roc 0.946276, loss 0.070960, acc 0, ECE 0 #edges 368460, #graphs 92 time: 143.2983s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 12: precision 0.818259,roc 0.946276, loss 0.070960, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 143.3003s\n",
      "2.0 1.0 FERMI epoch: 13\n",
      "Parameter containing:\n",
      "tensor([1.1619], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0866, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1044, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0838, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0936, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0983, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0957, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 13: precision 0.819713,roc 0.946442, loss 0.075743, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0978, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0814, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0854, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 13: precision 0.818717,roc 0.946332, loss 0.072392, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0846, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 13: precision 0.821558,roc 0.947223, loss 0.070463, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0848, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0989, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.01 train phase of epoch 13: precision 0.822499,roc 0.947640, loss 0.070117, acc 0, ECE 0 #edges 368460, #graphs 92 time: 146.9855s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 13: precision 0.822499,roc 0.947640, loss 0.070117, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 146.9875s\n",
      "92\n",
      "17\n",
      "0.09238331797654598 0.7752074612616584 loss acc\n",
      "17\n",
      "0.09238331797654598 0.7752074612616584 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.804940,roc 0.944803, loss 0.092383, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 14\n",
      "Parameter containing:\n",
      "tensor([1.1562], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0962, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1157, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1206, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1423, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0973, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0919, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0871, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0941, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 14: precision 0.809971,roc 0.943498, loss 0.084957, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0773, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0837, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0784, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0845, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0927, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 14: precision 0.816445,roc 0.945117, loss 0.078005, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0876, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 14: precision 0.819524,roc 0.946330, loss 0.075512, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0858, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.01 train phase of epoch 14: precision 0.819242,roc 0.946890, loss 0.073431, acc 0, ECE 0 #edges 368460, #graphs 92 time: 142.5708s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 14: precision 0.819242,roc 0.946890, loss 0.073431, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 142.5728s\n",
      "2.0 1.0 FERMI epoch: 15\n",
      "Parameter containing:\n",
      "tensor([1.1426], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 15: precision 0.826615,roc 0.948474, loss 0.064147, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 15: precision 0.825425,roc 0.949161, loss 0.065956, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0825, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 15: precision 0.826108,roc 0.949283, loss 0.066642, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1194, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0881, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0991, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1282, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0839, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0785, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0856, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.01 train phase of epoch 15: precision 0.824007,roc 0.948618, loss 0.070137, acc 0, ECE 0 #edges 368460, #graphs 92 time: 145.0477s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 15: precision 0.824007,roc 0.948618, loss 0.070137, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 145.0498s\n",
      "92\n",
      "17\n",
      "0.07459608060914155 0.8842035690680767 loss acc\n",
      "17\n",
      "0.07459608060914155 0.8842035690680767 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.808280,roc 0.943142, loss 0.074596, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 16\n",
      "Parameter containing:\n",
      "tensor([1.1265], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0955, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 16: precision 0.817960,roc 0.948599, loss 0.065924, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1051, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0866, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 16: precision 0.826413,roc 0.949620, loss 0.067067, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1198, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1306, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 16: precision 0.825988,roc 0.948889, loss 0.068240, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0852, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1061, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.01 train phase of epoch 16: precision 0.826868,roc 0.949369, loss 0.068395, acc 0, ECE 0 #edges 368460, #graphs 92 time: 146.5947s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 16: precision 0.826868,roc 0.949369, loss 0.068395, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 146.6120s\n",
      "2.0 1.0 FERMI epoch: 17\n",
      "Parameter containing:\n",
      "tensor([1.1275], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0823, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0935, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0946, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0849, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0746, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 17: precision 0.827514,roc 0.949347, loss 0.071625, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 17: precision 0.828209,roc 0.950417, loss 0.068976, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0868, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0873, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1325, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 17: precision 0.826366,roc 0.949105, loss 0.070854, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1181, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1052, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0879, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.01 train phase of epoch 17: precision 0.825088,roc 0.948765, loss 0.071264, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.6467s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 17: precision 0.825088,roc 0.948765, loss 0.071264, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.6467s\n",
      "92\n",
      "17\n",
      "0.06995411334189935 0.8731144892413892 loss acc\n",
      "17\n",
      "0.06995411334189935 0.8731144892413892 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.816000,roc 0.945910, loss 0.069954, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 18\n",
      "Parameter containing:\n",
      "tensor([1.1131], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0748, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1002, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 18: precision 0.831588,roc 0.951083, loss 0.065349, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 18: precision 0.830509,roc 0.950172, loss 0.064576, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0953, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 18: precision 0.830156,roc 0.950656, loss 0.064468, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0984, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.01 train phase of epoch 18: precision 0.831390,roc 0.951095, loss 0.064861, acc 0, ECE 0 #edges 368460, #graphs 92 time: 146.8090s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 18: precision 0.831390,roc 0.951095, loss 0.064861, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 146.8090s\n",
      "2.0 1.0 FERMI epoch: 19\n",
      "Parameter containing:\n",
      "tensor([1.1024], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0885, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 19: precision 0.829500,roc 0.948716, loss 0.065479, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0850, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0902, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 19: precision 0.828912,roc 0.950319, loss 0.066429, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 19: precision 0.830687,roc 0.951553, loss 0.065171, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1070, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.01 train phase of epoch 19: precision 0.832208,roc 0.951495, loss 0.066012, acc 0, ECE 0 #edges 368460, #graphs 92 time: 142.6871s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 19: precision 0.832208,roc 0.951495, loss 0.066012, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 142.6891s\n",
      "92\n",
      "17\n",
      "0.08497956585782332 0.790717485496071 loss acc\n",
      "17\n",
      "0.08497956585782332 0.790717485496071 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.820652,roc 0.949634, loss 0.084980, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 20\n",
      "Parameter containing:\n",
      "tensor([1.1027], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 20: precision 0.836604,roc 0.950738, loss 0.064207, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0764, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 20: precision 0.833329,roc 0.952348, loss 0.064806, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0909, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0904, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0804, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 20: precision 0.833851,roc 0.952251, loss 0.065534, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0901, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.009000000000000001 train phase of epoch 20: precision 0.833146,roc 0.951627, loss 0.066400, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.8024s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 20: precision 0.833146,roc 0.951627, loss 0.066400, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.8034s\n",
      "2.0 1.0 FERMI epoch: 21\n",
      "Parameter containing:\n",
      "tensor([1.0867], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0835, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0875, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 21: precision 0.828898,roc 0.950783, loss 0.064304, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0789, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 21: precision 0.832676,roc 0.952311, loss 0.063519, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0898, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 21: precision 0.833051,roc 0.952283, loss 0.063181, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0818, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.009000000000000001 train phase of epoch 21: precision 0.835469,roc 0.952707, loss 0.063019, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.1955s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 21: precision 0.835469,roc 0.952707, loss 0.063019, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.1955s\n",
      "92\n",
      "17\n",
      "0.07518366384862837 0.8200925313945802 loss acc\n",
      "17\n",
      "0.07518366384862837 0.8200925313945802 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.828339,roc 0.951657, loss 0.075184, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 22\n",
      "Parameter containing:\n",
      "tensor([1.0854], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0810, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 22: precision 0.832129,roc 0.953115, loss 0.064515, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0834, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0800, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0921, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0890, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1048, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 22: precision 0.833997,roc 0.953396, loss 0.068272, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 22: precision 0.835911,roc 0.953677, loss 0.066328, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0970, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.009000000000000001 train phase of epoch 22: precision 0.837436,roc 0.953009, loss 0.065410, acc 0, ECE 0 #edges 368460, #graphs 92 time: 147.4754s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 22: precision 0.837436,roc 0.953009, loss 0.065410, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 147.4774s\n",
      "2.0 1.0 FERMI epoch: 23\n",
      "Parameter containing:\n",
      "tensor([1.0722], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 23: precision 0.838390,roc 0.954885, loss 0.062491, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0715, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0851, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0792, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0821, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 23: precision 0.838643,roc 0.953600, loss 0.064824, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 23: precision 0.839240,roc 0.954319, loss 0.063997, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0817, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.009000000000000001 train phase of epoch 23: precision 0.838538,roc 0.953555, loss 0.063958, acc 0, ECE 0 #edges 368460, #graphs 92 time: 141.9321s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 23: precision 0.838538,roc 0.953555, loss 0.063958, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 141.9321s\n",
      "92\n",
      "17\n",
      "0.06686077482541662 0.8631269736358964 loss acc\n",
      "17\n",
      "0.06686077482541662 0.8631269736358964 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.829738,roc 0.950900, loss 0.066861, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 24\n",
      "Parameter containing:\n",
      "tensor([1.0656], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0707, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0788, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0916, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0827, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0853, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 24: precision 0.843183,roc 0.953938, loss 0.066457, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0783, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 24: precision 0.843949,roc 0.953696, loss 0.064124, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0726, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0713, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0998, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 24: precision 0.841767,roc 0.953778, loss 0.064949, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0756, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0735, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.009000000000000001 train phase of epoch 24: precision 0.839170,roc 0.953475, loss 0.064765, acc 0, ECE 0 #edges 368460, #graphs 92 time: 141.1083s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 24: precision 0.839170,roc 0.953475, loss 0.064765, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 141.1083s\n",
      "2.0 1.0 FERMI epoch: 25\n",
      "Parameter containing:\n",
      "tensor([1.0561], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 25: precision 0.840705,roc 0.954532, loss 0.061615, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1024, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 25: precision 0.840672,roc 0.953490, loss 0.062511, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0787, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 25: precision 0.843501,roc 0.954670, loss 0.061988, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.009000000000000001 train phase of epoch 25: precision 0.840531,roc 0.954751, loss 0.061719, acc 0, ECE 0 #edges 368460, #graphs 92 time: 139.8563s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 25: precision 0.840531,roc 0.954751, loss 0.061719, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 139.8573s\n",
      "92\n",
      "17\n",
      "0.06584415719939123 0.8649776015275022 loss acc\n",
      "17\n",
      "0.06584415719939123 0.8649776015275022 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.830189,roc 0.951571, loss 0.065844, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 26\n",
      "Parameter containing:\n",
      "tensor([1.0482], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0883, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0843, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 26: precision 0.839008,roc 0.952772, loss 0.064051, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0880, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0749, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 26: precision 0.846336,roc 0.955264, loss 0.063783, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1066, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0913, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1063, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0871, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1089, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 26: precision 0.843852,roc 0.954301, loss 0.067017, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0796, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.009000000000000001 train phase of epoch 26: precision 0.842420,roc 0.954412, loss 0.066462, acc 0, ECE 0 #edges 368460, #graphs 92 time: 140.1800s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 26: precision 0.842420,roc 0.954412, loss 0.066462, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 140.1800s\n",
      "2.0 1.0 FERMI epoch: 27\n",
      "Parameter containing:\n",
      "tensor([1.0372], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0791, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 27: precision 0.841037,roc 0.955991, loss 0.060709, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0819, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 27: precision 0.846882,roc 0.956164, loss 0.059692, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0890, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1189, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 27: precision 0.846010,roc 0.955790, loss 0.062283, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0878, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0685, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0832, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.009000000000000001 train phase of epoch 27: precision 0.842915,roc 0.955005, loss 0.063199, acc 0, ECE 0 #edges 368460, #graphs 92 time: 130.0787s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 27: precision 0.842915,roc 0.955005, loss 0.063199, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 130.0797s\n",
      "92\n",
      "17\n",
      "0.06860987985027198 0.8434163178379966 loss acc\n",
      "17\n",
      "0.06860987985027198 0.8434163178379966 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.831565,roc 0.952724, loss 0.068610, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 28\n",
      "Parameter containing:\n",
      "tensor([1.0340], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 28: precision 0.839888,roc 0.954663, loss 0.061623, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0797, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 28: precision 0.842924,roc 0.955130, loss 0.062361, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 28: precision 0.841713,roc 0.955076, loss 0.062254, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.009000000000000001 train phase of epoch 28: precision 0.844107,roc 0.955558, loss 0.061497, acc 0, ECE 0 #edges 368460, #graphs 92 time: 127.0824s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 28: precision 0.844107,roc 0.955558, loss 0.061497, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 127.0844s\n",
      "2.0 1.0 FERMI epoch: 29\n",
      "Parameter containing:\n",
      "tensor([1.0251], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 29: precision 0.848314,roc 0.956575, loss 0.059127, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0960, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0896, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 29: precision 0.846785,roc 0.956639, loss 0.061599, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 29: precision 0.844741,roc 0.956227, loss 0.061722, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0794, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.009000000000000001 train phase of epoch 29: precision 0.844897,roc 0.955737, loss 0.062024, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.8975s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 29: precision 0.844897,roc 0.955737, loss 0.062024, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.8985s\n",
      "92\n",
      "17\n",
      "0.06497345107464336 0.8818241903502972 loss acc\n",
      "17\n",
      "0.06497345107464336 0.8818241903502972 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.834264,roc 0.951893, loss 0.064973, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 30\n",
      "Parameter containing:\n",
      "tensor([1.0138], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 30: precision 0.848909,roc 0.957641, loss 0.058278, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 30: precision 0.849099,roc 0.957085, loss 0.059485, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0697, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 30: precision 0.845855,roc 0.956235, loss 0.061008, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0872, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.009000000000000001 train phase of epoch 30: precision 0.847501,roc 0.956717, loss 0.061319, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.7745s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 30: precision 0.847501,roc 0.956717, loss 0.061319, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.7745s\n",
      "2.0 1.0 FERMI epoch: 31\n",
      "Parameter containing:\n",
      "tensor([1.0080], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0848, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0975, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 31: precision 0.835359,roc 0.952881, loss 0.066456, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 31: precision 0.843048,roc 0.955458, loss 0.062666, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 31: precision 0.846560,roc 0.956520, loss 0.060710, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0857, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.009000000000000001 train phase of epoch 31: precision 0.847911,roc 0.956662, loss 0.061534, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.7696s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 31: precision 0.847911,roc 0.956662, loss 0.061534, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.7705s\n",
      "92\n",
      "17\n",
      "0.0639996780686798 0.8647572886832636 loss acc\n",
      "17\n",
      "0.0639996780686798 0.8647572886832636 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.835675,roc 0.953990, loss 0.064000, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 32\n",
      "Parameter containing:\n",
      "tensor([0.9990], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 32: precision 0.846572,roc 0.957311, loss 0.059949, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0777, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 32: precision 0.849850,roc 0.958234, loss 0.058940, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0846, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 32: precision 0.849961,roc 0.957713, loss 0.059403, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.009000000000000001 train phase of epoch 32: precision 0.850195,roc 0.957803, loss 0.059129, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.6237s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 32: precision 0.850195,roc 0.957803, loss 0.059129, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.6257s\n",
      "2.0 1.0 FERMI epoch: 33\n",
      "Parameter containing:\n",
      "tensor([0.9916], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1359, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0998, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0899, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1403, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 33: precision 0.852899,roc 0.959259, loss 0.070356, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 33: precision 0.851744,roc 0.958038, loss 0.064980, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 33: precision 0.850150,roc 0.957236, loss 0.062996, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0710, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.009000000000000001 train phase of epoch 33: precision 0.849460,roc 0.957160, loss 0.061943, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.8320s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 33: precision 0.849460,roc 0.957160, loss 0.061943, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.8330s\n",
      "92\n",
      "17\n",
      "0.06365927937181522 0.8803407505324228 loss acc\n",
      "17\n",
      "0.06365927937181522 0.8803407505324228 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.836493,roc 0.953699, loss 0.063659, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 34\n",
      "Parameter containing:\n",
      "tensor([0.9814], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 34: precision 0.849696,roc 0.956463, loss 0.058064, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0766, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 34: precision 0.852588,roc 0.957516, loss 0.058399, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0815, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0830, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1327, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0877, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 34: precision 0.851090,roc 0.957667, loss 0.060709, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.009000000000000001 train phase of epoch 34: precision 0.851379,roc 0.958181, loss 0.059798, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.8180s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 34: precision 0.851379,roc 0.958181, loss 0.059798, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.8190s\n",
      "2.0 1.0 FERMI epoch: 35\n",
      "Parameter containing:\n",
      "tensor([0.9715], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 35: precision 0.848186,roc 0.959401, loss 0.058587, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 35: precision 0.850097,roc 0.958410, loss 0.058327, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0801, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0890, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 35: precision 0.850032,roc 0.957698, loss 0.060015, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0860, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0985, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.009000000000000001 train phase of epoch 35: precision 0.852012,roc 0.958016, loss 0.060174, acc 0, ECE 0 #edges 368460, #graphs 92 time: 127.0124s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 35: precision 0.852012,roc 0.958016, loss 0.060174, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 127.0144s\n",
      "92\n",
      "17\n",
      "0.06221905418072891 0.8744069912609238 loss acc\n",
      "17\n",
      "0.06221905418072891 0.8744069912609238 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.840015,roc 0.954792, loss 0.062219, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 36\n",
      "Parameter containing:\n",
      "tensor([0.9653], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 36: precision 0.851817,roc 0.959966, loss 0.058936, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0734, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 36: precision 0.847848,roc 0.958029, loss 0.060698, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 36: precision 0.850752,roc 0.958633, loss 0.059940, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0942, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0940, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.009000000000000001 train phase of epoch 36: precision 0.852801,roc 0.958355, loss 0.060066, acc 0, ECE 0 #edges 368460, #graphs 92 time: 119.3352s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 36: precision 0.852801,roc 0.958355, loss 0.060066, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 119.3352s\n",
      "2.0 1.0 FERMI epoch: 37\n",
      "Parameter containing:\n",
      "tensor([0.9593], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0692, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 37: precision 0.858775,roc 0.960491, loss 0.058016, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 37: precision 0.857449,roc 0.961142, loss 0.057082, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0799, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0919, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 37: precision 0.857526,roc 0.960212, loss 0.057230, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0883, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0711, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0771, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0963, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1019, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.009000000000000001 train phase of epoch 37: precision 0.853894,roc 0.958824, loss 0.059511, acc 0, ECE 0 #edges 368460, #graphs 92 time: 119.4264s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 37: precision 0.853894,roc 0.958824, loss 0.059511, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 119.4274s\n",
      "92\n",
      "17\n",
      "0.08512951839316046 0.904119850187266 loss acc\n",
      "17\n",
      "0.08512951839316046 0.904119850187266 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.828260,roc 0.949507, loss 0.085130, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 38\n",
      "Parameter containing:\n",
      "tensor([0.9420], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.1236, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0828, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0836, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 38: precision 0.848959,roc 0.956968, loss 0.064001, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0730, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 38: precision 0.854475,roc 0.958117, loss 0.059943, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 38: precision 0.852509,roc 0.958191, loss 0.060957, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0847, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0743, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.009000000000000001 train phase of epoch 38: precision 0.853211,roc 0.958921, loss 0.060207, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.3840s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 38: precision 0.853211,roc 0.958921, loss 0.060207, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.3860s\n",
      "2.0 1.0 FERMI epoch: 39\n",
      "Parameter containing:\n",
      "tensor([0.9430], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0663, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0951, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0742, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 39: precision 0.852829,roc 0.958689, loss 0.060381, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0853, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0838, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0733, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0803, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 39: precision 0.855198,roc 0.959337, loss 0.060709, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0769, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 39: precision 0.853615,roc 0.959225, loss 0.059949, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0757, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.009000000000000001 train phase of epoch 39: precision 0.855198,roc 0.959345, loss 0.059910, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.5150s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 39: precision 0.855198,roc 0.959345, loss 0.059910, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.5160s\n",
      "92\n",
      "17\n",
      "0.06259140004858899 0.8627744730851142 loss acc\n",
      "17\n",
      "0.06259140004858899 0.8627744730851142 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.843011,roc 0.956552, loss 0.062591, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 40\n",
      "Parameter containing:\n",
      "tensor([0.9358], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 40: precision 0.855410,roc 0.959844, loss 0.055954, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0741, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0894, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0932, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0939, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 40: precision 0.854919,roc 0.960085, loss 0.058741, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0689, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0762, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 40: precision 0.855216,roc 0.959465, loss 0.059328, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.008100000000000001 train phase of epoch 40: precision 0.856541,roc 0.959750, loss 0.058670, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.2680s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 40: precision 0.856541,roc 0.959750, loss 0.058670, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.2690s\n",
      "2.0 1.0 FERMI epoch: 41\n",
      "Parameter containing:\n",
      "tensor([0.9269], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0700, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0714, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 41: precision 0.850854,roc 0.959213, loss 0.059775, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0731, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0758, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0709, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 41: precision 0.857136,roc 0.960879, loss 0.059291, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 41: precision 0.857826,roc 0.961109, loss 0.058091, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0755, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.1046, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.008100000000000001 train phase of epoch 41: precision 0.857081,roc 0.960117, loss 0.058955, acc 0, ECE 0 #edges 368460, #graphs 92 time: 122.9833s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 41: precision 0.857081,roc 0.960117, loss 0.058955, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 122.9833s\n",
      "92\n",
      "17\n",
      "0.061871854972721116 0.8644635382242785 loss acc\n",
      "17\n",
      "0.061871854972721116 0.8644635382242785 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.845297,roc 0.957072, loss 0.061872, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 42\n",
      "Parameter containing:\n",
      "tensor([0.9219], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0725, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0776, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0916, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 42: precision 0.855433,roc 0.960027, loss 0.058763, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 42: precision 0.857298,roc 0.960592, loss 0.057431, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0798, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 42: precision 0.857369,roc 0.960161, loss 0.057511, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0717, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.008100000000000001 train phase of epoch 42: precision 0.858631,roc 0.960609, loss 0.057973, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.9741s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 42: precision 0.858631,roc 0.960609, loss 0.057973, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.9741s\n",
      "2.0 1.0 FERMI epoch: 43\n",
      "Parameter containing:\n",
      "tensor([0.9140], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0720, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0747, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0719, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 43: precision 0.855982,roc 0.960349, loss 0.060016, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0775, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 43: precision 0.856960,roc 0.961072, loss 0.058936, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0786, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0829, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0628, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 43: precision 0.858374,roc 0.960383, loss 0.059148, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0603, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.008100000000000001 train phase of epoch 43: precision 0.859026,roc 0.960718, loss 0.058635, acc 0, ECE 0 #edges 368460, #graphs 92 time: 119.3558s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 43: precision 0.859026,roc 0.960718, loss 0.058635, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 119.3578s\n",
      "92\n",
      "17\n",
      "0.06181487076089643 0.8894763898068592 loss acc\n",
      "17\n",
      "0.06181487076089643 0.8894763898068592 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.842167,roc 0.956282, loss 0.061815, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 44\n",
      "Parameter containing:\n",
      "tensor([0.9054], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 44: precision 0.871723,roc 0.964541, loss 0.052505, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 44: precision 0.864921,roc 0.963556, loss 0.053303, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0811, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 44: precision 0.862492,roc 0.961939, loss 0.055823, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0871, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0627, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.008100000000000001 train phase of epoch 44: precision 0.860065,roc 0.961061, loss 0.057089, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.3485s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 44: precision 0.860065,roc 0.961061, loss 0.057089, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.3485s\n",
      "2.0 1.0 FERMI epoch: 45\n",
      "Parameter containing:\n",
      "tensor([0.9023], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 45: precision 0.855545,roc 0.959330, loss 0.059017, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0701, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 45: precision 0.859662,roc 0.960022, loss 0.060077, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 45: precision 0.859457,roc 0.960479, loss 0.058919, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.008100000000000001 train phase of epoch 45: precision 0.858886,roc 0.960849, loss 0.058168, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.6181s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 45: precision 0.858886,roc 0.960849, loss 0.058168, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.6191s\n",
      "92\n",
      "17\n",
      "0.0602606845081902 0.8886098259528531 loss acc\n",
      "17\n",
      "0.0602606845081902 0.8886098259528531 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.845642,roc 0.957321, loss 0.060261, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 46\n",
      "Parameter containing:\n",
      "tensor([0.8916], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0724, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 46: precision 0.858324,roc 0.959651, loss 0.055725, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0661, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 46: precision 0.858646,roc 0.961628, loss 0.056223, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0642, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0820, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0767, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 46: precision 0.859183,roc 0.961257, loss 0.057339, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0047 lr: 0.008100000000000001 train phase of epoch 46: precision 0.860235,roc 0.961457, loss 0.057428, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.7344s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 46: precision 0.860235,roc 0.961457, loss 0.057428, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.7354s\n",
      "2.0 1.0 FERMI epoch: 47\n",
      "Parameter containing:\n",
      "tensor([0.8861], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0995, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 47: precision 0.861455,roc 0.962483, loss 0.058288, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 47: precision 0.863620,roc 0.962585, loss 0.056348, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 47: precision 0.860621,roc 0.961851, loss 0.055990, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0048 lr: 0.008100000000000001 train phase of epoch 47: precision 0.862435,roc 0.962016, loss 0.056124, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.2061s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0765, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 47: precision 0.862435,roc 0.962016, loss 0.056124, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.2081s\n",
      "92\n",
      "17\n",
      "0.061413441628183685 0.8607182198722185 loss acc\n",
      "17\n",
      "0.061413441628183685 0.8607182198722185 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0048 dev phase of epoch 47: precision 0.851469,roc 0.959590, loss 0.061413, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 48\n",
      "Parameter containing:\n",
      "tensor([0.8803], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0759, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0712, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0716, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 48: precision 0.863146,roc 0.960212, loss 0.058781, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0680, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 48: precision 0.864336,roc 0.961591, loss 0.057317, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 48: precision 0.863085,roc 0.961507, loss 0.057145, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0049 lr: 0.008100000000000001 train phase of epoch 48: precision 0.863339,roc 0.962079, loss 0.056617, acc 0, ECE 0 #edges 368460, #graphs 92 time: 127.7751s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0774, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 48: precision 0.863339,roc 0.962079, loss 0.056617, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 127.7761s\n",
      "2.0 1.0 FERMI epoch: 49\n",
      "Parameter containing:\n",
      "tensor([0.8708], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0768, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 49: precision 0.858723,roc 0.962753, loss 0.055577, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 49: precision 0.863191,roc 0.963183, loss 0.055033, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0460, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 49: precision 0.865599,roc 0.962935, loss 0.055457, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0703, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0972, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0050 lr: 0.008100000000000001 train phase of epoch 49: precision 0.864277,roc 0.962447, loss 0.057214, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.5197s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0821, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 49: precision 0.864277,roc 0.962447, loss 0.057214, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.5197s\n",
      "92\n",
      "17\n",
      "0.06405786415014275 0.8463244473819491 loss acc\n",
      "17\n",
      "0.06405786415014275 0.8463244473819491 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0050 dev phase of epoch 49: precision 0.854240,roc 0.960244, loss 0.064058, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 50\n",
      "Parameter containing:\n",
      "tensor([0.8677], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0889, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0630, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 50: precision 0.866631,roc 0.962233, loss 0.055962, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0649, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 50: precision 0.864464,roc 0.962282, loss 0.055758, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 50: precision 0.863863,roc 0.962191, loss 0.055236, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0639, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0698, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0908, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0051 lr: 0.008100000000000001 train phase of epoch 50: precision 0.864501,roc 0.962578, loss 0.055960, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.9104s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 50: precision 0.864501,roc 0.962578, loss 0.055960, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.9104s\n",
      "2.0 1.0 FERMI epoch: 51\n",
      "Parameter containing:\n",
      "tensor([0.8554], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 51: precision 0.864091,roc 0.962045, loss 0.054716, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0435, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0738, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0691, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0805, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 51: precision 0.864119,roc 0.962413, loss 0.055948, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0643, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0662, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 51: precision 0.864645,roc 0.962719, loss 0.055658, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0677, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0997, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0739, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0052 lr: 0.008100000000000001 train phase of epoch 51: precision 0.864385,roc 0.962799, loss 0.056645, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.3515s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 51: precision 0.864385,roc 0.962799, loss 0.056645, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.3535s\n",
      "92\n",
      "17\n",
      "0.05846852893047101 0.8889917015495336 loss acc\n",
      "17\n",
      "0.05846852893047101 0.8889917015495336 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0052 dev phase of epoch 51: precision 0.850690,roc 0.959061, loss 0.058469, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 52\n",
      "Parameter containing:\n",
      "tensor([0.8493], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 52: precision 0.871265,roc 0.964989, loss 0.052092, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0666, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0696, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 52: precision 0.869227,roc 0.963605, loss 0.054421, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0760, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0821, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0664, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 52: precision 0.866708,roc 0.963277, loss 0.055501, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0722, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0660, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0462, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0053 lr: 0.008100000000000001 train phase of epoch 52: precision 0.865621,roc 0.963116, loss 0.055508, acc 0, ECE 0 #edges 368460, #graphs 92 time: 120.8368s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 52: precision 0.865621,roc 0.963116, loss 0.055508, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 120.8388s\n",
      "2.0 1.0 FERMI epoch: 53\n",
      "Parameter containing:\n",
      "tensor([0.8422], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0753, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0782, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 53: precision 0.862276,roc 0.961198, loss 0.056517, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0440, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0687, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0616, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0665, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 53: precision 0.863463,roc 0.962716, loss 0.055711, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0723, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0780, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 53: precision 0.864790,roc 0.963313, loss 0.056191, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0675, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0704, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0656, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0054 lr: 0.008100000000000001 train phase of epoch 53: precision 0.866363,roc 0.963360, loss 0.055992, acc 0, ECE 0 #edges 368460, #graphs 92 time: 116.2871s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0644, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 53: precision 0.866363,roc 0.963360, loss 0.055992, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 116.2881s\n",
      "92\n",
      "17\n",
      "0.06243088911203336 0.8515385180289344 loss acc\n",
      "17\n",
      "0.06243088911203336 0.8515385180289344 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0054 dev phase of epoch 53: precision 0.856532,roc 0.961197, loss 0.062431, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 54\n",
      "Parameter containing:\n",
      "tensor([0.8396], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0770, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0822, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 54: precision 0.872473,roc 0.963886, loss 0.059224, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0637, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0654, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 54: precision 0.868844,roc 0.963953, loss 0.058196, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0420, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 54: precision 0.866988,roc 0.963552, loss 0.057352, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0658, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0728, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0635, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0737, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0653, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0055 lr: 0.008100000000000001 train phase of epoch 54: precision 0.867111,roc 0.963238, loss 0.058030, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.2986s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0745, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 54: precision 0.867111,roc 0.963238, loss 0.058030, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.3005s\n",
      "2.0 1.0 FERMI epoch: 55\n",
      "Parameter containing:\n",
      "tensor([0.8303], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0646, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0807, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0781, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0761, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0779, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 55: precision 0.870072,roc 0.963408, loss 0.058613, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0672, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 55: precision 0.865742,roc 0.963260, loss 0.057194, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0623, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0752, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 55: precision 0.865048,roc 0.962704, loss 0.056589, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0727, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0615, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0694, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0056 lr: 0.008100000000000001 train phase of epoch 55: precision 0.866109,roc 0.963247, loss 0.056440, acc 0, ECE 0 #edges 368460, #graphs 92 time: 129.3602s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 55: precision 0.866109,roc 0.963247, loss 0.056440, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 129.3602s\n",
      "92\n",
      "17\n",
      "0.05766729004425594 0.8835132554894618 loss acc\n",
      "17\n",
      "0.05766729004425594 0.8835132554894618 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0056 dev phase of epoch 55: precision 0.854716,roc 0.960553, loss 0.057667, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 56\n",
      "Parameter containing:\n",
      "tensor([0.8247], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0550, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0652, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0443, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 56: precision 0.876920,roc 0.965778, loss 0.054530, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0674, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0655, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0601, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0744, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 56: precision 0.871392,roc 0.965154, loss 0.054627, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0461, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 56: precision 0.871288,roc 0.965559, loss 0.054473, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0732, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0702, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0657, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0790, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0632, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0057 lr: 0.008100000000000001 train phase of epoch 56: precision 0.868107,roc 0.963976, loss 0.055517, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.7435s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 56: precision 0.868107,roc 0.963976, loss 0.055517, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.7445s\n",
      "2.0 1.0 FERMI epoch: 57\n",
      "Parameter containing:\n",
      "tensor([0.8176], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0750, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0721, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0690, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 57: precision 0.867984,roc 0.963252, loss 0.055069, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0626, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0600, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0597, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0648, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0671, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0816, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0620, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0611, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 57: precision 0.866974,roc 0.963693, loss 0.056191, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0754, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0693, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0813, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0624, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0599, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0751, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0559, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0705, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 57: precision 0.869054,roc 0.963733, loss 0.057327, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0740, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0793, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0670, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0058 lr: 0.008100000000000001 train phase of epoch 57: precision 0.867589,roc 0.963626, loss 0.057820, acc 0, ECE 0 #edges 368460, #graphs 92 time: 118.8309s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 57: precision 0.867589,roc 0.963626, loss 0.057820, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 118.8319s\n",
      "92\n",
      "17\n",
      "0.06434383011044839 0.8431519424249102 loss acc\n",
      "17\n",
      "0.06434383011044839 0.8431519424249102 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0058 dev phase of epoch 57: precision 0.857283,roc 0.961451, loss 0.064344, acc 0, ECE 0 #edges 68085, #graphs 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 58\n",
      "Parameter containing:\n",
      "tensor([0.8164], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0638, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0645, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0581, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0706, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0812, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0641, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0634, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 58: precision 0.863751,roc 0.962515, loss 0.055886, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0571, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0610, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0718, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0708, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 58: precision 0.865611,roc 0.963461, loss 0.055464, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0519, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0446, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0465, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0527, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 58: precision 0.868368,roc 0.963958, loss 0.054512, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0059 lr: 0.008100000000000001 train phase of epoch 58: precision 0.869210,roc 0.964332, loss 0.053982, acc 0, ECE 0 #edges 368460, #graphs 92 time: 122.8311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 58: precision 0.869210,roc 0.964332, loss 0.053982, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 122.8321s\n",
      "2.0 1.0 FERMI epoch: 59\n",
      "Parameter containing:\n",
      "tensor([0.8045], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0458, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0450, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0455, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 59: precision 0.871278,roc 0.965734, loss 0.052049, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0625, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0679, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0447, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0565, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0605, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0604, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0532, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 59: precision 0.869592,roc 0.964930, loss 0.053256, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0682, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0469, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0592, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0529, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0531, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 59: precision 0.869553,roc 0.964669, loss 0.053419, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0524, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0448, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0573, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0490, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0499, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0463, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0060 lr: 0.008100000000000001 train phase of epoch 59: precision 0.870502,roc 0.964767, loss 0.053270, acc 0, ECE 0 #edges 368460, #graphs 92 time: 145.0138s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0631, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 59: precision 0.870502,roc 0.964767, loss 0.053270, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 145.0138s\n",
      "92\n",
      "17\n",
      "0.057576874403981675 0.8937063964162444 loss acc\n",
      "17\n",
      "0.057576874403981675 0.8937063964162444 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0060 dev phase of epoch 59: precision 0.857695,roc 0.960890, loss 0.057577, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 60\n",
      "Parameter containing:\n",
      "tensor([0.7976], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0763, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0686, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0495, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0441, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0729, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 60: precision 0.872197,roc 0.965028, loss 0.054399, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0533, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0667, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0668, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0778, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0546, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 60: precision 0.870781,roc 0.963886, loss 0.054974, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0482, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0439, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0453, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0633, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0678, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0442, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0525, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0606, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 60: precision 0.872246,roc 0.964918, loss 0.054084, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0568, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0688, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0561, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0684, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0683, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0470, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0535, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0528, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0061 lr: 0.007290000000000001 train phase of epoch 60: precision 0.871544,roc 0.965094, loss 0.054504, acc 0, ECE 0 #edges 368460, #graphs 92 time: 144.9466s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 60: precision 0.871544,roc 0.965094, loss 0.054504, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 144.9466s\n",
      "2.0 1.0 FERMI epoch: 61\n",
      "Parameter containing:\n",
      "tensor([0.7920], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0569, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0618, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0444, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0558, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0582, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0522, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0659, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0579, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0598, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0479, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0650, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 61: precision 0.872988,roc 0.965184, loss 0.053600, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0508, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0699, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0681, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0457, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0545, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0617, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0472, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 61: precision 0.869857,roc 0.964585, loss 0.054534, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0536, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0608, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0562, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0577, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0473, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0651, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0563, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0476, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0422, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0591, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 61: precision 0.870802,roc 0.965018, loss 0.053664, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0647, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0509, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0584, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0596, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0736, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0622, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0673, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0669, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0505, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0621, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0062 lr: 0.007290000000000001 train phase of epoch 61: precision 0.871639,roc 0.965076, loss 0.054404, acc 0, ECE 0 #edges 368460, #graphs 92 time: 155.2374s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 61: precision 0.871639,roc 0.965076, loss 0.054404, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 155.2374s\n",
      "92\n",
      "17\n",
      "0.057142400451197804 0.8768744951163988 loss acc\n",
      "17\n",
      "0.057142400451197804 0.8768744951163988 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0062 dev phase of epoch 61: precision 0.860556,roc 0.962370, loss 0.057142, acc 0, ECE 0 #edges 68085, #graphs 17\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\test\\pats_CogTr1\\L3\\HGCN_full_findc_id_dp\\e100_p3fr2_lr0.01_val_excl_group_strchinp95_strchloss95_bn_lmse_pneq\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "2.0 1.0 FERMI epoch: 62\n",
      "Parameter containing:\n",
      "tensor([0.7872], requires_grad=True) MODEL C\n",
      "71\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0477, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0474, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0471, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0590, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0553, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0695, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0575, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0676, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0543, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0500, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0492, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0410, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0554, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0496, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0498, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0585, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 62: precision 0.874020,roc 0.966402, loss 0.053230, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0452, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0595, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0566, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0530, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0564, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0911, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0542, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0521, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0772, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0607, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0454, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0512, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0506, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 62: precision 0.872206,roc 0.964861, loss 0.054336, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0587, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0464, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0449, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0468, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0489, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0504, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0588, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0574, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0538, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0483, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0640, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0517, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0629, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0478, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0619, grad_fn=<DivBackward0>) loss by avg\n",
      "69\n",
      "train phase of epoch 62: precision 0.870550,roc 0.964949, loss 0.054032, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "tensor(0.0466, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0548, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0589, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0481, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0459, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0544, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0516, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0636, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0514, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0515, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0507, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0865, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0612, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0556, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0578, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0572, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0567, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0547, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0438, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0493, grad_fn=<DivBackward0>) loss by avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0063 lr: 0.007290000000000001 train phase of epoch 62: precision 0.871996,roc 0.965089, loss 0.054132, acc 0, ECE 0 #edges 368460, #graphs 92 time: 145.4167s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "92\n",
      "train phase of epoch 62: precision 0.871996,roc 0.965089, loss 0.054132, acc 0, ECE 0 #edges 368460, #graphs 92\n",
      "92\n",
      "training epoch done in  time: 145.4167s\n",
      "2.0 1.0 FERMI epoch: 63\n",
      "Parameter containing:\n",
      "tensor([0.7839], requires_grad=True) MODEL C\n",
      "92\n",
      "reset\n",
      "92 train length\n",
      "tensor(0.0488, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0580, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0541, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0586, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0510, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0502, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0551, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0480, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0613, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0513, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0518, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0570, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0862, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0540, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0614, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0467, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0501, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0609, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0497, grad_fn=<DivBackward0>) loss by avg\n",
      "23\n",
      "train phase of epoch 63: precision 0.869357,roc 0.964448, loss 0.055009, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor(0.0494, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0534, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0434, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0602, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0537, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0475, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0484, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0549, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0583, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0456, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0526, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0486, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0552, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0557, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0523, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0560, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0576, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0503, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0593, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0539, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0520, grad_fn=<DivBackward0>) loss by avg\n",
      "46\n",
      "train phase of epoch 63: precision 0.873482,roc 0.965157, loss 0.053989, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "tensor(0.0594, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0511, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0555, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0485, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0491, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0445, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor(0.0487, grad_fn=<DivBackward0>) loss by avg\n",
      "tensor([0.0002], grad_fn=<NegBackward0>) MUST BE NEGATIVE WHAT THE HELL>>\n",
      "Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "error in roc\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] labels\n",
      "[nan nan nan ... nan nan nan] preds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py:199: UserWarning: Error detected in MseLossBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n",
      "    cell_id=cell_id,\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\coleb\\AppData\\Local\\Temp\\ipykernel_22512\\2937922118.py\", line 44, in <module>\n",
      "    complete_study_one_arg(args,NUM_VALIDATIONS)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\", line 277, in complete_study_one_arg\n",
      "    train_inductive.train(args_copy)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\", line 202, in train\n",
      "    metrics = model.compute_metrics(embeddings, data_i, 'train')\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 566, in compute_metrics\n",
      "    metrics = self.loss_handler(edges,edges_false,pos_probs,neg_probs,pos_scores,neg_scores,num_graphs=1)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 409, in loss_handler\n",
      "    neg_loss = l_func(neg_scores,neg_probs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\nn\\functional.py\", line 3292, in mse_loss\n",
      "    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\fx\\traceback.py\", line 57, in format_stack\n",
      "    return traceback.format_stack()\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'MseLossBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22512\\2937922118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0membeddings_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[0mdata_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[1;31m# loss.backward()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_epoch_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;31m# model.update_epoch_stats(metrics, 'train')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'MseLossBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':1,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3,4,2]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d784f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=2\n",
    "criteria={'CogTr':1}\n",
    "criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':0,\n",
    "          'lr':.04,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3,4,2]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "276f1b95",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'manifold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_160\\3393867345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLPModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLPModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFermiDiracDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;31m#### ADD TEMPERATURE DECODER RIGHT HERE!!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'manifold'"
     ]
    }
   ],
   "source": [
    "model = LPModel({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2382116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: 0.54, ID: 0, PLV 1\n",
      "C: 0.54, ID: 0, PLV 1\n",
      "\n",
      "\n",
      "HGCN_full_0.54c_plv_dp model\n",
      "HGCN_full_0.54c_plv_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8 study dir\n",
      "True exists for sure\n",
      "['0', '1', '10', '11', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=50, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_16_12_05_59_099019', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, plv_inp_raw=0, plv_norm_w_id=1, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\\\12', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.591684820481947 new standard\n",
      "-0.19621928570019653 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.5633176932784844 new standard\n",
      "-0.23692516371418681 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.6355866399179227 new standard\n",
      "-0.05884327140024249 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.6305893606932743 new standard\n",
      "-0.06440791242332194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.6551664051028231 new standard\n",
      "0.0008235055915582875 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6098446455064265 new standard\n",
      "-0.13162893779491736 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.6754246706734713 new standard\n",
      "-0.0503832704867866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.6535674796450197 new standard\n",
      "-0.09722998546262496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.6797443578160755 new standard\n",
      "-0.08828993863832367 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.664786318296941 new standard\n",
      "-0.10158655356709333 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6616786775484244 new standard\n",
      "0.012463980401553441 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.6941055187157409 new standard\n",
      "-0.03021286729157688 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.6691801281293318 new standard\n",
      "-0.21889468382028987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.6350525520368432 new standard\n",
      "-0.22280298674049448 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.6558549162545722 new standard\n",
      "-0.05791464047722264 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6503639969918733 new standard\n",
      "-0.07541755240804546 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.5810154257517677 new standard\n",
      "-0.10995182650321486 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.6160692724198047 new standard\n",
      "-0.07863284351604487 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.6473708486967352 new standard\n",
      "-0.08278183314600923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.6388394864671376 new standard\n",
      "-0.07166018113104046 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.6307809207311524 new standard\n",
      "-0.11046207299296361 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.6588010871487916 new standard\n",
      "-0.11226410628973121 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.6370166886233906 new standard\n",
      "-0.17968029249570633 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.6613225485115227 new standard\n",
      "-0.11777339360235413 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.686564818676489 new standard\n",
      "-0.05777834368729739 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6689165721059418 new standard\n",
      "-0.05832041515190725 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.6847809920770506 new standard\n",
      "-0.052739330795819585 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6746143188593097 new standard\n",
      "-0.05961804402582359 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.6548569402332477 new standard\n",
      "-0.14153738710654978 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.5898086538321955 new standard\n",
      "-0.24125136836961306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.668867688772101 new standard\n",
      "0.027763894989252535 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.6356356525778696 new standard\n",
      "0.02160395305811859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6600664144766222 new standard\n",
      "-0.1479370779273647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.6382136678947639 new standard\n",
      "-0.1610394185893834 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.6855823052683518 new standard\n",
      "-0.006450575262116452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.6713437583572579 new standard\n",
      "0.02995514733071667 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.6563121428916823 new standard\n",
      "-0.047391464071941475 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.6497184494685956 new standard\n",
      "-0.05781699815252446 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.6588483361014175 new standard\n",
      "0.0028458098536511167 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.668426908835471 new standard\n",
      "0.06022984059859686 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.6272974462644323 new standard\n",
      "-0.10330008080253753 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.6456091510489137 new standard\n",
      "-0.004584302275264409 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.6241255590313867 new standard\n",
      "-0.027009288747563722 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.6452409077846477 new standard\n",
      "-0.017786571160504753 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.6248248762574444 new standard\n",
      "-0.18034102800090143 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.6315693898720901 new standard\n",
      "-0.16069821371542836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.6514144135172069 new standard\n",
      "-0.08474424890240002 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.6381083977371999 new standard\n",
      "-0.09287984848556677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.6702671721129466 new standard\n",
      "0.07079744079270557 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.5932731172676233 new standard\n",
      "-0.12746675041465813 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.6342383701387992 new standard\n",
      "-0.03519149725770411 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.6491409303825797 new standard\n",
      "-0.09707595697813434 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.6398211703713707 new standard\n",
      "-0.07507817288479728 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.6459091078009382 new standard\n",
      "-0.040145809321510795 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.618704234773595 new standard\n",
      "-0.02591502483881242 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.6277445788614986 new standard\n",
      "-0.08739435472992224 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.6465997678559694 new standard\n",
      "0.020230902952799775 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.6563450009360215 new standard\n",
      "0.10425962268627031 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.6622935726544128 new standard\n",
      "-0.026732705457622977 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.6708993603769791 new standard\n",
      "-0.03783784158929423 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6977754562030356 new standard\n",
      "-0.039490457213739526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.6560869968212414 new standard\n",
      "-0.05835216128412314 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.6557374380199983 new standard\n",
      "-0.10626719756080834 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.6835917071338452 new standard\n",
      "0.004001907215283924 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.6291098160255406 new standard\n",
      "-0.09158232471730422 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.6342335663965073 new standard\n",
      "-0.13022489092372955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.7136694634950574 new standard\n",
      "0.03336201619100097 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.7082995429776927 new standard\n",
      "-0.031523328141878505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.6555784357099717 new standard\n",
      "-0.17937867813289993 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.6656067991466986 new standard\n",
      "-0.16454446513420223 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.6836743811875183 new standard\n",
      "-0.047029249852964077 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.6896336395200783 new standard\n",
      "0.06931271890586135 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.7225822178627245 new standard\n",
      "0.09024859376709438 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.6870234868067668 new standard\n",
      "0.002884941748783678 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.7238803714665085 new standard\n",
      "-0.04877730227352186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.7205133077203674 new standard\n",
      "-0.04276688091122644 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.6561062457405734 new standard\n",
      "-0.05706208625405787 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.6507300324901584 new standard\n",
      "-0.014881217451459757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.6972347074658627 new standard\n",
      "0.12383833047165718 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.6811537618624252 new standard\n",
      "-0.003388109069777935 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.6434208841808606 new standard\n",
      "-0.03862740542558217 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6361222425999005 new standard\n",
      "-0.09873485754036343 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.5886682914284032 new standard\n",
      "0.016006353855762705 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.5643364965961314 new standard\n",
      "-0.06025119193385223 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.6423102934796973 new standard\n",
      "-0.10107705964581569 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.6804468029758424 new standard\n",
      "-0.08754221526384204 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663054242075773 new standard\n",
      "0.04802492683063357 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.6879629192763587 new standard\n",
      "0.054635938609508036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.6565469584193143 new standard\n",
      "-0.06394098789863686 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6568202891701298 new standard\n",
      "-0.002928512504117037 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6551017357375262 new standard\n",
      "-0.10246394130337602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.6336128529173928 new standard\n",
      "-0.17696070323526236 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "0.657480814035368 new standard\n",
      "-0.07468496498720197 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.6735136960868752 new standard\n",
      "-0.03894427950674102 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.653329879548457 new standard\n",
      "-0.012666297796755674 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6736703150003768 new standard\n",
      "0.027285931837510134 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.6585853770052845 new standard\n",
      "0.13575554532074363 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.660319094014825 new standard\n",
      "0.09410894844871867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.5659955503126223 new standard\n",
      "0.052268008520987154 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.5918178276807909 new standard\n",
      "0.04960139581652146 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.6322040543488516 new standard\n",
      "-0.19646546639163578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.6412340697883696 new standard\n",
      "-0.13491578571598797 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.6212753393716759 new standard\n",
      "-0.026763110382222663 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.6493355863817503 new standard\n",
      "0.046611410993035104 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.7286997722864088 new standard\n",
      "0.04317066458298325 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.6920380988109458 new standard\n",
      "0.17763104695719711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.5827576779221979 new standard\n",
      "-0.1661464134361393 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.5942013734072794 new standard\n",
      "-0.12688434142369423 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.674036379430264 new standard\n",
      "-0.08308932283797826 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.6881126733368729 new standard\n",
      "-0.10938843172513228 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.6545613981654312 new standard\n",
      "-0.07974125895348147 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6380995962619183 new standard\n",
      "-0.04952427988343429 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.679200431544665 new standard\n",
      "-0.00997583321804496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.7250748099591909 new standard\n",
      "0.017101537176798055 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.6711731724853667 new standard\n",
      "-0.0566196612188396 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.675784849796036 new standard\n",
      "-0.020811639746592257 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.633521825767872 new standard\n",
      "-0.1048978365310599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.6485684696956839 new standard\n",
      "-0.1342760436349107 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.6726890561270488 new standard\n",
      "-0.07153067304465013 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.6855923842535496 new standard\n",
      "-0.08461276998343792 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.6691843791945087 new standard\n",
      "-0.11944204536002455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.6631234008192056 new standard\n",
      "-0.06228037666951586 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.6318449607181802 new standard\n",
      "0.03893101714331833 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.6789924452960843 new standard\n",
      "0.22731087209821244 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.6435409194322411 new standard\n",
      "-0.13442938596693288 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.6480372779055938 new standard\n",
      "-0.2042541501309706 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.6685758926510753 new standard\n",
      "-0.14319401579813773 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.6370126464204708 new standard\n",
      "-0.13507967706244403 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.6522670036064844 new standard\n",
      "-0.09930223953971667 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.6245947427439127 new standard\n",
      "-0.05918361203467047 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.6197527443375044 new standard\n",
      "-0.18126018201363578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.6368638238997707 new standard\n",
      "-0.1498836350870442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.6424096717709773 new standard\n",
      "-0.08875677311861978 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.71604108634994 new standard\n",
      "0.024218127036827047 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.6956171045434516 new standard\n",
      "-0.048036502509199906 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.6556307718289872 new standard\n",
      "-0.057639343036727186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.6556968237791458 new standard\n",
      "-0.12475691123158174 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.6765462309709099 new standard\n",
      "-0.023094687909982904 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.6379165906214789 new standard\n",
      "-0.09273173335885104 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.6265928468915841 new standard\n",
      "-0.05995795604599936 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.6606155942369542 new standard\n",
      "-0.05843743510059103 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.6662108358857259 new standard\n",
      "-0.07013364755997784 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.6924320194294181 new standard\n",
      "-0.06316699872552402 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.7185515023384693 new standard\n",
      "-0.021689054282551204 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.6636599940662542 new standard\n",
      "-0.034387101469241725 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6565145422858176 new standard\n",
      "0.004464850457743867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.6966293315590382 new standard\n",
      "-0.1186859226260085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.635257238195916 new standard\n",
      "-0.077195623727696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.645812439753755 new standard\n",
      "-0.12394912021506364 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.6575754284492699 new standard\n",
      "-0.12154741655822543 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.6121981538081376 new standard\n",
      "-0.20443894521060849 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.66705273790422 new standard\n",
      "-0.11929205731422532 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.7353249708142713 new standard\n",
      "0.1515451621591199 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.7054457110735272 new standard\n",
      "0.17533545125929897 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.631775093317922 new standard\n",
      "-0.06733993894676513 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.6523630182910423 new standard\n",
      "0.009972909304798178 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.6875538279529687 new standard\n",
      "-0.051485513383839936 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.7225699870026806 new standard\n",
      "-0.02360104284168586 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.6626652999899714 new standard\n",
      "-0.060013912833289745 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.6635821847720548 new standard\n",
      "-0.032371375520300984 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.7246511802753076 new standard\n",
      "0.046505839872251806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.7021933344336352 new standard\n",
      "-0.04380821885182966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.6040303430692191 new standard\n",
      "-0.2473038655137264 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.6411067445179023 new standard\n",
      "-0.14426370160388044 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.5898473415767872 new standard\n",
      "-0.30036330206775574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.6110701579212221 new standard\n",
      "-0.24920772803069483 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.6386237177058004 new standard\n",
      "-0.17151414974949203 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.626390660889379 new standard\n",
      "-0.1290650630640009 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.6275450639502167 new standard\n",
      "-0.11466719452440895 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.6533905467910026 new standard\n",
      "-0.027145878588477085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.6337246312553785 new standard\n",
      "-0.007452589079309381 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.6616799763395268 new standard\n",
      "0.005588371061936213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.63003024408203 new standard\n",
      "-0.16948300845686742 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.6773555828879775 new standard\n",
      "-0.03736170860259576 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6492286975328931 new standard\n",
      "-0.17565403714096336 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.6616476432143804 new standard\n",
      "-0.1239205295145543 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.6774692079055111 new standard\n",
      "-0.14714036437132036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.6798151273704023 new standard\n",
      "-0.18275197412549055 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6249582780295286 new standard\n",
      "-0.15469317129299137 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.6764027799356616 new standard\n",
      "-0.14447376486694416 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=91, out_features=6, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "        (hyp_act): HypAct(c_in=tensor([0.5400]), c_out=tensor([0.5400]))\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=6, out_features=3, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 575.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x000002752F663C18>, <function selu at 0x000002752F663C18>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x000002754201BE48>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.748649,roc 0.926998, loss 0.108440, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.765745,roc 0.932610, loss 0.097510, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.781312,roc 0.940457, loss 0.086870, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.796436,roc 0.945142, loss 0.080825, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.797322,roc 0.945525, loss 0.080383, acc 0, ECE 0 #edges 376470, #graphs 94 time: 104.2636s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 104.2646s\n",
      "94\n",
      "86\n",
      "0.06438864463501613 0.8628952181865688 loss acc\n",
      "86\n",
      "0.06438864463501613 0.8628952181865688 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.846872,roc 0.959597, loss 0.064389, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.828236,roc 0.964932, loss 0.056976, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.860603,roc 0.963714, loss 0.060323, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.868001,roc 0.966212, loss 0.057140, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.877430,roc 0.967593, loss 0.055857, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.881013,roc 0.968258, loss 0.055171, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.881523,roc 0.968320, loss 0.055129, acc 0, ECE 0 #edges 376470, #graphs 94 time: 103.9365s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 103.9365s\n",
      "94\n",
      "86\n",
      "0.053745132694525466 0.8981941178178444 loss acc\n",
      "86\n",
      "0.053745132694525466 0.8981941178178444 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.894059,roc 0.969958, loss 0.053745, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.903218,roc 0.978909, loss 0.044610, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.901472,roc 0.973612, loss 0.050010, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.899257,roc 0.973272, loss 0.050760, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.901539,roc 0.973533, loss 0.050408, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.904359,roc 0.973761, loss 0.049983, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.904485,roc 0.973755, loss 0.050027, acc 0, ECE 0 #edges 376470, #graphs 94 time: 103.2179s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 103.2179s\n",
      "94\n",
      "86\n",
      "0.05042840713525727 0.8997619255001017 loss acc\n",
      "86\n",
      "0.05042840713525727 0.8997619255001017 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.906060,roc 0.973326, loss 0.050428, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.919098,roc 0.982185, loss 0.040985, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.911767,roc 0.975046, loss 0.048987, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.907320,roc 0.974044, loss 0.050188, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.908497,roc 0.974543, loss 0.049398, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.910026,roc 0.974858, loss 0.048997, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.910571,roc 0.975008, loss 0.048852, acc 0, ECE 0 #edges 376470, #graphs 94 time: 105.3234s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 105.3234s\n",
      "94\n",
      "86\n",
      "0.049580228976400194 0.8961850013065065 loss acc\n",
      "86\n",
      "0.049580228976400194 0.8961850013065065 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.910510,roc 0.974756, loss 0.049580, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.925662,roc 0.983507, loss 0.039634, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.915983,roc 0.976330, loss 0.047905, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.913888,roc 0.975949, loss 0.048353, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.913781,roc 0.975799, loss 0.048273, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.914370,roc 0.976006, loss 0.048070, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.914602,roc 0.976029, loss 0.048031, acc 0, ECE 0 #edges 376470, #graphs 94 time: 120.8661s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 120.8661s\n",
      "94\n",
      "86\n",
      "0.048506710065323796 0.9054553900647445 loss acc\n",
      "86\n",
      "0.048506710065323796 0.9054553900647445 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.912733,roc 0.975293, loss 0.048507, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.926701,roc 0.983560, loss 0.040633, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.920456,roc 0.977647, loss 0.045948, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.916027,roc 0.976055, loss 0.047789, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.915787,roc 0.975946, loss 0.047569, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.916053,roc 0.976247, loss 0.047723, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.915874,roc 0.976207, loss 0.047816, acc 0, ECE 0 #edges 376470, #graphs 94 time: 126.2354s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 126.2364s\n",
      "94\n",
      "86\n",
      "0.049386661597061794 0.8955985250994397 loss acc\n",
      "86\n",
      "0.049386661597061794 0.8955985250994397 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.913493,roc 0.974973, loss 0.049387, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.928793,roc 0.983757, loss 0.040073, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.912383,roc 0.976443, loss 0.046970, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.913345,roc 0.975378, loss 0.048692, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.914869,roc 0.976194, loss 0.047879, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.916245,roc 0.976380, loss 0.047588, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.916717,roc 0.976471, loss 0.047518, acc 0, ECE 0 #edges 376470, #graphs 94 time: 129.1170s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 129.1170s\n",
      "94\n",
      "86\n",
      "0.04807356091270855 0.9104607612577301 loss acc\n",
      "86\n",
      "0.04807356091270855 0.9104607612577301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.916068,roc 0.975913, loss 0.048074, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.930762,roc 0.984491, loss 0.040143, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.917449,roc 0.976091, loss 0.047571, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.919489,roc 0.976977, loss 0.047384, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.918963,roc 0.977022, loss 0.047133, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.918301,roc 0.976822, loss 0.047204, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.918409,roc 0.976862, loss 0.047147, acc 0, ECE 0 #edges 376470, #graphs 94 time: 126.3680s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 126.3680s\n",
      "94\n",
      "86\n",
      "0.04791965250393688 0.9054641001074242 loss acc\n",
      "86\n",
      "0.04791965250393688 0.9054641001074242 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.914821,roc 0.975800, loss 0.047920, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.930497,roc 0.984503, loss 0.039627, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.921866,roc 0.977281, loss 0.046025, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.919308,roc 0.977238, loss 0.046703, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.918921,roc 0.976995, loss 0.047154, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.918491,roc 0.976967, loss 0.047100, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.918651,roc 0.976976, loss 0.047043, acc 0, ECE 0 #edges 376470, #graphs 94 time: 148.5108s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 148.5108s\n",
      "94\n",
      "86\n",
      "0.048160573836810106 0.9096913741543999 loss acc\n",
      "86\n",
      "0.048160573836810106 0.9096913741543999 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.915976,roc 0.975777, loss 0.048161, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.929815,roc 0.984081, loss 0.040712, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.922037,roc 0.978177, loss 0.046156, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.920337,roc 0.977221, loss 0.046986, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.918480,roc 0.976851, loss 0.047001, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.920442,roc 0.977493, loss 0.046425, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.920655,roc 0.977611, loss 0.046303, acc 0, ECE 0 #edges 376470, #graphs 94 time: 163.2790s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 163.2790s\n",
      "94\n",
      "86\n",
      "0.047182161788795016 0.905414743198908 loss acc\n",
      "86\n",
      "0.047182161788795016 0.905414743198908 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.919419,roc 0.976821, loss 0.047182, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.934562,roc 0.985364, loss 0.038577, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.923975,roc 0.979765, loss 0.044109, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.923178,roc 0.978875, loss 0.045031, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.921251,roc 0.977615, loss 0.046223, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.921752,roc 0.977816, loss 0.046251, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.922021,roc 0.977893, loss 0.046167, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.8168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.8168s\n",
      "94\n",
      "86\n",
      "0.04822730466341055 0.8956217518799174 loss acc\n",
      "86\n",
      "0.04822730466341055 0.8956217518799174 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.919282,roc 0.976625, loss 0.048227, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.934056,roc 0.985158, loss 0.038567, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.927608,roc 0.979151, loss 0.044787, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.922391,roc 0.978322, loss 0.045933, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.921418,roc 0.977485, loss 0.046711, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.922435,roc 0.978022, loss 0.046095, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.922409,roc 0.977991, loss 0.046117, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.1356s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.1356s\n",
      "94\n",
      "86\n",
      "0.04753091280120568 0.8968585779403657 loss acc\n",
      "86\n",
      "0.04753091280120568 0.8968585779403657 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.919854,roc 0.976998, loss 0.047531, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.935594,roc 0.985661, loss 0.037899, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.916071,roc 0.975669, loss 0.048570, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.919577,roc 0.977051, loss 0.046934, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.921053,roc 0.977790, loss 0.046265, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.922256,roc 0.978020, loss 0.046034, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.922364,roc 0.978052, loss 0.046031, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.4357s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.4357s\n",
      "94\n",
      "86\n",
      "0.04766267551841221 0.9123130970008418 loss acc\n",
      "86\n",
      "0.04766267551841221 0.9123130970008418 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.917603,roc 0.976244, loss 0.047663, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.935368,roc 0.985580, loss 0.038903, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.926538,roc 0.980273, loss 0.044428, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.923953,roc 0.978170, loss 0.046119, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.925265,roc 0.978759, loss 0.045422, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.923385,roc 0.978177, loss 0.045813, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.923485,roc 0.978273, loss 0.045640, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.3066s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.3066s\n",
      "94\n",
      "86\n",
      "0.04775853116456049 0.9018000754870361 loss acc\n",
      "86\n",
      "0.04775853116456049 0.9018000754870361 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.918611,roc 0.976410, loss 0.047759, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.933896,roc 0.985064, loss 0.038333, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.918334,roc 0.976969, loss 0.046916, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.922076,roc 0.977985, loss 0.045885, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.922905,roc 0.978111, loss 0.045706, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.923533,roc 0.978399, loss 0.045671, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.923787,roc 0.978354, loss 0.045666, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.0202s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.0202s\n",
      "94\n",
      "86\n",
      "0.04664962528633746 0.9027843103097867 loss acc\n",
      "86\n",
      "0.04664962528633746 0.9027843103097867 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.921373,roc 0.977421, loss 0.046650, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.936608,roc 0.985987, loss 0.037492, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.925551,roc 0.979021, loss 0.045324, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.923428,roc 0.978480, loss 0.045773, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.924347,roc 0.978640, loss 0.045280, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.925012,roc 0.978755, loss 0.045213, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.924685,roc 0.978718, loss 0.045227, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.3274s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.3274s\n",
      "94\n",
      "86\n",
      "0.04752954840948848 0.9015039340359433 loss acc\n",
      "86\n",
      "0.04752954840948848 0.9015039340359433 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.918759,roc 0.976354, loss 0.047530, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.932939,roc 0.984651, loss 0.039307, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.927779,roc 0.979491, loss 0.044138, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.925858,roc 0.978180, loss 0.044912, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.925012,roc 0.978795, loss 0.044684, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.924409,roc 0.978526, loss 0.045240, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.924359,roc 0.978530, loss 0.045331, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.0528s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.0528s\n",
      "94\n",
      "86\n",
      "0.04665014242535301 0.910643672153994 loss acc\n",
      "86\n",
      "0.04665014242535301 0.910643672153994 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.920713,roc 0.977176, loss 0.046650, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.934648,roc 0.985330, loss 0.038978, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.925212,roc 0.978970, loss 0.044294, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.922706,roc 0.978607, loss 0.045440, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.923786,roc 0.978960, loss 0.044940, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.924776,roc 0.978804, loss 0.044925, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.925088,roc 0.978822, loss 0.044967, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.9285s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.9285s\n",
      "94\n",
      "86\n",
      "0.046532399053894224 0.9095055599105769 loss acc\n",
      "86\n",
      "0.046532399053894224 0.9095055599105769 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.921935,roc 0.977110, loss 0.046532, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.935198,roc 0.985242, loss 0.039387, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.926617,roc 0.978733, loss 0.045766, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.926200,roc 0.979187, loss 0.045035, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.925972,roc 0.979139, loss 0.044833, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.925689,roc 0.978924, loss 0.045023, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.926107,roc 0.979056, loss 0.044876, acc 0, ECE 0 #edges 376470, #graphs 94 time: 175.8136s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 175.8136s\n",
      "94\n",
      "86\n",
      "0.04641978623772214 0.9161455157796938 loss acc\n",
      "86\n",
      "0.04641978623772214 0.9161455157796938 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.922115,roc 0.977520, loss 0.046420, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.936448,roc 0.985694, loss 0.039401, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.928150,roc 0.979442, loss 0.044145, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.928722,roc 0.979687, loss 0.044030, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.928007,roc 0.979555, loss 0.044160, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.926412,roc 0.979167, loss 0.044746, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.926237,roc 0.979077, loss 0.044799, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.7902s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.7902s\n",
      "94\n",
      "86\n",
      "0.04640899028459371 0.9163690735417943 loss acc\n",
      "86\n",
      "0.04640899028459371 0.9163690735417943 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.922327,roc 0.977538, loss 0.046409, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.937115,roc 0.986015, loss 0.039302, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.920922,roc 0.977629, loss 0.045891, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.926587,roc 0.978871, loss 0.044617, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.924560,roc 0.978356, loss 0.045464, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.926803,roc 0.979229, loss 0.044762, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.926764,roc 0.979266, loss 0.044734, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.2613s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.2613s\n",
      "94\n",
      "86\n",
      "0.04582688960179584 0.9093691025752692 loss acc\n",
      "86\n",
      "0.04582688960179584 0.9093691025752692 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.923736,roc 0.977938, loss 0.045827, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.939737,roc 0.986634, loss 0.037588, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.932504,roc 0.980692, loss 0.043786, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.932312,roc 0.981043, loss 0.043095, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.927367,roc 0.979439, loss 0.044515, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.927476,roc 0.979573, loss 0.044381, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.927493,roc 0.979463, loss 0.044444, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.8218s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.8374s\n",
      "94\n",
      "86\n",
      "0.0472380451503253 0.900929071219116 loss acc\n",
      "86\n",
      "0.0472380451503253 0.900929071219116 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.920106,roc 0.976812, loss 0.047238, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.936344,roc 0.985767, loss 0.037631, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.928970,roc 0.980550, loss 0.043705, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.929336,roc 0.980216, loss 0.044090, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.926535,roc 0.979266, loss 0.044610, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.926807,roc 0.979276, loss 0.044481, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.926630,roc 0.979223, loss 0.044568, acc 0, ECE 0 #edges 376470, #graphs 94 time: 180.0810s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 180.0810s\n",
      "94\n",
      "86\n",
      "0.04575872896929421 0.9129605435066633 loss acc\n",
      "86\n",
      "0.04575872896929421 0.9129605435066633 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.923815,roc 0.977906, loss 0.045759, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.934682,roc 0.985142, loss 0.039939, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.927587,roc 0.979406, loss 0.044293, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.926323,roc 0.979197, loss 0.044474, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.927648,roc 0.979483, loss 0.044412, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.927421,roc 0.979493, loss 0.044402, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.927608,roc 0.979521, loss 0.044411, acc 0, ECE 0 #edges 376470, #graphs 94 time: 163.8863s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 163.8863s\n",
      "94\n",
      "86\n",
      "0.04646642083119017 0.9056528176988067 loss acc\n",
      "86\n",
      "0.04646642083119017 0.9056528176988067 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.922218,roc 0.977307, loss 0.046466, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.930973,roc 0.984104, loss 0.039898, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.932601,roc 0.979946, loss 0.044143, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.927968,roc 0.979282, loss 0.044449, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.928033,roc 0.979223, loss 0.044621, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.927845,roc 0.979379, loss 0.044512, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.927306,roc 0.979333, loss 0.044536, acc 0, ECE 0 #edges 376470, #graphs 94 time: 172.6464s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 172.6474s\n",
      "94\n",
      "86\n",
      "0.04614058883010861 0.911610486891386 loss acc\n",
      "86\n",
      "0.04614058883010861 0.911610486891386 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.922879,roc 0.977618, loss 0.046141, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.938060,roc 0.986139, loss 0.038316, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.931373,roc 0.979904, loss 0.043495, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.926269,roc 0.978938, loss 0.044556, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.927274,roc 0.979293, loss 0.044643, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.927339,roc 0.979425, loss 0.044386, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.927320,roc 0.979416, loss 0.044377, acc 0, ECE 0 #edges 376470, #graphs 94 time: 182.8288s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 182.8384s\n",
      "94\n",
      "86\n",
      "0.04556495169122788 0.9102691403187879 loss acc\n",
      "86\n",
      "0.04556495169122788 0.9102691403187879 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.924364,roc 0.978138, loss 0.045565, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.938032,roc 0.986182, loss 0.037927, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.927235,roc 0.979840, loss 0.044519, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.926666,roc 0.979206, loss 0.044561, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.928810,roc 0.979635, loss 0.043973, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.928375,roc 0.979653, loss 0.043992, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.928139,roc 0.979648, loss 0.044075, acc 0, ECE 0 #edges 376470, #graphs 94 time: 181.9589s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 181.9609s\n",
      "94\n",
      "86\n",
      "0.04551265006128034 0.9112940220073745 loss acc\n",
      "86\n",
      "0.04551265006128034 0.9112940220073745 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.924903,roc 0.978135, loss 0.045513, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.936559,roc 0.985742, loss 0.038912, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.931378,roc 0.979867, loss 0.043009, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.928336,roc 0.979209, loss 0.043946, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.926789,roc 0.979471, loss 0.043975, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.928225,roc 0.979628, loss 0.044173, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.928067,roc 0.979628, loss 0.044190, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.7042s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.7172s\n",
      "94\n",
      "86\n",
      "0.04548986368963237 0.9118398513486049 loss acc\n",
      "86\n",
      "0.04548986368963237 0.9118398513486049 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.923888,roc 0.978103, loss 0.045490, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.937640,roc 0.986106, loss 0.038042, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.928589,roc 0.979501, loss 0.044591, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.928302,roc 0.980305, loss 0.043874, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.926593,roc 0.979525, loss 0.044227, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.927605,roc 0.979580, loss 0.044119, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.927888,roc 0.979654, loss 0.044039, acc 0, ECE 0 #edges 376470, #graphs 94 time: 171.9716s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 171.9736s\n",
      "94\n",
      "86\n",
      "0.04560756880002971 0.9121708329704152 loss acc\n",
      "86\n",
      "0.04560756880002971 0.9121708329704152 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.924803,roc 0.978131, loss 0.045608, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.936258,roc 0.985562, loss 0.039215, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 29 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 29: precision 0.926555,roc 0.981226, loss 0.043081, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 29: precision 0.928563,roc 0.980646, loss 0.043651, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 29: precision 0.928467,roc 0.979914, loss 0.044013, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 29: precision 0.928326,roc 0.979616, loss 0.044179, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.0189 train phase of epoch 29: precision 0.928402,roc 0.979642, loss 0.044169, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.8250s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.8260s\n",
      "94\n",
      "86\n",
      "0.04642007983478333 0.9049211741137536 loss acc\n",
      "86\n",
      "0.04642007983478333 0.9049211741137536 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.923446,roc 0.977717, loss 0.046420, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0030 test phase of epoch 29: precision 0.939681,roc 0.986572, loss 0.037180, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 30 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 30: precision 0.929292,roc 0.979546, loss 0.043953, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 30: precision 0.929982,roc 0.980236, loss 0.043379, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 30: precision 0.928462,roc 0.979431, loss 0.043937, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 30: precision 0.928051,roc 0.979660, loss 0.043962, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.0189 train phase of epoch 30: precision 0.928023,roc 0.979624, loss 0.044021, acc 0, ECE 0 #edges 376470, #graphs 94 time: 172.2500s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 172.2500s\n",
      "94\n",
      "86\n",
      "0.04572509093967156 0.9074935400516795 loss acc\n",
      "86\n",
      "0.04572509093967156 0.9074935400516795 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0031 dev phase of epoch 30: precision 0.925329,roc 0.978209, loss 0.045725, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0031 test phase of epoch 30: precision 0.939368,roc 0.986413, loss 0.037690, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 31 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 31: precision 0.928474,roc 0.978687, loss 0.044323, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 31: precision 0.929164,roc 0.979369, loss 0.044031, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 31: precision 0.927557,roc 0.979522, loss 0.044193, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 31: precision 0.928290,roc 0.979708, loss 0.044145, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.0189 train phase of epoch 31: precision 0.928432,roc 0.979731, loss 0.044075, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.5737s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.5737s\n",
      "94\n",
      "86\n",
      "0.04529846252822465 0.9141160758354379 loss acc\n",
      "86\n",
      "0.04529846252822465 0.9141160758354379 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.925165,roc 0.978323, loss 0.045298, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0032 test phase of epoch 31: precision 0.937155,roc 0.985783, loss 0.039136, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 32 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 32: precision 0.923282,roc 0.977330, loss 0.045576, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 32: precision 0.927661,roc 0.979191, loss 0.044340, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 32: precision 0.927502,roc 0.979289, loss 0.044543, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 32: precision 0.929027,roc 0.979888, loss 0.043874, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.0189 train phase of epoch 32: precision 0.929142,roc 0.979898, loss 0.043919, acc 0, ECE 0 #edges 376470, #graphs 94 time: 162.1557s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 162.1567s\n",
      "94\n",
      "86\n",
      "0.045466034750849434 0.9071451383445109 loss acc\n",
      "86\n",
      "0.045466034750849434 0.9071451383445109 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0033 dev phase of epoch 32: precision 0.925258,roc 0.978262, loss 0.045466, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0033 test phase of epoch 32: precision 0.936351,roc 0.985571, loss 0.038635, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 33 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 33: precision 0.930871,roc 0.980117, loss 0.043752, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 33: precision 0.927855,roc 0.980032, loss 0.043831, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 33: precision 0.928831,roc 0.979870, loss 0.043866, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 33: precision 0.928672,roc 0.979729, loss 0.044056, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.0189 train phase of epoch 33: precision 0.928889,roc 0.979870, loss 0.043924, acc 0, ECE 0 #edges 376470, #graphs 94 time: 212.9088s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 212.9108s\n",
      "94\n",
      "86\n",
      "0.04621085622414378 0.9060970298754473 loss acc\n",
      "86\n",
      "0.04621085622414378 0.9060970298754473 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.923773,roc 0.977611, loss 0.046211, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0034 test phase of epoch 33: precision 0.937872,roc 0.986037, loss 0.037999, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 34 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 34: precision 0.930959,roc 0.979783, loss 0.043925, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 34: precision 0.930205,roc 0.979933, loss 0.043745, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 34: precision 0.928535,roc 0.979770, loss 0.044037, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 34: precision 0.929843,roc 0.980161, loss 0.043643, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.0189 train phase of epoch 34: precision 0.929511,roc 0.980030, loss 0.043743, acc 0, ECE 0 #edges 376470, #graphs 94 time: 179.0881s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 179.0881s\n",
      "94\n",
      "86\n",
      "0.04547360979082693 0.9105275382516038 loss acc\n",
      "86\n",
      "0.04547360979082693 0.9105275382516038 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0035 dev phase of epoch 34: precision 0.925399,roc 0.978315, loss 0.045474, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0035 test phase of epoch 34: precision 0.938291,roc 0.986050, loss 0.038230, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 35 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 35: precision 0.924433,roc 0.979609, loss 0.044254, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 35: precision 0.929897,roc 0.980993, loss 0.042979, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 35: precision 0.929241,roc 0.980139, loss 0.043664, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 35: precision 0.929036,roc 0.979864, loss 0.043946, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.0189 train phase of epoch 35: precision 0.929219,roc 0.979921, loss 0.043832, acc 0, ECE 0 #edges 376470, #graphs 94 time: 222.3035s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 222.3055s\n",
      "94\n",
      "86\n",
      "0.046032586631251066 0.9115843567633483 loss acc\n",
      "86\n",
      "0.046032586631251066 0.9115843567633483 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.922933,roc 0.977668, loss 0.046033, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0036 test phase of epoch 35: precision 0.940180,roc 0.986841, loss 0.037385, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 36 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 36: precision 0.927534,roc 0.979089, loss 0.043992, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 36: precision 0.928123,roc 0.979596, loss 0.044005, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 36: precision 0.927448,roc 0.979513, loss 0.044046, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 36: precision 0.929011,roc 0.979875, loss 0.043864, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.0189 train phase of epoch 36: precision 0.929323,roc 0.979982, loss 0.043744, acc 0, ECE 0 #edges 376470, #graphs 94 time: 222.5264s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 222.5274s\n",
      "94\n",
      "86\n",
      "0.04527118490982926 0.9130824841041725 loss acc\n",
      "86\n",
      "0.04527118490982926 0.9130824841041725 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0037 dev phase of epoch 36: precision 0.925326,roc 0.978346, loss 0.045271, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0037 test phase of epoch 36: precision 0.939582,roc 0.986512, loss 0.037991, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 37 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 37: precision 0.932975,roc 0.982104, loss 0.041523, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 37: precision 0.929191,roc 0.980274, loss 0.042917, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 37: precision 0.930170,roc 0.980256, loss 0.043430, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 37: precision 0.929608,roc 0.980256, loss 0.043454, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.0189 train phase of epoch 37: precision 0.929134,roc 0.979919, loss 0.043755, acc 0, ECE 0 #edges 376470, #graphs 94 time: 207.9917s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 207.9937s\n",
      "94\n",
      "86\n",
      "0.04613313538342763 0.9049734343698284 loss acc\n",
      "86\n",
      "0.04613313538342763 0.9049734343698284 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.925035,roc 0.977992, loss 0.046133, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0038 test phase of epoch 37: precision 0.938555,roc 0.986037, loss 0.038169, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 38 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 38: precision 0.931390,roc 0.979823, loss 0.044378, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 38: precision 0.929593,roc 0.980093, loss 0.043658, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 38: precision 0.930251,roc 0.980205, loss 0.043537, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 38: precision 0.929815,roc 0.980173, loss 0.043501, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.0189 train phase of epoch 38: precision 0.929453,roc 0.980037, loss 0.043627, acc 0, ECE 0 #edges 376470, #graphs 94 time: 201.6953s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 201.6984s\n",
      "94\n",
      "86\n",
      "0.04522691808266712 0.911366605696368 loss acc\n",
      "86\n",
      "0.04522691808266712 0.911366605696368 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0039 dev phase of epoch 38: precision 0.925829,roc 0.978409, loss 0.045227, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0039 test phase of epoch 38: precision 0.938427,roc 0.986114, loss 0.038294, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 39 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 39: precision 0.932052,roc 0.981097, loss 0.042123, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 39: precision 0.930952,roc 0.980764, loss 0.043037, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 39: precision 0.930684,roc 0.980505, loss 0.043173, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 39: precision 0.929505,roc 0.980078, loss 0.043690, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.0189 train phase of epoch 39: precision 0.929824,roc 0.980165, loss 0.043573, acc 0, ECE 0 #edges 376470, #graphs 94 time: 202.7934s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 202.7938s\n",
      "94\n",
      "86\n",
      "0.04555347922973447 0.9107714194466218 loss acc\n",
      "86\n",
      "0.04555347922973447 0.9107714194466218 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.925281,roc 0.978268, loss 0.045553, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0040 test phase of epoch 39: precision 0.937803,roc 0.986035, loss 0.038398, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 40 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 40: precision 0.930583,roc 0.980836, loss 0.042722, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 40: precision 0.929868,roc 0.980204, loss 0.043245, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 40: precision 0.930205,roc 0.980069, loss 0.043419, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 40: precision 0.929519,roc 0.980024, loss 0.043617, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.01701 train phase of epoch 40: precision 0.929788,roc 0.980148, loss 0.043492, acc 0, ECE 0 #edges 376470, #graphs 94 time: 180.1742s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 180.1742s\n",
      "94\n",
      "86\n",
      "0.04588084587924198 0.9016142612432139 loss acc\n",
      "86\n",
      "0.04588084587924198 0.9016142612432139 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0041 dev phase of epoch 40: precision 0.925357,roc 0.978251, loss 0.045881, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0041 test phase of epoch 40: precision 0.939908,roc 0.986446, loss 0.037415, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 41 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 41: precision 0.933184,roc 0.980628, loss 0.043283, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 41: precision 0.931929,roc 0.981072, loss 0.042712, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 41: precision 0.931375,roc 0.980844, loss 0.042738, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 41: precision 0.929909,roc 0.980299, loss 0.043489, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.01701 train phase of epoch 41: precision 0.929844,roc 0.980121, loss 0.043599, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.5064s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.5064s\n",
      "94\n",
      "86\n",
      "0.04501235299438843 0.9132624916528757 loss acc\n",
      "86\n",
      "0.04501235299438843 0.9132624916528757 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.926441,roc 0.978652, loss 0.045012, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0042 test phase of epoch 41: precision 0.937856,roc 0.986021, loss 0.038732, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 42 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 42: precision 0.926631,roc 0.978966, loss 0.044037, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 42: precision 0.927567,roc 0.979874, loss 0.043603, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 42: precision 0.928072,roc 0.979463, loss 0.044116, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 42: precision 0.929435,roc 0.980014, loss 0.043784, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.01701 train phase of epoch 42: precision 0.929623,roc 0.980049, loss 0.043720, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.1155s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.1155s\n",
      "94\n",
      "86\n",
      "0.045020688178995 0.9119792120314721 loss acc\n",
      "86\n",
      "0.045020688178995 0.9119792120314721 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0043 dev phase of epoch 42: precision 0.925983,roc 0.978516, loss 0.045021, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0043 test phase of epoch 42: precision 0.939577,roc 0.986484, loss 0.037836, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 43 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 43: precision 0.931364,roc 0.980675, loss 0.043196, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 43: precision 0.930324,roc 0.979757, loss 0.043433, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 43: precision 0.928676,roc 0.979842, loss 0.043657, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 43: precision 0.929588,roc 0.980045, loss 0.043542, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.01701 train phase of epoch 43: precision 0.929697,roc 0.980047, loss 0.043527, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.4729s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.4729s\n",
      "94\n",
      "86\n",
      "0.04540219863466258 0.9079987225270735 loss acc\n",
      "86\n",
      "0.04540219863466258 0.9079987225270735 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.925907,roc 0.978450, loss 0.045402, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0044 test phase of epoch 43: precision 0.939397,roc 0.986461, loss 0.037322, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 44 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 44: precision 0.928460,roc 0.978362, loss 0.044702, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 44: precision 0.928114,roc 0.979408, loss 0.044179, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 44: precision 0.928830,roc 0.979649, loss 0.043995, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 44: precision 0.930166,roc 0.980147, loss 0.043396, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.01701 train phase of epoch 44: precision 0.929633,roc 0.980027, loss 0.043531, acc 0, ECE 0 #edges 376470, #graphs 94 time: 174.2540s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 174.2540s\n",
      "94\n",
      "86\n",
      "0.046009443020190485 0.9033882066022128 loss acc\n",
      "86\n",
      "0.046009443020190485 0.9033882066022128 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0045 dev phase of epoch 44: precision 0.924955,roc 0.978103, loss 0.046009, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0045 test phase of epoch 44: precision 0.941412,roc 0.986950, loss 0.036730, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 45 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 45: precision 0.930684,roc 0.980766, loss 0.043742, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 45: precision 0.930214,roc 0.980391, loss 0.043472, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 45: precision 0.930233,roc 0.980301, loss 0.043289, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 45: precision 0.929208,roc 0.979982, loss 0.043663, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.01701 train phase of epoch 45: precision 0.929335,roc 0.980015, loss 0.043646, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.2665s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.2665s\n",
      "94\n",
      "86\n",
      "0.0455379552811782 0.9098278314897076 loss acc\n",
      "86\n",
      "0.0455379552811782 0.9098278314897076 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.924614,roc 0.978097, loss 0.045538, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0046 test phase of epoch 45: precision 0.939019,roc 0.986307, loss 0.038086, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 46 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 46: precision 0.926743,roc 0.979592, loss 0.043919, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 46: precision 0.928389,roc 0.979926, loss 0.043602, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 46: precision 0.927523,roc 0.979333, loss 0.044092, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 46: precision 0.929162,roc 0.979970, loss 0.043646, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0047 lr: 0.01701 train phase of epoch 46: precision 0.929216,roc 0.979985, loss 0.043655, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.5552s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.5552s\n",
      "94\n",
      "86\n",
      "0.0460243598333048 0.9055744273146936 loss acc\n",
      "86\n",
      "0.0460243598333048 0.9055744273146936 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0047 dev phase of epoch 46: precision 0.923851,roc 0.977640, loss 0.046024, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0047 test phase of epoch 46: precision 0.933903,roc 0.984645, loss 0.039743, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 47 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 47: precision 0.924668,roc 0.977776, loss 0.045699, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 47: precision 0.927365,roc 0.979067, loss 0.044265, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 47: precision 0.929398,roc 0.979707, loss 0.043774, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 47: precision 0.930288,roc 0.980141, loss 0.043488, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0048 lr: 0.01701 train phase of epoch 47: precision 0.930172,roc 0.980164, loss 0.043479, acc 0, ECE 0 #edges 376470, #graphs 94 time: 174.2460s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 174.2460s\n",
      "94\n",
      "86\n",
      "0.045258438794531244 0.9104810846906487 loss acc\n",
      "86\n",
      "0.045258438794531244 0.9104810846906487 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0048 dev phase of epoch 47: precision 0.925575,roc 0.978274, loss 0.045258, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0048 test phase of epoch 47: precision 0.938468,roc 0.985977, loss 0.038488, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 10593.8370s\n",
      "INFO:root:Val set results: dev phase of epoch 41: precision 0.926441,roc 0.978652, loss 0.045012, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 41: precision 0.937856,roc 0.986021, loss 0.038732, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 41, 'loss': 0.04501235299438843, 'roc': 0.9786518716147252, 'ap': 0.9264414615099088, 'acc': 0.9132624916528757, 'ECE': 0.0}\n",
      "0.04501235299438843 val mets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=50, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_16_12_05_59_099019', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, plv_inp_raw=0, plv_norm_w_id=1, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\\\14', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.591684820481947 new standard\n",
      "-0.19621928570019653 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.5633176932784844 new standard\n",
      "-0.23692516371418681 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.6355866399179227 new standard\n",
      "-0.05884327140024249 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.6305893606932743 new standard\n",
      "-0.06440791242332194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.6551664051028231 new standard\n",
      "0.0008235055915582875 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6098446455064265 new standard\n",
      "-0.13162893779491736 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.6754246706734713 new standard\n",
      "-0.0503832704867866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.6535674796450197 new standard\n",
      "-0.09722998546262496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.6797443578160755 new standard\n",
      "-0.08828993863832367 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.664786318296941 new standard\n",
      "-0.10158655356709333 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6616786775484244 new standard\n",
      "0.012463980401553441 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.6941055187157409 new standard\n",
      "-0.03021286729157688 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.6691801281293318 new standard\n",
      "-0.21889468382028987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.6350525520368432 new standard\n",
      "-0.22280298674049448 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.6558549162545722 new standard\n",
      "-0.05791464047722264 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6503639969918733 new standard\n",
      "-0.07541755240804546 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.5810154257517677 new standard\n",
      "-0.10995182650321486 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.6160692724198047 new standard\n",
      "-0.07863284351604487 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.6473708486967352 new standard\n",
      "-0.08278183314600923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.6388394864671376 new standard\n",
      "-0.07166018113104046 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.6307809207311524 new standard\n",
      "-0.11046207299296361 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.6588010871487916 new standard\n",
      "-0.11226410628973121 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.6370166886233906 new standard\n",
      "-0.17968029249570633 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.6613225485115227 new standard\n",
      "-0.11777339360235413 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.686564818676489 new standard\n",
      "-0.05777834368729739 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6689165721059418 new standard\n",
      "-0.05832041515190725 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.6847809920770506 new standard\n",
      "-0.052739330795819585 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6746143188593097 new standard\n",
      "-0.05961804402582359 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.6548569402332477 new standard\n",
      "-0.14153738710654978 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.5898086538321955 new standard\n",
      "-0.24125136836961306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.668867688772101 new standard\n",
      "0.027763894989252535 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.6356356525778696 new standard\n",
      "0.02160395305811859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6600664144766222 new standard\n",
      "-0.1479370779273647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.6382136678947639 new standard\n",
      "-0.1610394185893834 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.6855823052683518 new standard\n",
      "-0.006450575262116452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.6713437583572579 new standard\n",
      "0.02995514733071667 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.6563121428916823 new standard\n",
      "-0.047391464071941475 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.6497184494685956 new standard\n",
      "-0.05781699815252446 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.6588483361014175 new standard\n",
      "0.0028458098536511167 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.668426908835471 new standard\n",
      "0.06022984059859686 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.6272974462644323 new standard\n",
      "-0.10330008080253753 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.6456091510489137 new standard\n",
      "-0.004584302275264409 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.6241255590313867 new standard\n",
      "-0.027009288747563722 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.6452409077846477 new standard\n",
      "-0.017786571160504753 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.6248248762574444 new standard\n",
      "-0.18034102800090143 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.6315693898720901 new standard\n",
      "-0.16069821371542836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.6514144135172069 new standard\n",
      "-0.08474424890240002 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.6381083977371999 new standard\n",
      "-0.09287984848556677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.6702671721129466 new standard\n",
      "0.07079744079270557 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.5932731172676233 new standard\n",
      "-0.12746675041465813 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.6342383701387992 new standard\n",
      "-0.03519149725770411 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.6491409303825797 new standard\n",
      "-0.09707595697813434 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.6398211703713707 new standard\n",
      "-0.07507817288479728 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.6459091078009382 new standard\n",
      "-0.040145809321510795 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.618704234773595 new standard\n",
      "-0.02591502483881242 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.6277445788614986 new standard\n",
      "-0.08739435472992224 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.6465997678559694 new standard\n",
      "0.020230902952799775 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.6563450009360215 new standard\n",
      "0.10425962268627031 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.6622935726544128 new standard\n",
      "-0.026732705457622977 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.6708993603769791 new standard\n",
      "-0.03783784158929423 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.6977754562030356 new standard\n",
      "-0.039490457213739526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.6560869968212414 new standard\n",
      "-0.05835216128412314 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.6557374380199983 new standard\n",
      "-0.10626719756080834 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.6835917071338452 new standard\n",
      "0.004001907215283924 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.6291098160255406 new standard\n",
      "-0.09158232471730422 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.6342335663965073 new standard\n",
      "-0.13022489092372955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.7136694634950574 new standard\n",
      "0.03336201619100097 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.7082995429776927 new standard\n",
      "-0.031523328141878505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.6555784357099717 new standard\n",
      "-0.17937867813289993 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.6656067991466986 new standard\n",
      "-0.16454446513420223 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.6836743811875183 new standard\n",
      "-0.047029249852964077 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.6896336395200783 new standard\n",
      "0.06931271890586135 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.7225822178627245 new standard\n",
      "0.09024859376709438 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.6870234868067668 new standard\n",
      "0.002884941748783678 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.7238803714665085 new standard\n",
      "-0.04877730227352186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.7205133077203674 new standard\n",
      "-0.04276688091122644 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.6561062457405734 new standard\n",
      "-0.05706208625405787 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.6507300324901584 new standard\n",
      "-0.014881217451459757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.6972347074658627 new standard\n",
      "0.12383833047165718 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.6811537618624252 new standard\n",
      "-0.003388109069777935 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.6434208841808606 new standard\n",
      "-0.03862740542558217 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6361222425999005 new standard\n",
      "-0.09873485754036343 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.5886682914284032 new standard\n",
      "0.016006353855762705 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.5643364965961314 new standard\n",
      "-0.06025119193385223 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6423102934796973 new standard\n",
      "-0.10107705964581569 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.6804468029758424 new standard\n",
      "-0.08754221526384204 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.663054242075773 new standard\n",
      "0.04802492683063357 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.6879629192763587 new standard\n",
      "0.054635938609508036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.6565469584193143 new standard\n",
      "-0.06394098789863686 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6568202891701298 new standard\n",
      "-0.002928512504117037 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6551017357375262 new standard\n",
      "-0.10246394130337602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.6336128529173928 new standard\n",
      "-0.17696070323526236 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "0.657480814035368 new standard\n",
      "-0.07468496498720197 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.6735136960868752 new standard\n",
      "-0.03894427950674102 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.653329879548457 new standard\n",
      "-0.012666297796755674 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.6736703150003768 new standard\n",
      "0.027285931837510134 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.6585853770052845 new standard\n",
      "0.13575554532074363 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.660319094014825 new standard\n",
      "0.09410894844871867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.5659955503126223 new standard\n",
      "0.052268008520987154 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.5918178276807909 new standard\n",
      "0.04960139581652146 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.6322040543488516 new standard\n",
      "-0.19646546639163578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.6412340697883696 new standard\n",
      "-0.13491578571598797 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.6212753393716759 new standard\n",
      "-0.026763110382222663 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.6493355863817503 new standard\n",
      "0.046611410993035104 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.7286997722864088 new standard\n",
      "0.04317066458298325 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.6920380988109458 new standard\n",
      "0.17763104695719711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.5827576779221979 new standard\n",
      "-0.1661464134361393 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.5942013734072794 new standard\n",
      "-0.12688434142369423 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.674036379430264 new standard\n",
      "-0.08308932283797826 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.6881126733368729 new standard\n",
      "-0.10938843172513228 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.6545613981654312 new standard\n",
      "-0.07974125895348147 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.6380995962619183 new standard\n",
      "-0.04952427988343429 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.679200431544665 new standard\n",
      "-0.00997583321804496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.7250748099591909 new standard\n",
      "0.017101537176798055 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.6711731724853667 new standard\n",
      "-0.0566196612188396 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.675784849796036 new standard\n",
      "-0.020811639746592257 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.633521825767872 new standard\n",
      "-0.1048978365310599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.6485684696956839 new standard\n",
      "-0.1342760436349107 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.6726890561270488 new standard\n",
      "-0.07153067304465013 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.6855923842535496 new standard\n",
      "-0.08461276998343792 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.6691843791945087 new standard\n",
      "-0.11944204536002455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.6631234008192056 new standard\n",
      "-0.06228037666951586 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.6318449607181802 new standard\n",
      "0.03893101714331833 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.6789924452960843 new standard\n",
      "0.22731087209821244 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.6435409194322411 new standard\n",
      "-0.13442938596693288 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.6480372779055938 new standard\n",
      "-0.2042541501309706 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.6685758926510753 new standard\n",
      "-0.14319401579813773 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.6370126464204708 new standard\n",
      "-0.13507967706244403 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.6522670036064844 new standard\n",
      "-0.09930223953971667 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.6245947427439127 new standard\n",
      "-0.05918361203467047 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.6197527443375044 new standard\n",
      "-0.18126018201363578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.6368638238997707 new standard\n",
      "-0.1498836350870442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.6424096717709773 new standard\n",
      "-0.08875677311861978 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.71604108634994 new standard\n",
      "0.024218127036827047 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.6956171045434516 new standard\n",
      "-0.048036502509199906 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.6556307718289872 new standard\n",
      "-0.057639343036727186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.6556968237791458 new standard\n",
      "-0.12475691123158174 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.6765462309709099 new standard\n",
      "-0.023094687909982904 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.6379165906214789 new standard\n",
      "-0.09273173335885104 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.6265928468915841 new standard\n",
      "-0.05995795604599936 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.6606155942369542 new standard\n",
      "-0.05843743510059103 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.6662108358857259 new standard\n",
      "-0.07013364755997784 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.6924320194294181 new standard\n",
      "-0.06316699872552402 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.7185515023384693 new standard\n",
      "-0.021689054282551204 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.6636599940662542 new standard\n",
      "-0.034387101469241725 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6565145422858176 new standard\n",
      "0.004464850457743867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.6966293315590382 new standard\n",
      "-0.1186859226260085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.635257238195916 new standard\n",
      "-0.077195623727696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.645812439753755 new standard\n",
      "-0.12394912021506364 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.6575754284492699 new standard\n",
      "-0.12154741655822543 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.6121981538081376 new standard\n",
      "-0.20443894521060849 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.66705273790422 new standard\n",
      "-0.11929205731422532 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.7353249708142713 new standard\n",
      "0.1515451621591199 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.7054457110735272 new standard\n",
      "0.17533545125929897 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.631775093317922 new standard\n",
      "-0.06733993894676513 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.6523630182910423 new standard\n",
      "0.009972909304798178 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.6875538279529687 new standard\n",
      "-0.051485513383839936 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.7225699870026806 new standard\n",
      "-0.02360104284168586 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.6626652999899714 new standard\n",
      "-0.060013912833289745 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.6635821847720548 new standard\n",
      "-0.032371375520300984 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.7246511802753076 new standard\n",
      "0.046505839872251806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.7021933344336352 new standard\n",
      "-0.04380821885182966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.6040303430692191 new standard\n",
      "-0.2473038655137264 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.6411067445179023 new standard\n",
      "-0.14426370160388044 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.5898473415767872 new standard\n",
      "-0.30036330206775574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.6110701579212221 new standard\n",
      "-0.24920772803069483 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.6386237177058004 new standard\n",
      "-0.17151414974949203 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.626390660889379 new standard\n",
      "-0.1290650630640009 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.6275450639502167 new standard\n",
      "-0.11466719452440895 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.6533905467910026 new standard\n",
      "-0.027145878588477085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6337246312553785 new standard\n",
      "-0.007452589079309381 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.6616799763395268 new standard\n",
      "0.005588371061936213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.63003024408203 new standard\n",
      "-0.16948300845686742 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.6773555828879775 new standard\n",
      "-0.03736170860259576 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.6492286975328931 new standard\n",
      "-0.17565403714096336 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.6616476432143804 new standard\n",
      "-0.1239205295145543 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.6774692079055111 new standard\n",
      "-0.14714036437132036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.6798151273704023 new standard\n",
      "-0.18275197412549055 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.6249582780295286 new standard\n",
      "-0.15469317129299137 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.6764027799356616 new standard\n",
      "-0.14447376486694416 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=91, out_features=6, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "        (hyp_act): HypAct(c_in=tensor([0.5400]), c_out=tensor([0.5400]))\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=6, out_features=3, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 575.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x000002752F663C18>, <function selu at 0x000002752F663C18>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x00000275496882C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.728651,roc 0.922386, loss 0.102539, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.785623,roc 0.938952, loss 0.086211, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.811720,roc 0.946915, loss 0.077945, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.831483,roc 0.952527, loss 0.073282, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.833044,roc 0.953010, loss 0.072863, acc 0, ECE 0 #edges 376470, #graphs 94 time: 335.1763s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 335.1908s\n",
      "94\n",
      "86\n",
      "0.05493603858272625 0.9012832796214034 loss acc\n",
      "86\n",
      "0.05493603858272625 0.9012832796214034 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.894085,roc 0.969473, loss 0.054936, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.897107,roc 0.976322, loss 0.050652, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.896721,roc 0.969897, loss 0.055924, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.898181,roc 0.971181, loss 0.053942, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.900000,roc 0.971769, loss 0.053275, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.901065,roc 0.971946, loss 0.053012, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.901257,roc 0.972050, loss 0.052896, acc 0, ECE 0 #edges 376470, #graphs 94 time: 354.7093s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 354.7249s\n",
      "94\n",
      "86\n",
      "0.052163682804733574 0.8898992538396769 loss acc\n",
      "86\n",
      "0.052163682804733574 0.8898992538396769 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.903997,roc 0.972441, loss 0.052164, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.919916,roc 0.981977, loss 0.042200, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.915899,roc 0.974565, loss 0.050014, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.910428,roc 0.972846, loss 0.052167, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.907743,roc 0.973003, loss 0.052356, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.908602,roc 0.974062, loss 0.050896, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.908990,roc 0.974158, loss 0.050780, acc 0, ECE 0 #edges 376470, #graphs 94 time: 341.4166s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 341.4166s\n",
      "94\n",
      "86\n",
      "0.04978586120411002 0.905350869552594 loss acc\n",
      "86\n",
      "0.04978586120411002 0.905350869552594 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.911256,roc 0.974272, loss 0.049786, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.923831,roc 0.982884, loss 0.041904, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.913346,roc 0.977104, loss 0.048576, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.910076,roc 0.974592, loss 0.050464, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.910828,roc 0.974721, loss 0.049693, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.912908,roc 0.975188, loss 0.049245, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.912595,roc 0.975116, loss 0.049319, acc 0, ECE 0 #edges 376470, #graphs 94 time: 172.8454s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 172.8454s\n",
      "94\n",
      "86\n",
      "0.04911141335934401 0.8983857387567863 loss acc\n",
      "86\n",
      "0.04911141335934401 0.8983857387567863 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.915466,roc 0.975268, loss 0.049111, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.926526,roc 0.983367, loss 0.040405, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e50_p6_lr0.021_val_excl_group_strchinp95wId_strchloss95_b8\\14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.918421,roc 0.976753, loss 0.047755, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.919954,roc 0.976970, loss 0.047671, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.916776,roc 0.976010, loss 0.048427, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.915728,roc 0.975999, loss 0.048506, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.915838,roc 0.975994, loss 0.048498, acc 0, ECE 0 #edges 376470, #graphs 94 time: 177.6358s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 177.6514s\n",
      "94\n",
      "86\n",
      "0.04966418638717479 0.8944400894231048 loss acc\n",
      "86\n",
      "0.04966418638717479 0.8944400894231048 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.914044,roc 0.975062, loss 0.049664, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.919531,roc 0.981552, loss 0.042071, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.913343,roc 0.974791, loss 0.049241, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.916739,roc 0.976320, loss 0.048360, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.915012,roc 0.975917, loss 0.048602, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.916420,roc 0.975979, loss 0.048420, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.915957,roc 0.975865, loss 0.048612, acc 0, ECE 0 #edges 376470, #graphs 94 time: 182.6887s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 182.6907s\n",
      "94\n",
      "86\n",
      "0.04913480111949777 0.909540400081294 loss acc\n",
      "86\n",
      "0.04913480111949777 0.909540400081294 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.914445,roc 0.975078, loss 0.049135, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.927930,roc 0.984185, loss 0.040070, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.915567,roc 0.976987, loss 0.047619, acc 0, ECE 0 #edges 92115, #graphs 23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_160\\3177211309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\u001b[0m in \u001b[0;36mcompute_metrics_multiple\u001b[1;34m(self, embeddings_list, data_list, split)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mroc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# ECE,MCE = get_calibration_metrics(labels,preds,one_side=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, h, idx)\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Euclidean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0memb_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\fx\\traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# fallback to traceback.format_stack()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    357\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# First call the original checkcache as intended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# to our compiled codes can be produced.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=2\n",
    "criteria={'CogTr':1}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':1,\n",
    "          'epochs':50,\n",
    "          'stretch_sigmoid':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['plv']\n",
    "curve_types_to_use=['setc']\n",
    "# raise Exception('OBVIOUSLY WE SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713a7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbd527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcf7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
