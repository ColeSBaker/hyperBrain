{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad3f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported utils\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used for recreating the link prediction results for different parameter settings\n",
    "and dimensionality\n",
    "\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "from params import *\n",
    "# from params import BAND_TO_OPT_C\n",
    "import sys\n",
    "from datetime import date\n",
    "import pickle\n",
    "import train_inductive\n",
    "# should we not make a seperate config for out \"official runnings\"\n",
    "from trials.hyperparam_config import config\n",
    "import pickle\n",
    "import optuna\n",
    "import copy\n",
    "from utils.train_utils import get_dir_name, format_metrics\n",
    "from main import parse_default_args\n",
    "from hyperparam import create_study_output_dir,create_objective_fun,complete_study_one_arg\n",
    "from utils.model_analysis_utils import save_embeddings_all\n",
    "from data.MEG import get_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2502fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trials.hyperparam_config import config\n",
    "from main import parse_default_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480a27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_OPT_C= { \n",
    "           'alpha':.54,\n",
    "           'gamma':.66,\n",
    "           'beta': .74,\n",
    "            'theta':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_arch_dict={'model':'HGCN','optimizer':'RiemannianAdam','manifold':'PoincareBall'}\n",
    "euc_arch_dict={'model':'GCN','optimizer':'Adam','manifold':'Euclidean'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 'set'},\n",
       " 'findc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': None},\n",
       " '1c': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 1},\n",
       " 'euc': {'model': 'GCN', 'optimizer': 'Adam', 'manifold': 'Euclidean', 'c': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_types={'full':{'use_weight':1,'use_virtual':1},\n",
    "            'no_virt':{'use_weight':1,'use_virtual':0},\n",
    "                'no_weight':{'use_weight':0,'use_virtual':1}}\n",
    "\n",
    "input_types={'plv':{'use_plv':1,'use_identity':0,'num_feature':91},\n",
    "             'id':{'use_plv':0,'use_identity':1,'num_feature':91},\n",
    "             'id_plv':{'use_plv':1,'use_identity':1,'num_feature':181}}\n",
    "\n",
    "\n",
    "curve_types={'setc':{**hyp_arch_dict,'c':'set'},\n",
    "            'findc':{**hyp_arch_dict,'c':None},\n",
    "            '1c':{**hyp_arch_dict,'c':1},\n",
    "             'euc':{**euc_arch_dict,'c':0},\n",
    "            }\n",
    "curve_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72779412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 1, PLV 0\n",
      "C: None, ID: 1, PLV 0\n",
      "\n",
      "\n",
      "HGCN_full_findc_id_dp model\n",
      "HGCN_full_findc_id_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L3\\HGCN_full_findc_id_dp\\e100_p2fr5_lr0.001g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L3\\HGCN_full_findc_id_dp\\e100_p2fr5_lr0.001g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=4, bias=1, c=None, criteria_dict={}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=5, eval_train=False, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.001, lr_reduce_freq=10, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_12_22_21_19_973084', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=2, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p2fr5_lr0.001g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L3\\\\HGCN_full_findc_id_dp\\\\e100_p2fr5_lr0.001g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.2, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.3, val_sub=0, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "0 USE Val\n",
      "Traditional split\n",
      "False EXCLUSION\n",
      "90 HOW MANY DID WE KEEP SHOULD BE 45\n",
      "54.0 NUM VAL\n",
      "90\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "now test\n",
      "whoopsie\n",
      "whoopsie\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "\n",
      "\n",
      " now\n",
      "[82, 83, 126, 127, 92, 93, 56, 57, 142, 143, 44, 45, 144, 145, 154, 155, 168, 169, 12, 13, 22, 23, 42, 43, 88, 89, 104, 105, 38, 39, 160, 161, 94, 95, 2, 3, 98, 99, 102, 103, 106, 107, 128, 129, 166, 167, 116, 117, 84, 85, 158, 159, 26, 27]\n",
      "90 54 36 lengths\n",
      "180 unique lenths\n",
      "90 54 36 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [0, 1, 4, 5, 6, 7, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 50, 51, 52, 53, 60, 61, 62, 63, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 90, 91, 96, 97, 110, 111, 114, 115, 122, 123, 124, 125, 130, 131, 136, 137, 138, 139, 140, 141, 146, 147, 148, 149, 152, 153, 156, 157, 162, 163, 164, 165, 170, 171, 174, 175, 176, 177, 178, 179], 'valid': [82, 83, 126, 127, 92, 93, 56, 57, 142, 143, 44, 45, 144, 145, 154, 155, 168, 169, 12, 13, 22, 23, 42, 43, 88, 89, 104, 105, 38, 39, 160, 161, 94, 95, 2, 3, 98, 99, 102, 103, 106, 107, 128, 129, 166, 167, 116, 117, 84, 85, 158, 159, 26, 27], 'test': [100, 101, 74, 75, 54, 55, 150, 151, 58, 59, 120, 121, 108, 109, 118, 119, 80, 81, 112, 113, 10, 11, 86, 87, 8, 9, 132, 133, 68, 69, 172, 173, 134, 135, 64, 65], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "90 36 54 length\n",
      "{'train': [0, 1, 4, 5, 6, 7, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 50, 51, 52, 53, 60, 61, 62, 63, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 90, 91, 96, 97, 110, 111, 114, 115, 122, 123, 124, 125, 130, 131, 136, 137, 138, 139, 140, 141, 146, 147, 148, 149, 152, 153, 156, 157, 162, 163, 164, 165, 170, 171, 174, 175, 176, 177, 178, 179], 'valid': [82, 83, 126, 127, 92, 93, 56, 57, 142, 143, 44, 45, 144, 145, 154, 155, 168, 169, 12, 13, 22, 23, 42, 43, 88, 89, 104, 105, 38, 39, 160, 161, 94, 95, 2, 3, 98, 99, 102, 103, 106, 107, 128, 129, 166, 167, 116, 117, 84, 85, 158, 159, 26, 27], 'test': [100, 101, 74, 75, 54, 55, 150, 151, 58, 59, 120, 121, 108, 109, 118, 119, 80, 81, 112, 113, 10, 11, 86, 87, 8, 9, 132, 133, 68, 69, 172, 173, 134, 135, 64, 65], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 4, 5, 6, 7, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 50, 51, 52, 53, 60, 61, 62, 63, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 90, 91, 96, 97, 110, 111, 114, 115, 122, 123, 124, 125, 130, 131, 136, 137, 138, 139, 140, 141, 146, 147, 148, 149, 152, 153, 156, 157, 162, 163, 164, 165, 170, 171, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['0', '1', '4', '5', '6', '7', '14', '15', '16', '17', '18', '19', '20', '21', '24', '25', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '40', '41', '46', '47', '48', '49', '50', '51', '52', '53', '60', '61', '62', '63', '66', '67', '70', '71', '72', '73', '76', '77', '78', '79', '90', '91', '96', '97', '110', '111', '114', '115', '122', '123', '124', '125', '130', '131', '136', '137', '138', '139', '140', '141', '146', '147', '148', '149', '152', '153', '156', '157', '162', '163', '164', '165', '170', '171', '174', '175', '176', '177', '178', '179', '2', '3', '12', '13', '22', '23', '26', '27', '38', '39', '42', '43', '44', '45', '56', '57', '82', '83', '84', '85', '88', '89', '92', '93', '94', '95', '98', '99', '102', '103', '104', '105', '106', '107', '116', '117', '126', '127', '128', '129', '142', '143', '144', '145', '154', '155', '158', '159', '160', '161', '166', '167', '168', '169', '8', '9', '10', '11', '54', '55', '58', '59', '64', '65', '68', '69', '74', '75', '80', '81', '86', '87', '100', '101', '108', '109', '112', '113', '118', '119', '120', '121', '132', '133', '134', '135', '150', '151', '172', '173'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[82, 83, 126, 127, 92, 93, 56, 57, 142, 143, 44, 45, 144, 145, 154, 155, 168, 169, 12, 13, 22, 23, 42, 43, 88, 89, 104, 105, 38, 39, 160, 161, 94, 95, 2, 3, 98, 99, 102, 103, 106, 107, 128, 129, 166, 167, 116, 117, 84, 85, 158, 159, 26, 27] SELF INDICES\n",
      "['0', '1', '4', '5', '6', '7', '14', '15', '16', '17', '18', '19', '20', '21', '24', '25', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '40', '41', '46', '47', '48', '49', '50', '51', '52', '53', '60', '61', '62', '63', '66', '67', '70', '71', '72', '73', '76', '77', '78', '79', '90', '91', '96', '97', '110', '111', '114', '115', '122', '123', '124', '125', '130', '131', '136', '137', '138', '139', '140', '141', '146', '147', '148', '149', '152', '153', '156', '157', '162', '163', '164', '165', '170', '171', '174', '175', '176', '177', '178', '179', '2', '3', '12', '13', '22', '23', '26', '27', '38', '39', '42', '43', '44', '45', '56', '57', '82', '83', '84', '85', '88', '89', '92', '93', '94', '95', '98', '99', '102', '103', '104', '105', '106', '107', '116', '117', '126', '127', '128', '129', '142', '143', '144', '145', '154', '155', '158', '159', '160', '161', '166', '167', '168', '169', '8', '9', '10', '11', '54', '55', '58', '59', '64', '65', '68', '69', '74', '75', '80', '81', '86', '87', '100', '101', '108', '109', '112', '113', '118', '119', '120', '121', '132', '133', '134', '135', '150', '151', '172', '173'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[100, 101, 74, 75, 54, 55, 150, 151, 58, 59, 120, 121, 108, 109, 118, 119, 80, 81, 112, 113, 10, 11, 86, 87, 8, 9, 132, 133, 68, 69, 172, 173, 134, 135, 64, 65] SELF INDICES\n",
      "['0', '1', '4', '5', '6', '7', '14', '15', '16', '17', '18', '19', '20', '21', '24', '25', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '40', '41', '46', '47', '48', '49', '50', '51', '52', '53', '60', '61', '62', '63', '66', '67', '70', '71', '72', '73', '76', '77', '78', '79', '90', '91', '96', '97', '110', '111', '114', '115', '122', '123', '124', '125', '130', '131', '136', '137', '138', '139', '140', '141', '146', '147', '148', '149', '152', '153', '156', '157', '162', '163', '164', '165', '170', '171', '174', '175', '176', '177', '178', '179', '2', '3', '12', '13', '22', '23', '26', '27', '38', '39', '42', '43', '44', '45', '56', '57', '82', '83', '84', '85', '88', '89', '92', '93', '94', '95', '98', '99', '102', '103', '104', '105', '106', '107', '116', '117', '126', '127', '128', '129', '142', '143', '144', '145', '154', '155', '158', '159', '160', '161', '166', '167', '168', '169', '8', '9', '10', '11', '54', '55', '58', '59', '64', '65', '68', '69', '74', '75', '80', '81', '86', '87', '100', '101', '108', '109', '112', '113', '118', '119', '120', '121', '132', '133', '134', '135', '150', '151', '172', '173'] dta set indices\n",
      "90 36 54\n",
      "-1 ARG FREQ\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) SLEF C\n",
      "no pruner\n",
      "no trial\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) SLEF C\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x000002B045983648>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.001]\n",
      "<generator object Module.parameters at 0x000002B03F066148> MODEL PARAMS\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "model\n",
      "<generator object Module.parameters at 0x000002B03F066148> MODEL PARAMS\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "90 train length\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0006], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0006], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0006], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9990], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9990], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9990], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0013], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0013], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0013], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9994], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0010], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0021], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0021], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0021], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9976], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9987], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9976], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9976], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0016], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0031], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0031], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0031], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9966], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9979], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9966], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9966], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0024], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0044], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0044], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0044], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9954], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9969], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9954], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9954], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0034], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0058], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0058], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0058], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9940], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9957], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9940], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9940], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0046], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0074], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0074], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0074], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9924], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9943], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9924], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9924], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0060], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0091], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0091], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0091], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9908], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9927], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9908], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9908], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0076], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0109], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0109], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0109], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9890], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9910], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9890], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9890], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0093], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0130], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0130], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0130], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9872], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9892], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9872], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9872], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0111], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0151], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0151], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0151], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9855], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9872], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9855], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9855], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0129], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0172], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0172], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0172], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9836], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9852], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9836], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9836], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0147], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0195], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0195], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0195], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9817], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9831], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9817], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9817], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0167], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0219], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0219], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0219], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9798], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9809], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9798], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9798], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0187], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0244], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0244], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0244], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9777], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9786], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9777], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9777], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0207], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0269], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0269], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0269], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9756], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9762], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9756], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9756], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0228], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0296], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0296], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0296], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9733], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9738], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9733], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9733], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0250], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0322], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0322], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0322], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9711], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9713], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9711], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9711], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0274], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0348], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0348], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0348], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9686], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9688], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9686], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9686], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0298], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0374], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0374], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0374], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9661], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9664], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9661], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9661], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0324], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0398], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0398], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0398], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9638], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9640], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9638], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9638], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0351], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0420], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0420], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0420], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9611], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9617], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9611], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9611], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0376], grad_fn=<MulBackward0>) agg man\n",
      "23\n",
      "train phase of epoch 0: precision 0.621013,roc 0.873668, loss 0.567742, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0445], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0445], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0445], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9585], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9597], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9585], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9585], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0405], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0470], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0470], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0470], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9556], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9574], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9556], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9556], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0433], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0492], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0492], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0492], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9525], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9551], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9525], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9525], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0465], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0514], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0514], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0514], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9495], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9531], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9495], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9495], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0498], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0536], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0536], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0536], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9464], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9511], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9464], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9464], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0531], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0557], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0557], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0557], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9431], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9492], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9431], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9431], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0567], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0579], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0579], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0579], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9402], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9472], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9402], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9402], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0603], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0601], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0601], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0601], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9375], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9453], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9375], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9375], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0636], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0620], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0620], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0620], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9345], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9433], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9345], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9345], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0666], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0642], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0642], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0642], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9318], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9416], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9318], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9318], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0701], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0665], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0665], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0665], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9294], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9397], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9294], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9294], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0732], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0682], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0682], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0682], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9271], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9376], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9271], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9271], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0759], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0694], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0694], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0694], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9243], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9362], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9243], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9243], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0787], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0708], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0708], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0708], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9218], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9351], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9218], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9218], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0819], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0722], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0722], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0722], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9196], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9339], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9196], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9196], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0848], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0741], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0741], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0741], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9174], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9326], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9174], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9174], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0874], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0765], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0765], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0765], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9154], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9310], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9154], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9154], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0901], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0791], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0791], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0791], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9137], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9290], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9137], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9137], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0924], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0819], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0819], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0819], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9122], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9267], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9122], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9122], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0945], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0847], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0847], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0847], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9111], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9243], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9111], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9111], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0963], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0875], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0875], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0875], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9105], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9219], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9105], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9105], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0975], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0904], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0904], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0904], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9101], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9195], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9101], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9101], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0983], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0929], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0929], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0929], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9097], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9171], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9097], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9097], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0988], grad_fn=<MulBackward0>) agg man\n",
      "46\n",
      "train phase of epoch 0: precision 0.622972,roc 0.873580, loss 0.555176, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0951], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0951], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0951], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9094], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9150], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9094], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9094], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0992], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0970], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0970], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0970], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9079], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9131], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9079], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9079], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0996], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0991], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0991], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0991], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9056], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9115], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9056], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9056], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.1014], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.1017], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.1017], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.1017], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9035], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9098], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9035], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9035], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.1043], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.1047], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.1047], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.1047], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9019], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9077], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9019], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9019], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.1067], grad_fn=<MulBackward0>) agg man\n",
      "tensor([0.8805, 0.8761,    nan, 0.8787, 0.8805, 0.8743, 0.8769, 0.8796,    nan,\n",
      "        0.8802, 0.8792, 0.8793, 0.8760, 0.8787, 0.8803,    nan, 0.8766, 0.8797,\n",
      "        0.8792, 0.8513, 0.8779, 0.8766, 0.8769, 0.8799,    nan, 0.8706, 0.8801,\n",
      "        0.8640, 0.8806, 0.8788, 0.8803, 0.8802, 0.8801, 0.8748, 0.8803, 0.8682,\n",
      "           nan, 0.8786, 0.8709, 0.8768, 0.8775, 0.8755,    nan, 0.8805, 0.8797,\n",
      "        0.8786, 0.8805, 0.8800, 0.8784, 0.8804, 0.8752, 0.8790, 0.8808, 0.8801,\n",
      "        0.8718, 0.8808, 0.8800, 0.8776,    nan, 0.8647, 0.8789, 0.8766, 0.8762,\n",
      "        0.8795, 0.8759, 0.8573, 0.8733, 0.8650, 0.8807, 0.8796, 0.8784, 0.8801,\n",
      "        0.8751, 0.8802,    nan, 0.8723, 0.8807, 0.8775, 0.8803, 0.8803, 0.8781,\n",
      "        0.8777, 0.8730, 0.8807, 0.8662, 0.8552, 0.8801, 0.8803, 0.8698, 0.8790,\n",
      "        0.8787, 0.8805, 0.8800, 0.8805, 0.8793,    nan, 0.8788, 0.8803,    nan,\n",
      "        0.8805, 0.8800, 0.8804, 0.8787, 0.8743, 0.8795, 0.8685, 0.8794,    nan,\n",
      "        0.8807,    nan, 0.8761, 0.8806,    nan, 0.8767, 0.8795, 0.8802, 0.8662,\n",
      "           nan, 0.8362, 0.8757, 0.8566, 0.8657, 0.8786, 0.8795, 0.8800, 0.8802,\n",
      "           nan, 0.8801, 0.8796, 0.8805, 0.8571, 0.8747, 0.8734, 0.8803, 0.8786,\n",
      "        0.8766, 0.8753, 0.8801, 0.8802, 0.8626, 0.8801, 0.8805, 0.8786, 0.8690,\n",
      "        0.8536, 0.8800, 0.8788, 0.8784, 0.8735, 0.8801, 0.8768, 0.8802, 0.8807,\n",
      "        0.8807,    nan, 0.8805, 0.8801, 0.8781, 0.8787, 0.8803, 0.8783, 0.8799,\n",
      "        0.8481,    nan, 0.8378, 0.8781, 0.8786, 0.8774, 0.8774, 0.8798, 0.8799,\n",
      "        0.8620, 0.8737, 0.8746, 0.8791, 0.8766, 0.8802, 0.8799, 0.8795, 0.8786,\n",
      "        0.8727,    nan, 0.8738, 0.8802, 0.8735, 0.8768, 0.8782,    nan, 0.8806,\n",
      "        0.8794, 0.8753, 0.8800, 0.8801,    nan,    nan, 0.8761, 0.8805, 0.8807,\n",
      "        0.8769, 0.8790, 0.8786, 0.8806, 0.8792, 0.8759, 0.8798, 0.8641, 0.8777,\n",
      "        0.8734, 0.8764, 0.8794, 0.8765, 0.8760, 0.8746, 0.8791, 0.8805, 0.8695,\n",
      "        0.8743, 0.8801, 0.8799, 0.8736, 0.8779, 0.8775, 0.8764,    nan, 0.8802,\n",
      "           nan, 0.8801, 0.8771, 0.8765, 0.8603, 0.8748, 0.8737, 0.8786, 0.8762,\n",
      "        0.8806, 0.8787, 0.8774, 0.8803, 0.8512, 0.8752, 0.8618,    nan,    nan,\n",
      "        0.8808, 0.8727, 0.8740, 0.8797, 0.8799, 0.8454,    nan, 0.8691, 0.8807,\n",
      "        0.8802, 0.8793, 0.8760,    nan, 0.8794, 0.8807, 0.8806, 0.8773, 0.8791,\n",
      "        0.8796, 0.8800, 0.8805, 0.8707, 0.8774, 0.8802, 0.8792, 0.8786,    nan,\n",
      "        0.8786, 0.8789, 0.8756, 0.8807, 0.8786, 0.8806, 0.8799, 0.8808, 0.8761,\n",
      "        0.8773, 0.8800, 0.8777, 0.8762, 0.8734, 0.8779, 0.8808, 0.8769, 0.8799,\n",
      "        0.8724, 0.8718, 0.8780, 0.8803, 0.8802, 0.8805, 0.8800, 0.8691, 0.8772,\n",
      "        0.8797,    nan, 0.8777, 0.8794, 0.8805, 0.8785, 0.8618, 0.8681, 0.8771,\n",
      "        0.8779, 0.8808,    nan, 0.8721, 0.8802, 0.8747, 0.8794, 0.8776, 0.8780,\n",
      "        0.8770, 0.8781, 0.8803, 0.8782, 0.8795, 0.8796, 0.8808,    nan, 0.8802,\n",
      "        0.8777, 0.8722, 0.8807,    nan, 0.8760, 0.8780, 0.8802, 0.8795, 0.8791,\n",
      "        0.8787, 0.8805, 0.8727, 0.8793, 0.8804, 0.8800, 0.8786, 0.8797, 0.8776,\n",
      "        0.8790, 0.8800, 0.8779, 0.8677, 0.8790, 0.8807, 0.8761, 0.8800, 0.8805,\n",
      "        0.8762,    nan,    nan, 0.8796, 0.8769, 0.8774, 0.8738,    nan, 0.8754,\n",
      "           nan, 0.8791, 0.8744, 0.8789, 0.8790, 0.8224, 0.8621, 0.8765, 0.8766,\n",
      "           nan, 0.8790, 0.8798, 0.8797, 0.8791, 0.8772, 0.8739, 0.8794, 0.8770,\n",
      "        0.8797, 0.8786, 0.8797, 0.8790, 0.8676, 0.8670, 0.8781, 0.8797, 0.8804,\n",
      "        0.8796, 0.8750, 0.8807, 0.8542, 0.8808, 0.8692, 0.8765, 0.8805, 0.8706,\n",
      "        0.8799,    nan, 0.8790, 0.8800, 0.8767, 0.8783, 0.8766, 0.8803, 0.8807,\n",
      "        0.8788, 0.8631, 0.8803, 0.8807, 0.8796, 0.8788, 0.8775, 0.8782, 0.8776,\n",
      "        0.8791, 0.8726, 0.8781, 0.8794, 0.8782, 0.8756, 0.8704, 0.8802, 0.8763,\n",
      "        0.8767, 0.8791, 0.8787, 0.8722, 0.8705, 0.8786, 0.8805, 0.8799, 0.8777,\n",
      "        0.8784, 0.8788, 0.8783, 0.8799, 0.8796, 0.8776, 0.8543, 0.8787, 0.8768,\n",
      "        0.8764, 0.8804, 0.8790, 0.8797, 0.8796, 0.8798, 0.8730, 0.8692, 0.8782,\n",
      "        0.8802, 0.8785, 0.8803, 0.8801, 0.8806, 0.8800, 0.8807, 0.8762, 0.8687,\n",
      "        0.8802, 0.8808, 0.8793,    nan, 0.8798, 0.8797, 0.8784, 0.8791, 0.8729,\n",
      "        0.8715, 0.8713, 0.8795, 0.8644, 0.8804, 0.8786, 0.8749, 0.8778, 0.8804,\n",
      "        0.8799, 0.8770,    nan,    nan, 0.8807, 0.8800, 0.8730, 0.8714, 0.8796,\n",
      "        0.8638, 0.8792, 0.8756, 0.8783, 0.8779, 0.8804, 0.8766, 0.8725, 0.8773,\n",
      "        0.8799,    nan, 0.8719,    nan, 0.8802, 0.8664, 0.8787, 0.8801, 0.8512,\n",
      "        0.8789, 0.8785, 0.8703, 0.8798, 0.8714, 0.8806, 0.8794, 0.8711, 0.8792,\n",
      "        0.8803, 0.8787,    nan,    nan, 0.8782, 0.8694, 0.8782, 0.8783, 0.8723,\n",
      "        0.8783, 0.8791, 0.8748, 0.8807, 0.8807, 0.8727, 0.8795, 0.8804,    nan,\n",
      "        0.8807, 0.8747, 0.8775, 0.8758, 0.8798, 0.8602, 0.8782, 0.8800, 0.8780,\n",
      "        0.8696, 0.8571, 0.8793, 0.8796, 0.8743, 0.8729, 0.8781, 0.8796, 0.8765,\n",
      "        0.8773, 0.8733, 0.8783, 0.8731, 0.8806, 0.8762, 0.8656, 0.8770, 0.8803,\n",
      "        0.8777, 0.8764, 0.8806,    nan, 0.8794, 0.8721, 0.8759, 0.8787, 0.8803,\n",
      "        0.8808, 0.8803, 0.8773, 0.8738, 0.8733, 0.8667,    nan, 0.8806, 0.8771,\n",
      "        0.8728, 0.8791, 0.8766, 0.8766, 0.8777, 0.8652, 0.8584, 0.8789, 0.8807,\n",
      "        0.8773, 0.8791, 0.8770, 0.8801, 0.8805, 0.8719, 0.8566, 0.8796,    nan,\n",
      "        0.8708, 0.8791, 0.8801, 0.8775, 0.8806, 0.8670, 0.8799, 0.8699, 0.8772,\n",
      "        0.8777, 0.8781, 0.8782, 0.8799, 0.8804, 0.8786, 0.8784, 0.8802, 0.8727,\n",
      "        0.8789, 0.8803, 0.8807,    nan, 0.8801, 0.8780, 0.8808, 0.8603, 0.8718,\n",
      "        0.8784, 0.8807, 0.8805, 0.8686, 0.8793, 0.8784, 0.8795, 0.8788, 0.8800,\n",
      "        0.8789, 0.8807, 0.8794, 0.8801,    nan, 0.8733, 0.8801,    nan, 0.8805,\n",
      "        0.8802, 0.8757, 0.8777, 0.8775,    nan, 0.8733, 0.8617, 0.8802, 0.8738,\n",
      "        0.8786, 0.8801, 0.8670, 0.8802, 0.8714, 0.8758, 0.8785, 0.8800, 0.8716,\n",
      "        0.8787, 0.8653, 0.8752, 0.8719, 0.8789, 0.8796, 0.8792, 0.8797, 0.8800,\n",
      "        0.8768, 0.8793, 0.8770, 0.8790, 0.8582, 0.8776, 0.8803, 0.8795, 0.8652,\n",
      "        0.8759, 0.8728, 0.8804, 0.8801, 0.8790, 0.8805, 0.8764, 0.8713, 0.8611,\n",
      "        0.8799, 0.8804, 0.8750, 0.8692, 0.8799, 0.8748, 0.8789, 0.8803, 0.8673,\n",
      "        0.8805, 0.8703, 0.8793, 0.8783, 0.8805, 0.8770, 0.8746, 0.8774, 0.8804,\n",
      "        0.8801, 0.8759, 0.8779, 0.8769, 0.8785, 0.8727, 0.8705, 0.8697, 0.8771,\n",
      "        0.8799, 0.8763, 0.8766, 0.8762,    nan, 0.8796, 0.8787, 0.8777, 0.8808,\n",
      "        0.8765, 0.8748, 0.8798, 0.8779], grad_fn=<CatBackward0>) pos scores??\n",
      "NANS IN POS SCORES\n",
      "tensor([0.8805, 0.8761, 0.0100, 0.8787, 0.8805, 0.8743, 0.8769, 0.8796, 0.0100,\n",
      "        0.8802, 0.8792, 0.8793, 0.8760, 0.8787, 0.8803, 0.0100, 0.8766, 0.8797,\n",
      "        0.8792, 0.8513, 0.8779, 0.8766, 0.8769, 0.8799, 0.0100, 0.8706, 0.8801,\n",
      "        0.8640, 0.8806, 0.8788, 0.8803, 0.8802, 0.8801, 0.8748, 0.8803, 0.8682,\n",
      "        0.0100, 0.8786, 0.8709, 0.8768, 0.8775, 0.8755, 0.0100, 0.8805, 0.8797,\n",
      "        0.8786, 0.8805, 0.8800, 0.8784, 0.8804, 0.8752, 0.8790, 0.8808, 0.8801,\n",
      "        0.8718, 0.8808, 0.8800, 0.8776, 0.0100, 0.8647, 0.8789, 0.8766, 0.8762,\n",
      "        0.8795, 0.8759, 0.8573, 0.8733, 0.8650, 0.8807, 0.8796, 0.8784, 0.8801,\n",
      "        0.8751, 0.8802, 0.0100, 0.8723, 0.8807, 0.8775, 0.8803, 0.8803, 0.8781,\n",
      "        0.8777, 0.8730, 0.8807, 0.8662, 0.8552, 0.8801, 0.8803, 0.8698, 0.8790,\n",
      "        0.8787, 0.8805, 0.8800, 0.8805, 0.8793, 0.0100, 0.8788, 0.8803, 0.0100,\n",
      "        0.8805, 0.8800, 0.8804, 0.8787, 0.8743, 0.8795, 0.8685, 0.8794, 0.0100,\n",
      "        0.8807, 0.0100, 0.8761, 0.8806, 0.0100, 0.8767, 0.8795, 0.8802, 0.8662,\n",
      "        0.0100, 0.8362, 0.8757, 0.8566, 0.8657, 0.8786, 0.8795, 0.8800, 0.8802,\n",
      "        0.0100, 0.8801, 0.8796, 0.8805, 0.8571, 0.8747, 0.8734, 0.8803, 0.8786,\n",
      "        0.8766, 0.8753, 0.8801, 0.8802, 0.8626, 0.8801, 0.8805, 0.8786, 0.8690,\n",
      "        0.8536, 0.8800, 0.8788, 0.8784, 0.8735, 0.8801, 0.8768, 0.8802, 0.8807,\n",
      "        0.8807, 0.0100, 0.8805, 0.8801, 0.8781, 0.8787, 0.8803, 0.8783, 0.8799,\n",
      "        0.8481, 0.0100, 0.8378, 0.8781, 0.8786, 0.8774, 0.8774, 0.8798, 0.8799,\n",
      "        0.8620, 0.8737, 0.8746, 0.8791, 0.8766, 0.8802, 0.8799, 0.8795, 0.8786,\n",
      "        0.8727, 0.0100, 0.8738, 0.8802, 0.8735, 0.8768, 0.8782, 0.0100, 0.8806,\n",
      "        0.8794, 0.8753, 0.8800, 0.8801, 0.0100, 0.0100, 0.8761, 0.8805, 0.8807,\n",
      "        0.8769, 0.8790, 0.8786, 0.8806, 0.8792, 0.8759, 0.8798, 0.8641, 0.8777,\n",
      "        0.8734, 0.8764, 0.8794, 0.8765, 0.8760, 0.8746, 0.8791, 0.8805, 0.8695,\n",
      "        0.8743, 0.8801, 0.8799, 0.8736, 0.8779, 0.8775, 0.8764, 0.0100, 0.8802,\n",
      "        0.0100, 0.8801, 0.8771, 0.8765, 0.8603, 0.8748, 0.8737, 0.8786, 0.8762,\n",
      "        0.8806, 0.8787, 0.8774, 0.8803, 0.8512, 0.8752, 0.8618, 0.0100, 0.0100,\n",
      "        0.8808, 0.8727, 0.8740, 0.8797, 0.8799, 0.8454, 0.0100, 0.8691, 0.8807,\n",
      "        0.8802, 0.8793, 0.8760, 0.0100, 0.8794, 0.8807, 0.8806, 0.8773, 0.8791,\n",
      "        0.8796, 0.8800, 0.8805, 0.8707, 0.8774, 0.8802, 0.8792, 0.8786, 0.0100,\n",
      "        0.8786, 0.8789, 0.8756, 0.8807, 0.8786, 0.8806, 0.8799, 0.8808, 0.8761,\n",
      "        0.8773, 0.8800, 0.8777, 0.8762, 0.8734, 0.8779, 0.8808, 0.8769, 0.8799,\n",
      "        0.8724, 0.8718, 0.8780, 0.8803, 0.8802, 0.8805, 0.8800, 0.8691, 0.8772,\n",
      "        0.8797, 0.0100, 0.8777, 0.8794, 0.8805, 0.8785, 0.8618, 0.8681, 0.8771,\n",
      "        0.8779, 0.8808, 0.0100, 0.8721, 0.8802, 0.8747, 0.8794, 0.8776, 0.8780,\n",
      "        0.8770, 0.8781, 0.8803, 0.8782, 0.8795, 0.8796, 0.8808, 0.0100, 0.8802,\n",
      "        0.8777, 0.8722, 0.8807, 0.0100, 0.8760, 0.8780, 0.8802, 0.8795, 0.8791,\n",
      "        0.8787, 0.8805, 0.8727, 0.8793, 0.8804, 0.8800, 0.8786, 0.8797, 0.8776,\n",
      "        0.8790, 0.8800, 0.8779, 0.8677, 0.8790, 0.8807, 0.8761, 0.8800, 0.8805,\n",
      "        0.8762, 0.0100, 0.0100, 0.8796, 0.8769, 0.8774, 0.8738, 0.0100, 0.8754,\n",
      "        0.0100, 0.8791, 0.8744, 0.8789, 0.8790, 0.8224, 0.8621, 0.8765, 0.8766,\n",
      "        0.0100, 0.8790, 0.8798, 0.8797, 0.8791, 0.8772, 0.8739, 0.8794, 0.8770,\n",
      "        0.8797, 0.8786, 0.8797, 0.8790, 0.8676, 0.8670, 0.8781, 0.8797, 0.8804,\n",
      "        0.8796, 0.8750, 0.8807, 0.8542, 0.8808, 0.8692, 0.8765, 0.8805, 0.8706,\n",
      "        0.8799, 0.0100, 0.8790, 0.8800, 0.8767, 0.8783, 0.8766, 0.8803, 0.8807,\n",
      "        0.8788, 0.8631, 0.8803, 0.8807, 0.8796, 0.8788, 0.8775, 0.8782, 0.8776,\n",
      "        0.8791, 0.8726, 0.8781, 0.8794, 0.8782, 0.8756, 0.8704, 0.8802, 0.8763,\n",
      "        0.8767, 0.8791, 0.8787, 0.8722, 0.8705, 0.8786, 0.8805, 0.8799, 0.8777,\n",
      "        0.8784, 0.8788, 0.8783, 0.8799, 0.8796, 0.8776, 0.8543, 0.8787, 0.8768,\n",
      "        0.8764, 0.8804, 0.8790, 0.8797, 0.8796, 0.8798, 0.8730, 0.8692, 0.8782,\n",
      "        0.8802, 0.8785, 0.8803, 0.8801, 0.8806, 0.8800, 0.8807, 0.8762, 0.8687,\n",
      "        0.8802, 0.8808, 0.8793, 0.0100, 0.8798, 0.8797, 0.8784, 0.8791, 0.8729,\n",
      "        0.8715, 0.8713, 0.8795, 0.8644, 0.8804, 0.8786, 0.8749, 0.8778, 0.8804,\n",
      "        0.8799, 0.8770, 0.0100, 0.0100, 0.8807, 0.8800, 0.8730, 0.8714, 0.8796,\n",
      "        0.8638, 0.8792, 0.8756, 0.8783, 0.8779, 0.8804, 0.8766, 0.8725, 0.8773,\n",
      "        0.8799, 0.0100, 0.8719, 0.0100, 0.8802, 0.8664, 0.8787, 0.8801, 0.8512,\n",
      "        0.8789, 0.8785, 0.8703, 0.8798, 0.8714, 0.8806, 0.8794, 0.8711, 0.8792,\n",
      "        0.8803, 0.8787, 0.0100, 0.0100, 0.8782, 0.8694, 0.8782, 0.8783, 0.8723,\n",
      "        0.8783, 0.8791, 0.8748, 0.8807, 0.8807, 0.8727, 0.8795, 0.8804, 0.0100,\n",
      "        0.8807, 0.8747, 0.8775, 0.8758, 0.8798, 0.8602, 0.8782, 0.8800, 0.8780,\n",
      "        0.8696, 0.8571, 0.8793, 0.8796, 0.8743, 0.8729, 0.8781, 0.8796, 0.8765,\n",
      "        0.8773, 0.8733, 0.8783, 0.8731, 0.8806, 0.8762, 0.8656, 0.8770, 0.8803,\n",
      "        0.8777, 0.8764, 0.8806, 0.0100, 0.8794, 0.8721, 0.8759, 0.8787, 0.8803,\n",
      "        0.8808, 0.8803, 0.8773, 0.8738, 0.8733, 0.8667, 0.0100, 0.8806, 0.8771,\n",
      "        0.8728, 0.8791, 0.8766, 0.8766, 0.8777, 0.8652, 0.8584, 0.8789, 0.8807,\n",
      "        0.8773, 0.8791, 0.8770, 0.8801, 0.8805, 0.8719, 0.8566, 0.8796, 0.0100,\n",
      "        0.8708, 0.8791, 0.8801, 0.8775, 0.8806, 0.8670, 0.8799, 0.8699, 0.8772,\n",
      "        0.8777, 0.8781, 0.8782, 0.8799, 0.8804, 0.8786, 0.8784, 0.8802, 0.8727,\n",
      "        0.8789, 0.8803, 0.8807, 0.0100, 0.8801, 0.8780, 0.8808, 0.8603, 0.8718,\n",
      "        0.8784, 0.8807, 0.8805, 0.8686, 0.8793, 0.8784, 0.8795, 0.8788, 0.8800,\n",
      "        0.8789, 0.8807, 0.8794, 0.8801, 0.0100, 0.8733, 0.8801, 0.0100, 0.8805,\n",
      "        0.8802, 0.8757, 0.8777, 0.8775, 0.0100, 0.8733, 0.8617, 0.8802, 0.8738,\n",
      "        0.8786, 0.8801, 0.8670, 0.8802, 0.8714, 0.8758, 0.8785, 0.8800, 0.8716,\n",
      "        0.8787, 0.8653, 0.8752, 0.8719, 0.8789, 0.8796, 0.8792, 0.8797, 0.8800,\n",
      "        0.8768, 0.8793, 0.8770, 0.8790, 0.8582, 0.8776, 0.8803, 0.8795, 0.8652,\n",
      "        0.8759, 0.8728, 0.8804, 0.8801, 0.8790, 0.8805, 0.8764, 0.8713, 0.8611,\n",
      "        0.8799, 0.8804, 0.8750, 0.8692, 0.8799, 0.8748, 0.8789, 0.8803, 0.8673,\n",
      "        0.8805, 0.8703, 0.8793, 0.8783, 0.8805, 0.8770, 0.8746, 0.8774, 0.8804,\n",
      "        0.8801, 0.8759, 0.8779, 0.8769, 0.8785, 0.8727, 0.8705, 0.8697, 0.8771,\n",
      "        0.8799, 0.8763, 0.8766, 0.8762, 0.0100, 0.8796, 0.8787, 0.8777, 0.8808,\n",
      "        0.8765, 0.8748, 0.8798, 0.8779], grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n",
      "NANS IN NEG SCORES\n",
      "tensor([0.7568, 0.8646, 0.8716,  ..., 0.7398, 0.8605, 0.8680],\n",
      "       grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py:199: UserWarning: Error detected in ReciprocalBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n",
      "    cell_id=cell_id,\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\coleb\\AppData\\Local\\Temp\\ipykernel_25064\\4285808443.py\", line 47, in <module>\n",
      "    complete_study_one_arg(args,NUM_VALIDATIONS)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\", line 279, in complete_study_one_arg\n",
      "    train_inductive.train(args_copy)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\", line 286, in train\n",
      "    train_metrics=model.compute_metrics_multiple(embeddings_list,data_list,'train')\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 534, in compute_metrics_multiple\n",
      "    neg_scores = self.decode(embeddings, edges_false)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 158, in decode\n",
      "    probs = self.dc.forward(sqdist)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\layers\\layers.py\", line 141, in forward\n",
      "    probs = 1. / (torch.exp(  torch.clamp( ((dist - self.r) / self.t),max=max_clamp))+ 1.0)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 39, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 838, in __rdiv__\n",
      "    return self.reciprocal() * other\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\fx\\traceback.py\", line 57, in format_stack\n",
      "    return traceback.format_stack()\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'ReciprocalBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25064\\4285808443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'ReciprocalBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':0,\n",
    "          'lr':.001,\n",
    "          'use_batch':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_models import NCModel, LPModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LPModel({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2382116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 0, PLV 1\n",
      "C: None, ID: 0, PLV 1\n",
      "\n",
      "\n",
      "HGCN_full_findc_plv_dp model\n",
      "HGCN_full_findc_plv_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L3\\HGCN_full_findc_plv_dp\\e100_p2fr5_lr0.021g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L3\\HGCN_full_findc_plv_dp\\e100_p2fr5_lr0.021g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=4, bias=1, c=None, criteria_dict={}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=5, eval_train=False, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=10, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_12_23_17_00_632497', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=3, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=2, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e100_p2fr5_lr0.021g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e100_p2fr5_lr0.021g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.2, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.3, val_sub=0, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "0 USE Val\n",
      "Traditional split\n",
      "False EXCLUSION\n",
      "90 HOW MANY DID WE KEEP SHOULD BE 45\n",
      "54.0 NUM VAL\n",
      "90\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "now test\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "\n",
      "\n",
      " now\n",
      "[132, 133, 114, 115, 50, 51, 102, 103, 16, 17, 86, 87, 84, 85, 58, 59, 118, 119, 80, 81, 130, 131, 26, 27, 148, 149, 72, 73, 10, 11, 38, 39, 136, 137, 8, 9, 98, 99, 56, 57, 126, 127, 20, 21, 24, 25, 40, 41, 106, 107, 64, 65, 108, 109]\n",
      "90 54 36 lengths\n",
      "180 unique lenths\n",
      "90 54 36 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 14, 15, 18, 19, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 68, 69, 70, 71, 74, 75, 76, 77, 82, 83, 90, 91, 92, 93, 96, 97, 100, 101, 104, 105, 112, 113, 116, 117, 120, 121, 128, 129, 134, 135, 140, 141, 142, 143, 144, 145, 146, 147, 156, 157, 158, 159, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179], 'valid': [132, 133, 114, 115, 50, 51, 102, 103, 16, 17, 86, 87, 84, 85, 58, 59, 118, 119, 80, 81, 130, 131, 26, 27, 148, 149, 72, 73, 10, 11, 38, 39, 136, 137, 8, 9, 98, 99, 56, 57, 126, 127, 20, 21, 24, 25, 40, 41, 106, 107, 64, 65, 108, 109], 'test': [88, 89, 94, 95, 122, 123, 66, 67, 172, 173, 154, 155, 152, 153, 124, 125, 138, 139, 160, 161, 110, 111, 60, 61, 78, 79, 28, 29, 150, 151, 12, 13, 62, 63, 170, 171], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "90 36 54 length\n",
      "{'train': [0, 1, 2, 3, 4, 5, 6, 7, 14, 15, 18, 19, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 68, 69, 70, 71, 74, 75, 76, 77, 82, 83, 90, 91, 92, 93, 96, 97, 100, 101, 104, 105, 112, 113, 116, 117, 120, 121, 128, 129, 134, 135, 140, 141, 142, 143, 144, 145, 146, 147, 156, 157, 158, 159, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179], 'valid': [132, 133, 114, 115, 50, 51, 102, 103, 16, 17, 86, 87, 84, 85, 58, 59, 118, 119, 80, 81, 130, 131, 26, 27, 148, 149, 72, 73, 10, 11, 38, 39, 136, 137, 8, 9, 98, 99, 56, 57, 126, 127, 20, 21, 24, 25, 40, 41, 106, 107, 64, 65, 108, 109], 'test': [88, 89, 94, 95, 122, 123, 66, 67, 172, 173, 154, 155, 152, 153, 124, 125, 138, 139, 160, 161, 110, 111, 60, 61, 78, 79, 28, 29, 150, 151, 12, 13, 62, 63, 170, 171], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "0.03227859777398502 new standard\n",
      "-0.0039200813967295 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "0.027087408946041742 new standard\n",
      "-0.0026239746872457137 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "0.03431903997300958 new standard\n",
      "-0.00683706548986242 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "0.036307673958648104 new standard\n",
      "-0.010256227310130319 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "0.03185125405988161 new standard\n",
      "0.0010359758140816083 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "0.031386820481631925 new standard\n",
      "0.0007501658543285247 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "0.03396800444557268 new standard\n",
      "0.004183948393387939 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "0.033623484893530356 new standard\n",
      "-0.0029039780874298804 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "0.03127302543635446 new standard\n",
      "-0.006565758001793694 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "0.034695356232598645 new standard\n",
      "-0.007896995227210447 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "0.03352595244014014 new standard\n",
      "-0.0017796885114625136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "0.030811283231283248 new standard\n",
      "3.731127911025725e-05 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "0.03244608812040355 new standard\n",
      "-0.0016108397019914539 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "0.033043606490023386 new standard\n",
      "-0.0016607753128357059 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "0.03690146786792895 new standard\n",
      "-0.0035272307223003963 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "0.036919416607331154 new standard\n",
      "-0.01022536277634858 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "0.031724932096420584 new standard\n",
      "0.0051115138568578345 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "0.033138715596862954 new standard\n",
      "0.00529892849129713 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "0.03415746683175193 new standard\n",
      "-0.0035723582005419696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "0.03234736206990305 new standard\n",
      "-0.004169772452503477 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "0.03074598257897055 new standard\n",
      "0.003289116033264406 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "0.030960359503674484 new standard\n",
      "0.005071307869116135 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "0.03328994746875904 new standard\n",
      "-0.0012791121930865593 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "0.03202413705934963 new standard\n",
      "0.003733780494743753 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "0.03472908530820397 new standard\n",
      "0.002934300566518216 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "0.029175906525059296 new standard\n",
      "0.002803001191836236 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "0.03183661558972146 new standard\n",
      "-0.005184785933954619 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "0.033541609239901106 new standard\n",
      "-0.004351625568627227 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "0.034314710594726947 new standard\n",
      "-0.00028483078343487646 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "0.03434252115440518 new standard\n",
      "-0.0007320434868473846 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "0.033008233695195996 new standard\n",
      "0.0023151749143489886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "0.034162637259870184 new standard\n",
      "-0.000938016856952489 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "0.035152625313036985 new standard\n",
      "0.00023761792761095238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "0.032206412451071156 new standard\n",
      "0.001968952237835007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "0.034154995363102764 new standard\n",
      "0.005423066811826095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "0.03239021422797145 new standard\n",
      "0.0022001432121792263 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "0.03149224306155804 new standard\n",
      "-0.004838025848540727 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "0.03405470936113541 new standard\n",
      "-0.0043872958035545305 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "0.029656375546246085 new standard\n",
      "0.006995081179870874 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "0.029132047366106854 new standard\n",
      "0.0035078336404493664 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "0.03376019139392201 new standard\n",
      "0.001434504047653063 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISEessing: 40\n",
      "0.031224809725222968 new standard\n",
      "0.0015948719534051305 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "0.0344850479635006 new standard\n",
      "0.0021984293808650778 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "0.032524491125308023 new standard\n",
      "-0.0009970038905471918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "0.03194230421947245 new standard\n",
      "0.0007557180276905149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "0.0320618469945647 new standard\n",
      "0.003754865729964936 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "0.03523111165612923 new standard\n",
      "-0.0012501734274274375 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "0.03255831275377094 new standard\n",
      "-0.005052546384037259 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "0.030118127640242173 new standard\n",
      "0.0030947110709549563 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "0.029425086985439348 new standard\n",
      "0.0046857818092776345 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "0.030764781387209016 new standard\n",
      "0.007213319247928293 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISE\n",
      "0.03254922819104458 new standard\n",
      "0.007146027467904101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "0.033038781371369313 new standard\n",
      "0.0028176548181156986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISE\n",
      "0.03318683474023096 new standard\n",
      "0.006478607192433181 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISE\n",
      "0.03645025103988002 new standard\n",
      "-2.0625298996367433e-05 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "0.0341047327675689 new standard\n",
      "0.0016062790896434846 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "0.0322953656131018 new standard\n",
      "0.0011016612138152271 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "0.032970962219983115 new standard\n",
      "0.0028742467832224483 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "0.030433014064819654 new standard\n",
      "0.0003570265508040041 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "0.030369374609892367 new standard\n",
      "-0.00023349886805610446 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "0.0325480932250672 new standard\n",
      "-0.0031276218016944484 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "0.034409812414580514 new standard\n",
      "-0.003031057239310691 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "0.034265945640136575 new standard\n",
      "-0.0005039867572853352 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "0.028220516616344626 new standard\n",
      "0.004103732975654356 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "0.03518206084408464 new standard\n",
      "-0.000741940745985786 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "0.03490636524127816 new standard\n",
      "0.0010893379053582893 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "0.03563152002344341 new standard\n",
      "0.0011364723621915733 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "0.0326313237942987 new standard\n",
      "0.00045544648569740534 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "0.035701747059261706 new standard\n",
      "0.0008404966549989223 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "0.03191195951856876 new standard\n",
      "0.002575380148557872 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031549244091045966 new standard\n",
      "0.002151951638438567 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "0.032125151449550624 new standard\n",
      "0.004127954871254843 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "0.03520734637164363 new standard\n",
      "0.0006753380761840406 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "0.03146093096224813 new standard\n",
      "0.0043358505859194965 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "0.034337891193347334 new standard\n",
      "0.001400992263520316 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "0.03256467037438089 new standard\n",
      "0.0025266853282439367 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "0.03240220850035373 new standard\n",
      "0.0056563794133601564 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "0.030765326001307325 new standard\n",
      "0.0015669820928890887 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "0.03408336921429501 new standard\n",
      "-0.009558494836389543 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "0.034040544544176765 new standard\n",
      "-0.003470406038099861 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "0.036241679778179034 new standard\n",
      "-0.013706732704817117 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISEessing: 80\n",
      "0.034042707527080135 new standard\n",
      "-0.00954227403443337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "0.03362176798537299 new standard\n",
      "-0.004887010478553353 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISE\n",
      "0.033776253348252516 new standard\n",
      "-0.002699610753615913 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "0.035069000290306025 new standard\n",
      "-0.005053982494002412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "0.034724355198969124 new standard\n",
      "0.0021666708229425196 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "0.03498933192262309 new standard\n",
      "-0.0052263245121768765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "0.03617876926072434 new standard\n",
      "-0.002452159435495176 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "0.0 ADD NOISE\n",
      "0.033744154511961215 new standard\n",
      "-0.0033973258200300834 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n",
      "0.03318300037704981 new standard\n",
      "-0.005079392696139306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "0.031382553427113574 new standard\n",
      "0.0013552076544077322 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "0.03168421093286738 new standard\n",
      "-0.0008715116204486953 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "0.03288470113138049 new standard\n",
      "-0.0004340405255481884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "0.031108218972293124 new standard\n",
      "-0.0010462495423701188 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "0.03332234093138459 new standard\n",
      "0.0010973685401723283 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "0.03437417596985796 new standard\n",
      "0.00021048061007778015 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "0.033210170203838915 new standard\n",
      "-0.0001760476206610392 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "0.033911137761532 new standard\n",
      "0.0004122738653030075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "0.032101347611318796 new standard\n",
      "-0.0050927556160126515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "0.03260398494619019 new standard\n",
      "-0.001905818044902404 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "0.03252269277785114 new standard\n",
      "0.0010290369451702078 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "0.03377668593953743 new standard\n",
      "0.001069719379307938 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "0.029535269623441412 new standard\n",
      "0.0014485419895616978 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "0.03180531113721723 new standard\n",
      "0.0010622447825036426 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "0.02887228632352304 new standard\n",
      "0.0036253082902217514 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "0.029822634039611013 new standard\n",
      "0.006264369285025532 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "0.029237041545679826 new standard\n",
      "0.006587597647266144 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "0.033250867445557976 new standard\n",
      "-0.0027180476793243658 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "0.030245037899811564 new standard\n",
      "0.002632012335798018 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "0.028942005225057386 new standard\n",
      "-0.00037249630802725116 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "0.0330937256742514 new standard\n",
      "0.005130169034022593 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "0.030627350779458433 new standard\n",
      "0.008618340316461356 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "0.03286857684566148 new standard\n",
      "-0.0013571356968547592 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "0.03388178389797209 new standard\n",
      "0.004156132775687278 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "0.03397555723202849 new standard\n",
      "0.001616916199962145 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "0.03079548321208532 new standard\n",
      "0.006675148111551973 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "0.030686938182626362 new standard\n",
      "0.008988744008599349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISE\n",
      "0.03533032266063567 new standard\n",
      "0.003964112118658091 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "0.02908437862362393 new standard\n",
      "0.004748650348254292 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "0.031353628095221256 new standard\n",
      "0.0010717960307146225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "0.034644520074234124 new standard\n",
      "-0.0011788446409681447 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISEessing: 120\n",
      "0.03562864679192303 new standard\n",
      "-0.0004303713189393436 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "0.02888989758724066 new standard\n",
      "0.009489631618359858 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "0.028454413405279225 new standard\n",
      "0.007518590389505921 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "0.03431551230823769 new standard\n",
      "-0.00640466287464504 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "0.037246905405708 new standard\n",
      "-0.0032494648670491613 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "0.03127189347338052 new standard\n",
      "0.005284673566706592 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISE\n",
      "0.032859127952921924 new standard\n",
      "0.012262515706424311 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "0.03442030646700275 new standard\n",
      "-0.005170895353690045 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "0.033054571332538495 new standard\n",
      "-0.002665032006397841 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "0.034066849768280484 new standard\n",
      "0.0035012163080865937 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "0.029289892726682476 new standard\n",
      "0.003916817855172832 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "0.03515204795560946 new standard\n",
      "-0.0014265020361379657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "0.033558505253326536 new standard\n",
      "-0.002860763416115303 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "0.03612727047472344 new standard\n",
      "-0.0031128185012668946 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "0.03128970576042842 new standard\n",
      "-0.006074160753789414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "0.03264007490164105 new standard\n",
      "-0.001004027846230354 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "0.036345767998348724 new standard\n",
      "0.0011833187344731887 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "0.03626240367159237 new standard\n",
      "-0.006008887988399813 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "0.03523919849648157 new standard\n",
      "-0.003930248227458178 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "0.03198008936881032 new standard\n",
      "0.0014489502228860422 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "0.03305266759607233 new standard\n",
      "0.0011028325359101153 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "0.02887388832675886 new standard\n",
      "-0.0016392360672703192 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "0.034949185735476014 new standard\n",
      "0.00012065213651573548 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "0.03270280468252655 new standard\n",
      "0.004566585085430824 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "0.031122473489296473 new standard\n",
      "0.00221683288219512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "0.03339116702873597 new standard\n",
      "0.0013064527921670484 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0329270150880525 new standard\n",
      "0.000970173020579893 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "0.03711409575904418 new standard\n",
      "0.0029683515664537933 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "0.03456594033652011 new standard\n",
      "0.0021531185801243117 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "0.032909142532712085 new standard\n",
      "0.001891672295627107 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "0.034798005178872646 new standard\n",
      "0.001122199877447573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "0.03350353958037495 new standard\n",
      "-0.000654916270682217 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "0.03369081758542431 new standard\n",
      "-0.0027210680584408902 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "0.03207523503472068 new standard\n",
      "0.0010978352655273392 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "0.03380017423222973 new standard\n",
      "0.0033713542330231143 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "0.03124792630260483 new standard\n",
      "0.006039348449051453 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "0.030972640476482374 new standard\n",
      "0.006066077456829847 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "0.03248303246134034 new standard\n",
      "0.00023314979845924258 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "0.03245002090875756 new standard\n",
      "0.001959751853180965 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "0.0351974166572898 new standard\n",
      "-0.00019526359419768754 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISEessing: 160\n",
      "0.029080669881364447 new standard\n",
      "-0.00127626108928338 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "0.031379516162616805 new standard\n",
      "-0.0018911814186914778 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "0.03453606737542515 new standard\n",
      "0.0008959087018618982 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "0.03222835889917058 new standard\n",
      "0.006073829174571073 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "0.025891315235967813 new standard\n",
      "0.011751251567745999 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "0.03252188918095422 new standard\n",
      "-0.002266353498064558 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "0.03299693998775507 new standard\n",
      "0.0027612484311631074 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "0.035145314593238115 new standard\n",
      "-0.0024429042725897694 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "0.034065162606777236 new standard\n",
      "-0.002199598678383014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "0.034547419869350414 new standard\n",
      "-0.007116041802560156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "0.03485731127775309 new standard\n",
      "-0.002099692296760795 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "0.028982199538958132 new standard\n",
      "0.009141602873374037 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "0.02829660275244678 new standard\n",
      "0.01026482727695748 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "0.03539768101219042 new standard\n",
      "0.0010407356786736315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n",
      "0.03298688722327504 new standard\n",
      "0.0023510879073353336 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "0.0 ADD NOISE\n",
      "0.03510835460437738 new standard\n",
      "-0.001989171572012134 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (2): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 621.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03420123801136374 new standard\n",
      "0.002751372071574633 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "0.032294236000261926 new standard\n",
      "0.0036897306581569994 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "0.032107822804510994 new standard\n",
      "0.004147954725311618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 14, 15, 18, 19, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 68, 69, 70, 71, 74, 75, 76, 77, 82, 83, 90, 91, 92, 93, 96, 97, 100, 101, 104, 105, 112, 113, 116, 117, 120, 121, 128, 129, 134, 135, 140, 141, 142, 143, 144, 145, 146, 147, 156, 157, 158, 159, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '14', '15', '18', '19', '22', '23', '30', '31', '32', '33', '34', '35', '36', '37', '42', '43', '44', '45', '46', '47', '48', '49', '52', '53', '54', '55', '68', '69', '70', '71', '74', '75', '76', '77', '82', '83', '90', '91', '92', '93', '96', '97', '100', '101', '104', '105', '112', '113', '116', '117', '120', '121', '128', '129', '134', '135', '140', '141', '142', '143', '144', '145', '146', '147', '156', '157', '158', '159', '162', '163', '164', '165', '166', '167', '168', '169', '174', '175', '176', '177', '178', '179', '8', '9', '10', '11', '16', '17', '20', '21', '24', '25', '26', '27', '38', '39', '40', '41', '50', '51', '56', '57', '58', '59', '64', '65', '72', '73', '80', '81', '84', '85', '86', '87', '98', '99', '102', '103', '106', '107', '108', '109', '114', '115', '118', '119', '126', '127', '130', '131', '132', '133', '136', '137', '148', '149', '12', '13', '28', '29', '60', '61', '62', '63', '66', '67', '78', '79', '88', '89', '94', '95', '110', '111', '122', '123', '124', '125', '138', '139', '150', '151', '152', '153', '154', '155', '160', '161', '170', '171', '172', '173'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[132, 133, 114, 115, 50, 51, 102, 103, 16, 17, 86, 87, 84, 85, 58, 59, 118, 119, 80, 81, 130, 131, 26, 27, 148, 149, 72, 73, 10, 11, 38, 39, 136, 137, 8, 9, 98, 99, 56, 57, 126, 127, 20, 21, 24, 25, 40, 41, 106, 107, 64, 65, 108, 109] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '14', '15', '18', '19', '22', '23', '30', '31', '32', '33', '34', '35', '36', '37', '42', '43', '44', '45', '46', '47', '48', '49', '52', '53', '54', '55', '68', '69', '70', '71', '74', '75', '76', '77', '82', '83', '90', '91', '92', '93', '96', '97', '100', '101', '104', '105', '112', '113', '116', '117', '120', '121', '128', '129', '134', '135', '140', '141', '142', '143', '144', '145', '146', '147', '156', '157', '158', '159', '162', '163', '164', '165', '166', '167', '168', '169', '174', '175', '176', '177', '178', '179', '8', '9', '10', '11', '16', '17', '20', '21', '24', '25', '26', '27', '38', '39', '40', '41', '50', '51', '56', '57', '58', '59', '64', '65', '72', '73', '80', '81', '84', '85', '86', '87', '98', '99', '102', '103', '106', '107', '108', '109', '114', '115', '118', '119', '126', '127', '130', '131', '132', '133', '136', '137', '148', '149', '12', '13', '28', '29', '60', '61', '62', '63', '66', '67', '78', '79', '88', '89', '94', '95', '110', '111', '122', '123', '124', '125', '138', '139', '150', '151', '152', '153', '154', '155', '160', '161', '170', '171', '172', '173'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[88, 89, 94, 95, 122, 123, 66, 67, 172, 173, 154, 155, 152, 153, 124, 125, 138, 139, 160, 161, 110, 111, 60, 61, 78, 79, 28, 29, 150, 151, 12, 13, 62, 63, 170, 171] SELF INDICES\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '14', '15', '18', '19', '22', '23', '30', '31', '32', '33', '34', '35', '36', '37', '42', '43', '44', '45', '46', '47', '48', '49', '52', '53', '54', '55', '68', '69', '70', '71', '74', '75', '76', '77', '82', '83', '90', '91', '92', '93', '96', '97', '100', '101', '104', '105', '112', '113', '116', '117', '120', '121', '128', '129', '134', '135', '140', '141', '142', '143', '144', '145', '146', '147', '156', '157', '158', '159', '162', '163', '164', '165', '166', '167', '168', '169', '174', '175', '176', '177', '178', '179', '8', '9', '10', '11', '16', '17', '20', '21', '24', '25', '26', '27', '38', '39', '40', '41', '50', '51', '56', '57', '58', '59', '64', '65', '72', '73', '80', '81', '84', '85', '86', '87', '98', '99', '102', '103', '106', '107', '108', '109', '114', '115', '118', '119', '126', '127', '130', '131', '132', '133', '136', '137', '148', '149', '12', '13', '28', '29', '60', '61', '62', '63', '66', '67', '78', '79', '88', '89', '94', '95', '110', '111', '122', '123', '124', '125', '138', '139', '150', '151', '152', '153', '154', '155', '160', '161', '170', '171', '172', '173'] dta set indices\n",
      "90 36 54\n",
      "-1 ARG FREQ\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6, 6] dims\n",
      "[91, 6, 6, 3] dims after\n",
      "[91, 6, 6, 3] dims\n",
      "[<function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>] acts\n",
      "[True, True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) SLEF C\n",
      "no pruner\n",
      "no trial\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6, 6] dims\n",
      "[91, 6, 6, 3] dims after\n",
      "[91, 6, 6, 3] dims\n",
      "[<function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>, <function selu at 0x000002B023F05D38>] acts\n",
      "[True, True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) SLEF C\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x000002B0380163C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "<generator object Module.parameters at 0x000002B0459833C8> MODEL PARAMS\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "model\n",
      "<generator object Module.parameters at 0x000002B0459833C8> MODEL PARAMS\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "90 train length\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0133], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0133], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0133], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.0102], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0102], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0102], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0102], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.0210], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.0210], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0210], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0242], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0242], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0242], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9997], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9869], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.9997], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9997], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.9997], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.0112], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9899], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([1.0112], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0112], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9794], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0346], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0346], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0346], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9881], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9763], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.9881], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9881], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.9881], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0003], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9984], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9889], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0520], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0520], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0520], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9676], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9665], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.9676], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9676], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.9676], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9779], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0121], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9779], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9779], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0016], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0766], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0766], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0766], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9441], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9506], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.9441], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9441], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.9441], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9558], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0335], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9558], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9558], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0226], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0923], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0923], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0923], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9142], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9288], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.9142], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9142], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.9142], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.9268], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0593], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.9268], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.9268], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0463], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.0921], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.0921], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.0921], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.8791], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-0.9155], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=6, c=Parameter containing:\n",
      "    tensor([0.8791], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.8791], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([0.8791], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([0.8972], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0938], grad_fn=<MulBackward0>) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=3, c=Parameter containing:\n",
      "    tensor([0.8972], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([0.8972], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor([-1.0790], grad_fn=<MulBackward0>) agg man\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   nan,    nan, 0.8778, 0.8793,    nan, 0.8755,    nan,    nan, 0.8739,\n",
      "        0.8794,    nan, 0.8803, 0.8724, 0.8802,    nan, 0.8755,    nan, 0.8711,\n",
      "        0.8754, 0.8756, 0.8714, 0.8612,    nan, 0.8741, 0.8774, 0.8598, 0.8660,\n",
      "           nan, 0.8766, 0.8313, 0.8808,    nan, 0.8182, 0.8808, 0.8791, 0.8649,\n",
      "        0.8796, 0.8643, 0.8766, 0.8683,    nan, 0.8763, 0.8609, 0.8804, 0.8785,\n",
      "           nan,    nan,    nan, 0.8766, 0.8783, 0.8634,    nan, 0.8781, 0.8698,\n",
      "           nan,    nan, 0.8641, 0.8718, 0.8807,    nan,    nan, 0.8788, 0.8792,\n",
      "           nan, 0.8764, 0.8653, 0.8796,    nan, 0.8800,    nan,    nan, 0.8771,\n",
      "           nan, 0.8782, 0.8798, 0.8758, 0.8794, 0.8789, 0.8420,    nan,    nan,\n",
      "        0.8631, 0.8706,    nan, 0.8772,    nan, 0.8759,    nan,    nan,    nan,\n",
      "           nan, 0.8763, 0.8798,    nan, 0.8773, 0.8757,    nan,    nan,    nan,\n",
      "        0.8786,    nan, 0.8768, 0.8711,    nan,    nan,    nan, 0.8806, 0.8723,\n",
      "           nan, 0.8395, 0.8775,    nan, 0.8541,    nan, 0.8166, 0.8678, 0.8678,\n",
      "        0.8747,    nan, 0.8562, 0.8779,    nan, 0.8737,    nan, 0.8787,    nan,\n",
      "           nan, 0.8678, 0.8742,    nan,    nan, 0.8729, 0.8626, 0.8676,    nan,\n",
      "           nan, 0.8607, 0.8719, 0.8432, 0.8195, 0.8802, 0.8795, 0.8733, 0.8721,\n",
      "        0.8736, 0.8792, 0.8774, 0.8253, 0.8787, 0.8731, 0.8799, 0.8717,    nan,\n",
      "        0.8796, 0.8420, 0.8625, 0.8610, 0.8773,    nan, 0.8696,    nan,    nan,\n",
      "           nan, 0.8729, 0.8751,    nan, 0.8805, 0.8764,    nan, 0.8805,    nan,\n",
      "        0.8566, 0.8761, 0.8651, 0.8772,    nan, 0.8785, 0.8752, 0.8806, 0.8789,\n",
      "        0.8736, 0.8784, 0.8726,    nan, 0.8710, 0.8803, 0.8500, 0.8765, 0.8795,\n",
      "           nan, 0.8806, 0.8639,    nan,    nan,    nan, 0.8756,    nan, 0.8794,\n",
      "        0.8781, 0.8780, 0.8767, 0.8710, 0.8741,    nan, 0.8574, 0.8530,    nan,\n",
      "        0.8793, 0.8788, 0.8770, 0.8727,    nan,    nan,    nan,    nan, 0.8802,\n",
      "        0.8793, 0.8662, 0.8778,    nan, 0.8757, 0.8798,    nan,    nan,    nan,\n",
      "        0.8802,    nan, 0.8755, 0.8738,    nan, 0.8784, 0.8752,    nan, 0.8785,\n",
      "           nan,    nan, 0.8804, 0.8679, 0.8804, 0.8798, 0.8538, 0.8793, 0.8804,\n",
      "           nan, 0.8737, 0.8713, 0.8796, 0.8779, 0.8805,    nan, 0.8770, 0.8800,\n",
      "        0.8764, 0.8763, 0.8786,    nan, 0.8571, 0.8310, 0.8725, 0.8776,    nan,\n",
      "           nan, 0.8807, 0.8770, 0.8628, 0.8494, 0.8610, 0.8796,    nan, 0.8314,\n",
      "           nan, 0.8703, 0.8803, 0.8801,    nan, 0.8627,    nan,    nan, 0.8803,\n",
      "        0.8776, 0.8794, 0.8738, 0.8762, 0.8719, 0.8749, 0.8746, 0.8683, 0.8797,\n",
      "        0.8689, 0.8769,    nan, 0.8795,    nan, 0.8733, 0.8611, 0.8791,    nan,\n",
      "           nan,    nan, 0.8802, 0.8805, 0.8743,    nan, 0.8512, 0.8765,    nan,\n",
      "        0.8807,    nan, 0.8795, 0.8576, 0.8722, 0.8787,    nan,    nan, 0.8741,\n",
      "        0.8779, 0.8516, 0.8419, 0.8784, 0.8635, 0.8783,    nan, 0.8789, 0.8659,\n",
      "        0.8698, 0.8792, 0.8784, 0.8781, 0.8794,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan, 0.8778, 0.8801,    nan, 0.8720, 0.8793, 0.8785,    nan,\n",
      "        0.8808,    nan, 0.8747, 0.8772, 0.8668, 0.8463, 0.8787, 0.8785, 0.8757,\n",
      "        0.8741,    nan,    nan,    nan, 0.8741, 0.8726, 0.8797, 0.8779,    nan,\n",
      "        0.8750,    nan, 0.8682, 0.8778, 0.8696, 0.8564, 0.8658, 0.8727, 0.8803,\n",
      "        0.8606, 0.8763,    nan, 0.8566, 0.8698, 0.8796,    nan, 0.8736, 0.8765,\n",
      "           nan,    nan, 0.8695, 0.8795,    nan,    nan, 0.8781, 0.8729, 0.8223,\n",
      "        0.8490, 0.8689, 0.8763,    nan, 0.8786, 0.8792,    nan, 0.8672,    nan,\n",
      "           nan, 0.8780, 0.8789,    nan,    nan, 0.8792,    nan,    nan, 0.8645,\n",
      "        0.8797, 0.8787, 0.8804, 0.8462,    nan, 0.8726,    nan, 0.8652, 0.8734,\n",
      "        0.8688, 0.8767, 0.8774, 0.8778, 0.8761, 0.8713, 0.8706, 0.8672,    nan,\n",
      "        0.8753, 0.8507, 0.8764, 0.8807, 0.8769, 0.8707,    nan, 0.8803, 0.8752,\n",
      "           nan,    nan,    nan,    nan,    nan, 0.8792,    nan, 0.8731, 0.8773,\n",
      "        0.8798, 0.8678, 0.8764, 0.8655,    nan,    nan, 0.8728,    nan, 0.8798,\n",
      "        0.8659, 0.8805, 0.8802, 0.8464,    nan,    nan, 0.8783, 0.8697, 0.8768,\n",
      "           nan, 0.8778,    nan, 0.8751,    nan, 0.8712, 0.8688, 0.8778,    nan,\n",
      "        0.8728, 0.8419, 0.8656,    nan,    nan,    nan,    nan, 0.8651, 0.8718,\n",
      "        0.8793, 0.8788, 0.8803, 0.8754, 0.8783, 0.8224, 0.8693, 0.8788,    nan,\n",
      "           nan,    nan,    nan, 0.8587, 0.8540, 0.8389, 0.8603,    nan, 0.8792,\n",
      "        0.8803, 0.8793,    nan, 0.8706, 0.8803, 0.8786,    nan, 0.8768,    nan,\n",
      "        0.8807, 0.8805,    nan,    nan,    nan, 0.8807, 0.8794, 0.8785, 0.6744,\n",
      "        0.8704, 0.8785, 0.8777,    nan,    nan,    nan, 0.8794, 0.8694, 0.8726,\n",
      "           nan, 0.8677, 0.8693,    nan, 0.8649,    nan,    nan,    nan,    nan,\n",
      "        0.8739,    nan, 0.8672, 0.8768, 0.8805,    nan, 0.8761,    nan,    nan,\n",
      "        0.8712, 0.8807, 0.8599, 0.8800, 0.8787,    nan, 0.8667, 0.8791, 0.8790,\n",
      "        0.8731, 0.8798,    nan,    nan,    nan, 0.8722, 0.8695, 0.8780, 0.8690,\n",
      "        0.8762,    nan, 0.8749,    nan,    nan, 0.8769, 0.8808, 0.8785, 0.8800,\n",
      "        0.8648, 0.8799, 0.8801, 0.8804, 0.8746, 0.8681, 0.8774, 0.8714,    nan,\n",
      "        0.8760, 0.8419,    nan, 0.8794, 0.8492,    nan, 0.8784,    nan,    nan,\n",
      "           nan, 0.8548, 0.8791,    nan, 0.8785,    nan, 0.8700, 0.8791, 0.8742,\n",
      "        0.8765,    nan, 0.8784, 0.8703, 0.8782,    nan, 0.8766, 0.8755, 0.8409,\n",
      "        0.8640, 0.8795, 0.8763, 0.8803, 0.8612, 0.8740, 0.8752, 0.8786,    nan,\n",
      "        0.8804, 0.8771,    nan, 0.8747, 0.8670, 0.8805, 0.8696, 0.8508, 0.8746,\n",
      "        0.8772,    nan, 0.8693,    nan, 0.8394, 0.8640, 0.8668,    nan,    nan,\n",
      "           nan,    nan, 0.8579, 0.8745, 0.8792, 0.8746, 0.8793, 0.8796, 0.8794,\n",
      "        0.8697, 0.8794,    nan, 0.8801, 0.8751, 0.8786, 0.8805, 0.8635, 0.8641,\n",
      "        0.8786, 0.8805, 0.8743, 0.8788, 0.8804, 0.8792,    nan,    nan,    nan,\n",
      "        0.8783,    nan, 0.8800, 0.8776,    nan, 0.7934, 0.8752, 0.8686, 0.8793,\n",
      "           nan,    nan, 0.8791, 0.8622, 0.8766, 0.8643,    nan, 0.8806,    nan,\n",
      "        0.8765,    nan, 0.8749, 0.8807, 0.8803, 0.8690,    nan, 0.8754, 0.8612,\n",
      "        0.8804, 0.8696, 0.8686, 0.8746, 0.8528,    nan, 0.8751, 0.8790, 0.8738,\n",
      "        0.8729, 0.8805, 0.8808, 0.8740, 0.8683, 0.8746, 0.8757, 0.8806, 0.8770,\n",
      "        0.8716,    nan, 0.8632,    nan, 0.8744,    nan,    nan, 0.8741, 0.8691,\n",
      "        0.8627,    nan, 0.8799, 0.8697, 0.8796,    nan, 0.8590, 0.8742, 0.8800,\n",
      "        0.8756,    nan,    nan, 0.8622,    nan, 0.8681, 0.8808,    nan,    nan,\n",
      "        0.8701, 0.8787, 0.8782, 0.8705, 0.8635, 0.8763, 0.8764,    nan, 0.8587,\n",
      "           nan, 0.8429, 0.8806,    nan, 0.8776, 0.8767,    nan, 0.8794, 0.8778,\n",
      "           nan,    nan, 0.8806, 0.8771, 0.8779, 0.8789, 0.8780, 0.8808, 0.8803,\n",
      "        0.8797,    nan, 0.8648, 0.8689, 0.8678, 0.8734, 0.8668, 0.8727,    nan,\n",
      "           nan, 0.8698,    nan, 0.8722, 0.8726, 0.8569, 0.8799, 0.8798,    nan,\n",
      "           nan,    nan,    nan,    nan, 0.8799, 0.8808, 0.8218, 0.8711, 0.8806,\n",
      "           nan,    nan, 0.8114, 0.8439,    nan, 0.8777, 0.8792],\n",
      "       grad_fn=<CatBackward0>) pos scores??\n",
      "NANS IN POS SCORES\n",
      "tensor([0.0100, 0.0100, 0.8778, 0.8793, 0.0100, 0.8755, 0.0100, 0.0100, 0.8739,\n",
      "        0.8794, 0.0100, 0.8803, 0.8724, 0.8802, 0.0100, 0.8755, 0.0100, 0.8711,\n",
      "        0.8754, 0.8756, 0.8714, 0.8612, 0.0100, 0.8741, 0.8774, 0.8598, 0.8660,\n",
      "        0.0100, 0.8766, 0.8313, 0.8808, 0.0100, 0.8182, 0.8808, 0.8791, 0.8649,\n",
      "        0.8796, 0.8643, 0.8766, 0.8683, 0.0100, 0.8763, 0.8609, 0.8804, 0.8785,\n",
      "        0.0100, 0.0100, 0.0100, 0.8766, 0.8783, 0.8634, 0.0100, 0.8781, 0.8698,\n",
      "        0.0100, 0.0100, 0.8641, 0.8718, 0.8807, 0.0100, 0.0100, 0.8788, 0.8792,\n",
      "        0.0100, 0.8764, 0.8653, 0.8796, 0.0100, 0.8800, 0.0100, 0.0100, 0.8771,\n",
      "        0.0100, 0.8782, 0.8798, 0.8758, 0.8794, 0.8789, 0.8420, 0.0100, 0.0100,\n",
      "        0.8631, 0.8706, 0.0100, 0.8772, 0.0100, 0.8759, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.8763, 0.8798, 0.0100, 0.8773, 0.8757, 0.0100, 0.0100, 0.0100,\n",
      "        0.8786, 0.0100, 0.8768, 0.8711, 0.0100, 0.0100, 0.0100, 0.8806, 0.8723,\n",
      "        0.0100, 0.8395, 0.8775, 0.0100, 0.8541, 0.0100, 0.8166, 0.8678, 0.8678,\n",
      "        0.8747, 0.0100, 0.8562, 0.8779, 0.0100, 0.8737, 0.0100, 0.8787, 0.0100,\n",
      "        0.0100, 0.8678, 0.8742, 0.0100, 0.0100, 0.8729, 0.8626, 0.8676, 0.0100,\n",
      "        0.0100, 0.8607, 0.8719, 0.8432, 0.8195, 0.8802, 0.8795, 0.8733, 0.8721,\n",
      "        0.8736, 0.8792, 0.8774, 0.8253, 0.8787, 0.8731, 0.8799, 0.8717, 0.0100,\n",
      "        0.8796, 0.8420, 0.8625, 0.8610, 0.8773, 0.0100, 0.8696, 0.0100, 0.0100,\n",
      "        0.0100, 0.8729, 0.8751, 0.0100, 0.8805, 0.8764, 0.0100, 0.8805, 0.0100,\n",
      "        0.8566, 0.8761, 0.8651, 0.8772, 0.0100, 0.8785, 0.8752, 0.8806, 0.8789,\n",
      "        0.8736, 0.8784, 0.8726, 0.0100, 0.8710, 0.8803, 0.8500, 0.8765, 0.8795,\n",
      "        0.0100, 0.8806, 0.8639, 0.0100, 0.0100, 0.0100, 0.8756, 0.0100, 0.8794,\n",
      "        0.8781, 0.8780, 0.8767, 0.8710, 0.8741, 0.0100, 0.8574, 0.8530, 0.0100,\n",
      "        0.8793, 0.8788, 0.8770, 0.8727, 0.0100, 0.0100, 0.0100, 0.0100, 0.8802,\n",
      "        0.8793, 0.8662, 0.8778, 0.0100, 0.8757, 0.8798, 0.0100, 0.0100, 0.0100,\n",
      "        0.8802, 0.0100, 0.8755, 0.8738, 0.0100, 0.8784, 0.8752, 0.0100, 0.8785,\n",
      "        0.0100, 0.0100, 0.8804, 0.8679, 0.8804, 0.8798, 0.8538, 0.8793, 0.8804,\n",
      "        0.0100, 0.8737, 0.8713, 0.8796, 0.8779, 0.8805, 0.0100, 0.8770, 0.8800,\n",
      "        0.8764, 0.8763, 0.8786, 0.0100, 0.8571, 0.8310, 0.8725, 0.8776, 0.0100,\n",
      "        0.0100, 0.8807, 0.8770, 0.8628, 0.8494, 0.8610, 0.8796, 0.0100, 0.8314,\n",
      "        0.0100, 0.8703, 0.8803, 0.8801, 0.0100, 0.8627, 0.0100, 0.0100, 0.8803,\n",
      "        0.8776, 0.8794, 0.8738, 0.8762, 0.8719, 0.8749, 0.8746, 0.8683, 0.8797,\n",
      "        0.8689, 0.8769, 0.0100, 0.8795, 0.0100, 0.8733, 0.8611, 0.8791, 0.0100,\n",
      "        0.0100, 0.0100, 0.8802, 0.8805, 0.8743, 0.0100, 0.8512, 0.8765, 0.0100,\n",
      "        0.8807, 0.0100, 0.8795, 0.8576, 0.8722, 0.8787, 0.0100, 0.0100, 0.8741,\n",
      "        0.8779, 0.8516, 0.8419, 0.8784, 0.8635, 0.8783, 0.0100, 0.8789, 0.8659,\n",
      "        0.8698, 0.8792, 0.8784, 0.8781, 0.8794, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.8778, 0.8801, 0.0100, 0.8720, 0.8793, 0.8785, 0.0100,\n",
      "        0.8808, 0.0100, 0.8747, 0.8772, 0.8668, 0.8463, 0.8787, 0.8785, 0.8757,\n",
      "        0.8741, 0.0100, 0.0100, 0.0100, 0.8741, 0.8726, 0.8797, 0.8779, 0.0100,\n",
      "        0.8750, 0.0100, 0.8682, 0.8778, 0.8696, 0.8564, 0.8658, 0.8727, 0.8803,\n",
      "        0.8606, 0.8763, 0.0100, 0.8566, 0.8698, 0.8796, 0.0100, 0.8736, 0.8765,\n",
      "        0.0100, 0.0100, 0.8695, 0.8795, 0.0100, 0.0100, 0.8781, 0.8729, 0.8223,\n",
      "        0.8490, 0.8689, 0.8763, 0.0100, 0.8786, 0.8792, 0.0100, 0.8672, 0.0100,\n",
      "        0.0100, 0.8780, 0.8789, 0.0100, 0.0100, 0.8792, 0.0100, 0.0100, 0.8645,\n",
      "        0.8797, 0.8787, 0.8804, 0.8462, 0.0100, 0.8726, 0.0100, 0.8652, 0.8734,\n",
      "        0.8688, 0.8767, 0.8774, 0.8778, 0.8761, 0.8713, 0.8706, 0.8672, 0.0100,\n",
      "        0.8753, 0.8507, 0.8764, 0.8807, 0.8769, 0.8707, 0.0100, 0.8803, 0.8752,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.8792, 0.0100, 0.8731, 0.8773,\n",
      "        0.8798, 0.8678, 0.8764, 0.8655, 0.0100, 0.0100, 0.8728, 0.0100, 0.8798,\n",
      "        0.8659, 0.8805, 0.8802, 0.8464, 0.0100, 0.0100, 0.8783, 0.8697, 0.8768,\n",
      "        0.0100, 0.8778, 0.0100, 0.8751, 0.0100, 0.8712, 0.8688, 0.8778, 0.0100,\n",
      "        0.8728, 0.8419, 0.8656, 0.0100, 0.0100, 0.0100, 0.0100, 0.8651, 0.8718,\n",
      "        0.8793, 0.8788, 0.8803, 0.8754, 0.8783, 0.8224, 0.8693, 0.8788, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.8587, 0.8540, 0.8389, 0.8603, 0.0100, 0.8792,\n",
      "        0.8803, 0.8793, 0.0100, 0.8706, 0.8803, 0.8786, 0.0100, 0.8768, 0.0100,\n",
      "        0.8807, 0.8805, 0.0100, 0.0100, 0.0100, 0.8807, 0.8794, 0.8785, 0.6744,\n",
      "        0.8704, 0.8785, 0.8777, 0.0100, 0.0100, 0.0100, 0.8794, 0.8694, 0.8726,\n",
      "        0.0100, 0.8677, 0.8693, 0.0100, 0.8649, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.8739, 0.0100, 0.8672, 0.8768, 0.8805, 0.0100, 0.8761, 0.0100, 0.0100,\n",
      "        0.8712, 0.8807, 0.8599, 0.8800, 0.8787, 0.0100, 0.8667, 0.8791, 0.8790,\n",
      "        0.8731, 0.8798, 0.0100, 0.0100, 0.0100, 0.8722, 0.8695, 0.8780, 0.8690,\n",
      "        0.8762, 0.0100, 0.8749, 0.0100, 0.0100, 0.8769, 0.8808, 0.8785, 0.8800,\n",
      "        0.8648, 0.8799, 0.8801, 0.8804, 0.8746, 0.8681, 0.8774, 0.8714, 0.0100,\n",
      "        0.8760, 0.8419, 0.0100, 0.8794, 0.8492, 0.0100, 0.8784, 0.0100, 0.0100,\n",
      "        0.0100, 0.8548, 0.8791, 0.0100, 0.8785, 0.0100, 0.8700, 0.8791, 0.8742,\n",
      "        0.8765, 0.0100, 0.8784, 0.8703, 0.8782, 0.0100, 0.8766, 0.8755, 0.8409,\n",
      "        0.8640, 0.8795, 0.8763, 0.8803, 0.8612, 0.8740, 0.8752, 0.8786, 0.0100,\n",
      "        0.8804, 0.8771, 0.0100, 0.8747, 0.8670, 0.8805, 0.8696, 0.8508, 0.8746,\n",
      "        0.8772, 0.0100, 0.8693, 0.0100, 0.8394, 0.8640, 0.8668, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.8579, 0.8745, 0.8792, 0.8746, 0.8793, 0.8796, 0.8794,\n",
      "        0.8697, 0.8794, 0.0100, 0.8801, 0.8751, 0.8786, 0.8805, 0.8635, 0.8641,\n",
      "        0.8786, 0.8805, 0.8743, 0.8788, 0.8804, 0.8792, 0.0100, 0.0100, 0.0100,\n",
      "        0.8783, 0.0100, 0.8800, 0.8776, 0.0100, 0.7934, 0.8752, 0.8686, 0.8793,\n",
      "        0.0100, 0.0100, 0.8791, 0.8622, 0.8766, 0.8643, 0.0100, 0.8806, 0.0100,\n",
      "        0.8765, 0.0100, 0.8749, 0.8807, 0.8803, 0.8690, 0.0100, 0.8754, 0.8612,\n",
      "        0.8804, 0.8696, 0.8686, 0.8746, 0.8528, 0.0100, 0.8751, 0.8790, 0.8738,\n",
      "        0.8729, 0.8805, 0.8808, 0.8740, 0.8683, 0.8746, 0.8757, 0.8806, 0.8770,\n",
      "        0.8716, 0.0100, 0.8632, 0.0100, 0.8744, 0.0100, 0.0100, 0.8741, 0.8691,\n",
      "        0.8627, 0.0100, 0.8799, 0.8697, 0.8796, 0.0100, 0.8590, 0.8742, 0.8800,\n",
      "        0.8756, 0.0100, 0.0100, 0.8622, 0.0100, 0.8681, 0.8808, 0.0100, 0.0100,\n",
      "        0.8701, 0.8787, 0.8782, 0.8705, 0.8635, 0.8763, 0.8764, 0.0100, 0.8587,\n",
      "        0.0100, 0.8429, 0.8806, 0.0100, 0.8776, 0.8767, 0.0100, 0.8794, 0.8778,\n",
      "        0.0100, 0.0100, 0.8806, 0.8771, 0.8779, 0.8789, 0.8780, 0.8808, 0.8803,\n",
      "        0.8797, 0.0100, 0.8648, 0.8689, 0.8678, 0.8734, 0.8668, 0.8727, 0.0100,\n",
      "        0.0100, 0.8698, 0.0100, 0.8722, 0.8726, 0.8569, 0.8799, 0.8798, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.8799, 0.8808, 0.8218, 0.8711, 0.8806,\n",
      "        0.0100, 0.0100, 0.8114, 0.8439, 0.0100, 0.8777, 0.8792],\n",
      "       grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n",
      "NANS IN NEG SCORES\n",
      "tensor([0.8798, 0.9900, 0.9900,  ..., 0.8737, 0.8556, 0.9900],\n",
      "       grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py:199: UserWarning: Error detected in ReciprocalBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n",
      "    cell_id=cell_id,\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\coleb\\AppData\\Local\\Temp\\ipykernel_25064\\1627162578.py\", line 46, in <module>\n",
      "    complete_study_one_arg(args,NUM_VALIDATIONS)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\", line 279, in complete_study_one_arg\n",
      "    train_inductive.train(args_copy)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\", line 286, in train\n",
      "    train_metrics=model.compute_metrics_multiple(embeddings_list,data_list,'train')\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 534, in compute_metrics_multiple\n",
      "    neg_scores = self.decode(embeddings, edges_false)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 158, in decode\n",
      "    probs = self.dc.forward(sqdist)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\layers\\layers.py\", line 141, in forward\n",
      "    probs = 1. / (torch.exp(  torch.clamp( ((dist - self.r) / self.t),max=max_clamp))+ 1.0)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 39, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 838, in __rdiv__\n",
      "    return self.reciprocal() * other\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\fx\\traceback.py\", line 57, in format_stack\n",
      "    return traceback.format_stack()\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'ReciprocalBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25064\\1627162578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'ReciprocalBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':0,\n",
    "          'lr':.021,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713a7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbd527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcf7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644379a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
