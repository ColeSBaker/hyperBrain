{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad3f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported utils\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used for recreating the link prediction results for different parameter settings\n",
    "and dimensionality\n",
    "\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "from params import *\n",
    "# from params import BAND_TO_OPT_C\n",
    "import sys\n",
    "from datetime import date\n",
    "import pickle\n",
    "import train_inductive\n",
    "# should we not make a seperate config for out \"official runnings\"\n",
    "from trials.hyperparam_config import config\n",
    "import pickle\n",
    "import optuna\n",
    "import copy\n",
    "from utils.train_utils import get_dir_name, format_metrics\n",
    "from main import parse_default_args\n",
    "# import t\n",
    "from hyperparam import create_study_output_dir,create_objective_fun,complete_study_one_arg\n",
    "from utils.model_analysis_utils import save_embeddings_all\n",
    "from data.MEG import get_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2502fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trials.hyperparam_config import config\n",
    "from main import parse_default_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480a27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_OPT_C= { \n",
    "           'alpha':.54,\n",
    "           'gamma':.66,\n",
    "           'beta': .74,\n",
    "            'theta':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_arch_dict={'model':'HGCN','optimizer':'RiemannianAdam','manifold':'PoincareBall'}\n",
    "euc_arch_dict={'model':'GCN','optimizer':'Adam','manifold':'Euclidean'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 'set'},\n",
       " 'findc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': None},\n",
       " '1c': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 1},\n",
       " 'euc': {'model': 'GCN', 'optimizer': 'Adam', 'manifold': 'Euclidean', 'c': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_types={'full':{'use_weight':1,'use_virtual':1},\n",
    "            'no_virt':{'use_weight':1,'use_virtual':0},\n",
    "                'no_weight':{'use_weight':0,'use_virtual':1}}\n",
    "\n",
    "input_types={'plv':{'use_plv':1,'use_identity':0,'num_feature':91},\n",
    "             'id':{'use_plv':0,'use_identity':1,'num_feature':91},\n",
    "             'id_plv':{'use_plv':1,'use_identity':1,'num_feature':181}}\n",
    "\n",
    "\n",
    "curve_types={'setc':{**hyp_arch_dict,'c':'set'},\n",
    "            'findc':{**hyp_arch_dict,'c':None},\n",
    "            '1c':{**hyp_arch_dict,'c':1},\n",
    "             'euc':{**euc_arch_dict,'c':0},\n",
    "            }\n",
    "curve_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72779412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 1, PLV 0\n",
      "C: None, ID: 1, PLV 0\n",
      "\n",
      "\n",
      "HGCN_full_findc_id_dp model\n",
      "HGCN_full_findc_id_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L2\\HGCN_full_findc_id_dp\\e100_p2fr5_lr0.015g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\april\\all_pats\\L2\\HGCN_full_findc_id_dp\\e100_p2fr5_lr0.015g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=4, bias=1, c=None, criteria_dict={}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=100, eval_freq=5, eval_train=False, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.015, lr_reduce_freq=10, manifold='PoincareBall', match_plv_inp_loss=0, max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_04_13_00_47_17_942560', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=2, patience=2, plv_inp_raw=0, plv_norm_w_id=0, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L2\\\\HGCN_full_findc_id_dp\\\\e100_p2fr5_lr0.015g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn\\\\0', save_id='', save_model=False, split_seed=1234, stretch_loss=95, stretch_pct=95, stretch_r=0.34, stretch_sigmoid=0, stretch_t=0.03, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\april\\\\all_pats\\\\L2\\\\HGCN_full_findc_id_dp\\\\e100_p2fr5_lr0.015g0.9lf_10_strchinpvpct0.3_tpct0.2_95_bstrchloss95_lnmse_pn', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.2, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, unify_pos_neg_loss=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=1, use_norm=0, use_plv=0, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_bce=0, use_weighted_loss=1, val_prop=0.3, val_sub=0, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "0 USE Val\n",
      "Traditional split\n",
      "False EXCLUSION\n",
      "90 HOW MANY DID WE KEEP SHOULD BE 45\n",
      "54.0 NUM VAL\n",
      "90\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "now test\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "whoopsie\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "(2, 64) matching rows\n",
      "\n",
      "\n",
      " now\n",
      "[136, 137, 102, 103, 34, 35, 124, 125, 144, 145, 134, 135, 152, 153, 162, 163, 146, 147, 8, 9, 90, 91, 76, 77, 44, 45, 84, 85, 60, 61, 114, 115, 100, 101, 112, 113, 54, 55, 178, 179, 28, 29, 86, 87, 22, 23, 32, 33, 26, 27, 18, 19, 98, 99]\n",
      "90 54 36 lengths\n",
      "180 unique lenths\n",
      "90 54 36 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 16, 17, 20, 21, 24, 25, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 52, 53, 56, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 92, 93, 94, 95, 108, 109, 116, 117, 118, 119, 120, 121, 126, 127, 142, 143, 148, 149, 150, 151, 154, 155, 156, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177], 'valid': [136, 137, 102, 103, 34, 35, 124, 125, 144, 145, 134, 135, 152, 153, 162, 163, 146, 147, 8, 9, 90, 91, 76, 77, 44, 45, 84, 85, 60, 61, 114, 115, 100, 101, 112, 113, 54, 55, 178, 179, 28, 29, 86, 87, 22, 23, 32, 33, 26, 27, 18, 19, 98, 99], 'test': [130, 131, 132, 133, 110, 111, 88, 89, 58, 59, 96, 97, 104, 105, 128, 129, 106, 107, 68, 69, 50, 51, 4, 5, 160, 161, 138, 139, 14, 15, 122, 123, 158, 159, 140, 141], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "90 36 54 length\n",
      "{'train': [0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 16, 17, 20, 21, 24, 25, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 52, 53, 56, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 92, 93, 94, 95, 108, 109, 116, 117, 118, 119, 120, 121, 126, 127, 142, 143, 148, 149, 150, 151, 154, 155, 156, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177], 'valid': [136, 137, 102, 103, 34, 35, 124, 125, 144, 145, 134, 135, 152, 153, 162, 163, 146, 147, 8, 9, 90, 91, 76, 77, 44, 45, 84, 85, 60, 61, 114, 115, 100, 101, 112, 113, 54, 55, 178, 179, 28, 29, 86, 87, 22, 23, 32, 33, 26, 27, 18, 19, 98, 99], 'test': [130, 131, 132, 133, 110, 111, 88, 89, 58, 59, 96, 97, 104, 105, 128, 129, 106, 107, 68, 69, 50, 51, 4, 5, 160, 161, 138, 139, 14, 15, 122, 123, 158, 159, 140, 141], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "0.37674931507844195 90\n",
      "0.4264068635304769 95\n",
      "dict_keys(['mm_strech', 'ms_norm', 'ms_sigmoid', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "0.0 ADD NOISEessing: 0\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISEessing: 40\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.0 ADD NOISEessing: 80\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "train: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.0 ADD NOISEessing: 120\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "0.0 ADD NOISEessing: 160\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.0 ADD NOISE\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "0.0 ADD NOISE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=2, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 571.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 16, 17, 20, 21, 24, 25, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 52, 53, 56, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 92, 93, 94, 95, 108, 109, 116, 117, 118, 119, 120, 121, 126, 127, 142, 143, 148, 149, 150, 151, 154, 155, 156, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177] SELF INDICES\n",
      "['0', '1', '2', '3', '6', '7', '10', '11', '12', '13', '16', '17', '20', '21', '24', '25', '30', '31', '36', '37', '38', '39', '40', '41', '42', '43', '46', '47', '48', '49', '52', '53', '56', '57', '62', '63', '64', '65', '66', '67', '70', '71', '72', '73', '74', '75', '78', '79', '80', '81', '82', '83', '92', '93', '94', '95', '108', '109', '116', '117', '118', '119', '120', '121', '126', '127', '142', '143', '148', '149', '150', '151', '154', '155', '156', '157', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '8', '9', '18', '19', '22', '23', '26', '27', '28', '29', '32', '33', '34', '35', '44', '45', '54', '55', '60', '61', '76', '77', '84', '85', '86', '87', '90', '91', '98', '99', '100', '101', '102', '103', '112', '113', '114', '115', '124', '125', '134', '135', '136', '137', '144', '145', '146', '147', '152', '153', '162', '163', '178', '179', '4', '5', '14', '15', '50', '51', '58', '59', '68', '69', '88', '89', '96', '97', '104', '105', '106', '107', '110', '111', '122', '123', '128', '129', '130', '131', '132', '133', '138', '139', '140', '141', '158', '159', '160', '161'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[136, 137, 102, 103, 34, 35, 124, 125, 144, 145, 134, 135, 152, 153, 162, 163, 146, 147, 8, 9, 90, 91, 76, 77, 44, 45, 84, 85, 60, 61, 114, 115, 100, 101, 112, 113, 54, 55, 178, 179, 28, 29, 86, 87, 22, 23, 32, 33, 26, 27, 18, 19, 98, 99] SELF INDICES\n",
      "['0', '1', '2', '3', '6', '7', '10', '11', '12', '13', '16', '17', '20', '21', '24', '25', '30', '31', '36', '37', '38', '39', '40', '41', '42', '43', '46', '47', '48', '49', '52', '53', '56', '57', '62', '63', '64', '65', '66', '67', '70', '71', '72', '73', '74', '75', '78', '79', '80', '81', '82', '83', '92', '93', '94', '95', '108', '109', '116', '117', '118', '119', '120', '121', '126', '127', '142', '143', '148', '149', '150', '151', '154', '155', '156', '157', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '8', '9', '18', '19', '22', '23', '26', '27', '28', '29', '32', '33', '34', '35', '44', '45', '54', '55', '60', '61', '76', '77', '84', '85', '86', '87', '90', '91', '98', '99', '100', '101', '102', '103', '112', '113', '114', '115', '124', '125', '134', '135', '136', '137', '144', '145', '146', '147', '152', '153', '162', '163', '178', '179', '4', '5', '14', '15', '50', '51', '58', '59', '68', '69', '88', '89', '96', '97', '104', '105', '106', '107', '110', '111', '122', '123', '128', '129', '130', '131', '132', '133', '138', '139', '140', '141', '158', '159', '160', '161'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[130, 131, 132, 133, 110, 111, 88, 89, 58, 59, 96, 97, 104, 105, 128, 129, 106, 107, 68, 69, 50, 51, 4, 5, 160, 161, 138, 139, 14, 15, 122, 123, 158, 159, 140, 141] SELF INDICES\n",
      "['0', '1', '2', '3', '6', '7', '10', '11', '12', '13', '16', '17', '20', '21', '24', '25', '30', '31', '36', '37', '38', '39', '40', '41', '42', '43', '46', '47', '48', '49', '52', '53', '56', '57', '62', '63', '64', '65', '66', '67', '70', '71', '72', '73', '74', '75', '78', '79', '80', '81', '82', '83', '92', '93', '94', '95', '108', '109', '116', '117', '118', '119', '120', '121', '126', '127', '142', '143', '148', '149', '150', '151', '154', '155', '156', '157', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '8', '9', '18', '19', '22', '23', '26', '27', '28', '29', '32', '33', '34', '35', '44', '45', '54', '55', '60', '61', '76', '77', '84', '85', '86', '87', '90', '91', '98', '99', '100', '101', '102', '103', '112', '113', '114', '115', '124', '125', '134', '135', '136', '137', '144', '145', '146', '147', '152', '153', '162', '163', '178', '179', '4', '5', '14', '15', '50', '51', '58', '59', '68', '69', '88', '89', '96', '97', '104', '105', '106', '107', '110', '111', '122', '123', '128', '129', '130', '131', '132', '133', '138', '139', '140', '141', '158', '159', '160', '161'] dta set indices\n",
      "90 36 54\n",
      "-1 ARG FREQ\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 2] dims after\n",
      "[91, 6, 2] dims\n",
      "[<function selu at 0x000001B47D32BF78>, <function selu at 0x000001B47D32BF78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.base_models.LPModel'>\n",
      "<class 'models.encoders.HGCN'> aTTRs\n",
      "91 NUMBER FEATs\n",
      "[91, 6] dims\n",
      "[91, 6, 2] dims after\n",
      "[91, 6, 2] dims\n",
      "[<function selu at 0x000001B47D32BF78>, <function selu at 0x000001B47D32BF78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x000001B416DA91C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.015]\n",
      "<generator object Module.parameters at 0x000001B4134A94C8> MODEL PARAMS\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=91, out_features=6, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (hyp_act): HypAct(\n",
      "    c_in=Parameter containing:\n",
      "    tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "HyperbolicGraphConvolution(\n",
      "  (linear): HypLinear(\n",
      "    in_features=6, out_features=2, c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      "  (agg): HypAgg(\n",
      "    c=Parameter containing:\n",
      "    tensor([1.], requires_grad=True)\n",
      "  )\n",
      ")\n",
      "tensor(-1.) agg man\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "model\n",
      "<generator object Module.parameters at 0x000001B4134A94C8> MODEL PARAMS\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "90 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.552225,roc 0.842988, loss 0.409736, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "tensor([0.0050], grad_fn=<NegBackward0>) MUST BE NEGATIVE WHAT THE HELL>>\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan], grad_fn=<CatBackward0>) pos scores??\n",
      "NANS IN POS SCORES\n",
      "tensor([0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100],\n",
      "       grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n",
      "NANS IN NEG SCORES\n",
      "tensor([0.9900, 0.9900, 0.9900,  ..., 0.9900, 0.9900, 0.9900],\n",
      "       grad_fn=<WhereBackward0>) new scores\n",
      "tensor(False) any left??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py:199: UserWarning: Error detected in ReciprocalBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n",
      "    cell_id=cell_id,\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\coleb\\AppData\\Local\\Temp\\ipykernel_49580\\1052483703.py\", line 46, in <module>\n",
      "    complete_study_one_arg(args,NUM_VALIDATIONS)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\", line 279, in complete_study_one_arg\n",
      "    train_inductive.train(args_copy)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\", line 287, in train\n",
      "    train_metrics=model.compute_metrics_multiple(embeddings_list,data_list,'train')\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 538, in compute_metrics_multiple\n",
      "    neg_scores = self.decode(embeddings, edges_false)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\models\\base_models.py\", line 162, in decode\n",
      "    probs = self.dc.forward(sqdist)\n",
      "  File \"C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\layers\\layers.py\", line 141, in forward\n",
      "    probs = 1. / (torch.exp(  torch.clamp( ((dist - self.r) / self.t),max=max_clamp))+ 1.0)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 39, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\", line 838, in __rdiv__\n",
      "    return self.reciprocal() * other\n",
      "  File \"C:\\Users\\coleb\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\fx\\traceback.py\", line 57, in format_stack\n",
      "    return traceback.format_stack()\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'ReciprocalBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_49580\\1052483703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {}, ID: {}, PLV {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_identity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_plv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#             aka\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mcomplete_study_one_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNUM_VALIDATIONS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#             sksks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperparam.py\u001b[0m in \u001b[0;36mcomplete_study_one_arg\u001b[1;34m(args, n, erase_empty)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'study directory!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0margs_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dir_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[0mtrain_inductive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[0msave_embeddings_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\train_inductive.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;31m# try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hgcn_test\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'ReciprocalBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':0,\n",
    "          'lr':.015,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[2]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':0,\n",
    "          'lr':.01,\n",
    "          'stretch_sigmoid':0,\n",
    "          'plv_norm_w_id':0,\n",
    "          'plv_inp_raw':0,\n",
    "          'unify_pos_neg_loss':0,\n",
    "          'stretch_sigmoid':0,\n",
    "          'use_weighted_bce':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['id']\n",
    "curve_types_to_use=['findc']\n",
    "# raise Exception('OBVIOUSLY WE 'SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LPModel({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=2\n",
    "criteria={'CogTr':1}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'val_sub':1,\n",
    "          'epochs':50,\n",
    "          'stretch_sigmoid':0,\n",
    "          'criteria_dict':criteria}\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['plv']\n",
    "curve_types_to_use=['setc']\n",
    "# raise Exception('OBVIOUSLY WE SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "    \n",
    "#             sksks\n",
    "#             try:\n",
    "#                 complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "#             except:\n",
    "#                 print('FUCKED THAT UP')\n",
    "#             sksks\n",
    "            \n",
    "            \n",
    "\n",
    "# # c=[1,None,.54]\n",
    "# args = parse_default_args(set_args) ### still need to call this with args for dataset, possibly others\n",
    "# complete_study_one_arg(args,NUM_VALIDATIONS)\n",
    "# # print(args)\n",
    "# # change_task(args,)\n",
    "# # \n",
    "# # setattr(args,'criteria_dict',criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713a7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbd527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcf7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
