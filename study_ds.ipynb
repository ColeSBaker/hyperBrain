{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad3f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2022.03.3 jupyter extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported utils\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used for recreating the link prediction results for different parameter settings\n",
    "and dimensionality\n",
    "\"\"\"\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from utils import *\n",
    "from params import *\n",
    "from params import MEGLpParams\n",
    "# from params import BAND_TO_OPT_C\n",
    "import sys\n",
    "from datetime import date\n",
    "import pickle\n",
    "import train_inductive\n",
    "# should we not make a seperate config for out \"official runnings\"\n",
    "from trials.hyperparam_config import config\n",
    "import pickle\n",
    "import optuna\n",
    "import copy\n",
    "from utils.train_utils import get_dir_name, format_metrics\n",
    "from utils.model_analysis_utils import plot_loss_dir,create_res_df_study\n",
    "from main import parse_default_args\n",
    "from hyperparam import create_study_output_dir,create_objective_fun,complete_study_one_arg\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2502fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trials.hyperparam_config import config\n",
    "from main import parse_default_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480a27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_OPT_C= { \n",
    "           'alpha':.54,\n",
    "           'gamma':.66,\n",
    "           'beta': .74,\n",
    "            'theta':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_arch_dict={'model':'HGCN','optimizer':'RiemannianAdam','manifold':'PoincareBall'}\n",
    "euc_arch_dict={'model':'GCN','optimizer':'Adam','manifold':'Euclidean'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b57590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 'set'},\n",
       " 'findc': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': None},\n",
       " '1c': {'model': 'HGCN',\n",
       "  'optimizer': 'RiemannianAdam',\n",
       "  'manifold': 'PoincareBall',\n",
       "  'c': 1},\n",
       " 'euc': {'model': 'GCN', 'optimizer': 'Adam', 'manifold': 'Euclidean', 'c': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_types={'full':{'use_weight':1,'use_virtual':1},\n",
    "            'no_virt':{'use_weight':1,'use_virtual':0},\n",
    "                'no_weight':{'use_weight':0,'use_virtual':1}}\n",
    "\n",
    "input_types={'plv':{'use_plv':1,'use_identity':0},'id':{'use_plv':0,'use_identity':1}}\n",
    "\n",
    "\n",
    "curve_types={'setc':{**hyp_arch_dict,'c':'set'},\n",
    "            'findc':{**hyp_arch_dict,'c':None},\n",
    "            '1c':{**hyp_arch_dict,'c':1},\n",
    "             'euc':{**euc_arch_dict,'c':0},\n",
    "            }\n",
    "curve_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72779412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2382116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: 0.54, ID: 0, PLV 1\n",
      "C: 0.54, ID: 0, PLV 1\n",
      "\n",
      "\n",
      "HGCN_full_0.54c_plv_dp model\n",
      "HGCN_full_0.54c_plv_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study dir\n",
      "True exists for sure\n",
      "['0', '1']\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "finished reading: 20\r",
      "finished reading: 40\r",
      "finished reading: 60\r",
      "finished reading: 80\r",
      "finished reading: 100\r",
      "finished reading: 120\r",
      "finished reading: 140\r",
      "finished reading: 160\r",
      "finished reading: 180\r",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=91, out_features=6, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "        (hyp_act): HypAct(c_in=tensor([0.5400]), c_out=tensor([0.5400]))\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=6, out_features=3, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 575.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025E86B4F4C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.699890,roc 0.905855, loss 0.117826, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.754548,roc 0.928505, loss 0.094275, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.785427,roc 0.939060, loss 0.083692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.809014,roc 0.946615, loss 0.076380, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.811132,roc 0.947169, loss 0.075821, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.6061s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.6071s\n",
      "94\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.886454,roc 0.968286, loss 0.055301, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.883248,roc 0.973268, loss 0.053643, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.894002,roc 0.968854, loss 0.055443, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.898143,roc 0.970899, loss 0.053501, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.900882,roc 0.972394, loss 0.051751, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.903094,roc 0.972999, loss 0.051234, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.903256,roc 0.973070, loss 0.051152, acc 0, ECE 0 #edges 376470, #graphs 94 time: 153.4769s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 153.4769s\n",
      "94\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.909695,roc 0.974522, loss 0.049983, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.917142,roc 0.981753, loss 0.042254, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908742,roc 0.975563, loss 0.049584, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.910825,roc 0.975128, loss 0.049545, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.913516,roc 0.975607, loss 0.049034, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.912789,roc 0.975447, loss 0.048667, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.912889,roc 0.975472, loss 0.048600, acc 0, ECE 0 #edges 376470, #graphs 94 time: 153.8302s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 153.8312s\n",
      "94\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.912360,roc 0.974228, loss 0.050477, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.927856,roc 0.983560, loss 0.041039, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.916478,roc 0.976890, loss 0.047610, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.915519,roc 0.976807, loss 0.048224, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.915475,roc 0.976289, loss 0.048181, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.917554,roc 0.976668, loss 0.047621, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.917384,roc 0.976481, loss 0.047758, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.4781s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.4801s\n",
      "94\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.919194,roc 0.977019, loss 0.047013, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.933753,roc 0.985321, loss 0.040557, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.918453,roc 0.977354, loss 0.045974, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.919787,roc 0.977516, loss 0.046429, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.920075,roc 0.977571, loss 0.046447, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.919695,roc 0.977106, loss 0.047188, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.919735,roc 0.977172, loss 0.047120, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.1733s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.1743s\n",
      "94\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.919944,roc 0.976849, loss 0.047087, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.929579,roc 0.983959, loss 0.040950, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.924591,roc 0.977884, loss 0.045665, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.918008,roc 0.976500, loss 0.047571, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.919046,roc 0.976532, loss 0.047534, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.920042,roc 0.977111, loss 0.047026, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.920202,roc 0.977141, loss 0.046989, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.1729s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.1749s\n",
      "94\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.920473,roc 0.976894, loss 0.047031, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.928248,roc 0.983571, loss 0.041973, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.926087,roc 0.978031, loss 0.045376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.924063,roc 0.977875, loss 0.045891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.922620,roc 0.977865, loss 0.045863, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.923983,roc 0.978384, loss 0.045608, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.923873,roc 0.978373, loss 0.045630, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.1792s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.1887s\n",
      "94\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.921675,roc 0.977217, loss 0.046616, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.930926,roc 0.984117, loss 0.041589, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.920068,roc 0.977544, loss 0.047681, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.919624,roc 0.976906, loss 0.047704, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.922168,roc 0.977575, loss 0.046721, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.923635,roc 0.978108, loss 0.046093, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.923438,roc 0.978110, loss 0.046044, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.5000s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.5000s\n",
      "94\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.924766,roc 0.977949, loss 0.046116, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.936422,roc 0.985460, loss 0.039343, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.923381,roc 0.977988, loss 0.045783, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.923844,roc 0.977927, loss 0.045979, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.924776,roc 0.978401, loss 0.045799, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.925366,roc 0.978524, loss 0.045378, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.925172,roc 0.978536, loss 0.045386, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.1830s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.1830s\n",
      "94\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.923575,roc 0.977656, loss 0.046691, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.935454,roc 0.985331, loss 0.038306, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.927470,roc 0.978751, loss 0.046000, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.925828,roc 0.978639, loss 0.045442, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.926629,roc 0.978779, loss 0.045129, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.925996,roc 0.978882, loss 0.044922, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.926047,roc 0.978886, loss 0.044969, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.8616s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.8636s\n",
      "94\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.925007,roc 0.978370, loss 0.045559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.937513,roc 0.985978, loss 0.038086, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.926836,roc 0.978727, loss 0.045174, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.924990,roc 0.978712, loss 0.045514, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.925455,roc 0.979040, loss 0.045060, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.925179,roc 0.978594, loss 0.045381, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.925373,roc 0.978675, loss 0.045343, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.6069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.6069s\n",
      "94\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.921853,roc 0.977168, loss 0.046559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.931596,roc 0.984285, loss 0.039886, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.927489,roc 0.980205, loss 0.044214, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.926322,roc 0.979426, loss 0.044953, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.927023,roc 0.979416, loss 0.044822, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.927026,roc 0.979111, loss 0.044942, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.926614,roc 0.979026, loss 0.045024, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.1591s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.1591s\n",
      "94\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.925192,roc 0.978129, loss 0.045928, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.937971,roc 0.985901, loss 0.038226, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.925443,roc 0.979437, loss 0.044991, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.923839,roc 0.978177, loss 0.045636, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.925824,roc 0.978959, loss 0.044997, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.927227,roc 0.979156, loss 0.044783, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.927325,roc 0.979207, loss 0.044671, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.1258s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.1268s\n",
      "94\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.923752,roc 0.977912, loss 0.046007, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.937105,roc 0.985925, loss 0.037962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.926453,roc 0.979476, loss 0.044447, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.924849,roc 0.979063, loss 0.044977, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.925078,roc 0.978880, loss 0.045221, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.925495,roc 0.978622, loss 0.045273, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.925899,roc 0.978792, loss 0.045073, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.6880s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.6880s\n",
      "94\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.924780,roc 0.978051, loss 0.045857, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.936083,roc 0.985493, loss 0.038347, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.931247,roc 0.979959, loss 0.043788, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.929874,roc 0.979013, loss 0.044570, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.927344,roc 0.978967, loss 0.044692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.928655,roc 0.979582, loss 0.044206, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.928302,roc 0.979509, loss 0.044281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.6946s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.6946s\n",
      "94\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.925907,roc 0.978364, loss 0.045497, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.935931,roc 0.985331, loss 0.039242, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.932318,roc 0.980364, loss 0.043333, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.929457,roc 0.980276, loss 0.043569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.929547,roc 0.980297, loss 0.043656, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.928898,roc 0.979784, loss 0.043973, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.928861,roc 0.979708, loss 0.044025, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.7272s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.7272s\n",
      "94\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.925628,roc 0.978142, loss 0.046315, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.938819,roc 0.986135, loss 0.037580, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.927789,roc 0.980180, loss 0.043439, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.928608,roc 0.979859, loss 0.043964, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.929083,roc 0.979751, loss 0.044185, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.928308,roc 0.979550, loss 0.044186, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.928386,roc 0.979542, loss 0.044169, acc 0, ECE 0 #edges 376470, #graphs 94 time: 163.0100s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 163.0110s\n",
      "94\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.922175,roc 0.976995, loss 0.046316, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.927051,roc 0.982967, loss 0.041845, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.925896,roc 0.978122, loss 0.045541, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.926613,roc 0.979498, loss 0.044599, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.928072,roc 0.979913, loss 0.043936, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.928050,roc 0.979497, loss 0.044178, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.927875,roc 0.979385, loss 0.044371, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.5425s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.5425s\n",
      "94\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.924821,roc 0.977939, loss 0.045956, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.931192,roc 0.983973, loss 0.040779, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.926647,roc 0.977765, loss 0.046211, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.929779,roc 0.979402, loss 0.044847, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.930845,roc 0.980203, loss 0.043795, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.929203,roc 0.979738, loss 0.044082, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.929457,roc 0.979804, loss 0.044002, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.7867s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.7877s\n",
      "94\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.924995,roc 0.977992, loss 0.045723, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.937402,roc 0.985714, loss 0.038561, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.935712,roc 0.981556, loss 0.041977, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.931404,roc 0.980353, loss 0.043131, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.931376,roc 0.980198, loss 0.043484, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.929875,roc 0.979849, loss 0.043997, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.929774,roc 0.979867, loss 0.044013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.0079s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.0079s\n",
      "94\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.926919,roc 0.978550, loss 0.046085, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.936626,roc 0.985463, loss 0.038288, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.927619,roc 0.979881, loss 0.043880, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.927112,roc 0.979629, loss 0.044205, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.929350,roc 0.979788, loss 0.044134, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.929780,roc 0.979975, loss 0.043748, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.929806,roc 0.979968, loss 0.043701, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.8964s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.8974s\n",
      "94\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.926661,roc 0.978617, loss 0.045100, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.938909,roc 0.986317, loss 0.037703, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.931971,roc 0.979845, loss 0.044513, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.930206,roc 0.979174, loss 0.044595, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.931357,roc 0.980145, loss 0.043748, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.930195,roc 0.980106, loss 0.043584, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.930207,roc 0.980100, loss 0.043645, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.5901s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.5911s\n",
      "94\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.926538,roc 0.978421, loss 0.045529, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.940997,roc 0.986705, loss 0.036933, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.932076,roc 0.980795, loss 0.043752, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.931904,roc 0.980570, loss 0.043528, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.930706,roc 0.980350, loss 0.043337, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.931507,roc 0.980359, loss 0.043333, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.930535,roc 0.980213, loss 0.043503, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.6965s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.6965s\n",
      "94\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.928262,roc 0.979045, loss 0.044699, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.936973,roc 0.985608, loss 0.038156, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.932504,roc 0.981691, loss 0.042062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.928881,roc 0.980198, loss 0.043523, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.929297,roc 0.980358, loss 0.043763, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.930537,roc 0.980141, loss 0.043778, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.930737,roc 0.980197, loss 0.043744, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.1898s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.1908s\n",
      "94\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.927300,roc 0.978773, loss 0.044810, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.934895,roc 0.985112, loss 0.038742, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.931391,roc 0.979825, loss 0.043862, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.931725,roc 0.980221, loss 0.043690, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.930735,roc 0.979829, loss 0.044202, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.929720,roc 0.979843, loss 0.044048, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.929754,roc 0.979847, loss 0.044011, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.2101s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.2131s\n",
      "94\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.927743,roc 0.979066, loss 0.044603, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.939747,roc 0.986478, loss 0.037275, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.934329,roc 0.981575, loss 0.042078, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.930988,roc 0.980254, loss 0.043246, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.931583,roc 0.980298, loss 0.043233, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.930389,roc 0.980052, loss 0.043611, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.930247,roc 0.980124, loss 0.043553, acc 0, ECE 0 #edges 376470, #graphs 94 time: 164.4532s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 164.4542s\n",
      "94\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.923557,roc 0.977307, loss 0.046068, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.929055,roc 0.983351, loss 0.040976, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.927603,roc 0.979307, loss 0.044376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.928710,roc 0.979908, loss 0.044328, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.930332,roc 0.980645, loss 0.043258, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.930592,roc 0.980196, loss 0.043472, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.930551,roc 0.980222, loss 0.043459, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.8818s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.8988s\n",
      "94\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.926872,roc 0.978587, loss 0.045182, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.940054,roc 0.986547, loss 0.036962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.929238,roc 0.978010, loss 0.044892, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.929800,roc 0.979498, loss 0.044036, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.930448,roc 0.980185, loss 0.043367, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.930937,roc 0.980403, loss 0.043373, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.930805,roc 0.980218, loss 0.043531, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.5127s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.5127s\n",
      "94\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.927760,roc 0.978966, loss 0.044921, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.936044,roc 0.985301, loss 0.038568, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.929558,roc 0.978960, loss 0.044258, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.929652,roc 0.979778, loss 0.043849, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.930798,roc 0.980231, loss 0.043328, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.930750,roc 0.980201, loss 0.043533, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.930826,roc 0.980258, loss 0.043499, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.2881s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.2881s\n",
      "94\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.928678,roc 0.979220, loss 0.044770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.940396,roc 0.986648, loss 0.036741, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 29 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 29: precision 0.933008,roc 0.981551, loss 0.041741, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 29: precision 0.933408,roc 0.981564, loss 0.041958, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 29: precision 0.930852,roc 0.980214, loss 0.043615, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 29: precision 0.931251,roc 0.980514, loss 0.043241, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.0189 train phase of epoch 29: precision 0.931119,roc 0.980426, loss 0.043281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.3000s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.3000s\n",
      "94\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.928682,roc 0.979232, loss 0.044330, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0030 test phase of epoch 29: precision 0.937848,roc 0.985911, loss 0.038645, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 30 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 30: precision 0.929850,roc 0.979006, loss 0.044312, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 30: precision 0.930621,roc 0.979883, loss 0.043705, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 30: precision 0.930285,roc 0.979892, loss 0.043745, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 30: precision 0.931124,roc 0.980349, loss 0.043149, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.0189 train phase of epoch 30: precision 0.931080,roc 0.980416, loss 0.043164, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.9884s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.9894s\n",
      "94\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0031 dev phase of epoch 30: precision 0.926824,roc 0.978445, loss 0.045343, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0031 test phase of epoch 30: precision 0.936435,roc 0.985353, loss 0.038667, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 31 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 31: precision 0.930094,roc 0.979053, loss 0.043863, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 31: precision 0.931971,roc 0.980384, loss 0.042809, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 31: precision 0.931218,roc 0.980481, loss 0.043057, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 31: precision 0.931038,roc 0.980489, loss 0.043204, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.0189 train phase of epoch 31: precision 0.930708,roc 0.980300, loss 0.043388, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.1124s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.1134s\n",
      "94\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.928031,roc 0.979022, loss 0.044448, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0032 test phase of epoch 31: precision 0.934858,roc 0.985214, loss 0.039423, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 32 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 32: precision 0.927956,roc 0.979417, loss 0.044533, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 32: precision 0.930984,roc 0.980836, loss 0.042804, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 32: precision 0.932786,roc 0.981326, loss 0.042322, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 32: precision 0.931355,roc 0.980446, loss 0.043301, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.0189 train phase of epoch 32: precision 0.931369,roc 0.980423, loss 0.043329, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.0948s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.0958s\n",
      "94\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0033 dev phase of epoch 32: precision 0.928526,roc 0.979127, loss 0.044701, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0033 test phase of epoch 32: precision 0.938379,roc 0.986185, loss 0.037147, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 33 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 33: precision 0.932710,roc 0.981158, loss 0.042866, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 33: precision 0.928811,roc 0.979832, loss 0.043891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 33: precision 0.929840,roc 0.979837, loss 0.043764, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 33: precision 0.931072,roc 0.980406, loss 0.043294, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.0189 train phase of epoch 33: precision 0.931176,roc 0.980445, loss 0.043248, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.6495s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.6505s\n",
      "94\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.929115,roc 0.979241, loss 0.044597, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0034 test phase of epoch 33: precision 0.937238,roc 0.985638, loss 0.038450, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 34 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 34: precision 0.929986,roc 0.980918, loss 0.042467, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 34: precision 0.930798,roc 0.980789, loss 0.042663, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 34: precision 0.931115,roc 0.980599, loss 0.042990, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 34: precision 0.930982,roc 0.980438, loss 0.043085, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.0189 train phase of epoch 34: precision 0.931208,roc 0.980482, loss 0.043056, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.8866s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.8876s\n",
      "94\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0035 dev phase of epoch 34: precision 0.927793,roc 0.978821, loss 0.045882, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0035 test phase of epoch 34: precision 0.939814,roc 0.986541, loss 0.036967, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 35 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 35: precision 0.934938,roc 0.979552, loss 0.044037, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 35: precision 0.931269,roc 0.979804, loss 0.044103, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 35: precision 0.931533,roc 0.980041, loss 0.043689, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 35: precision 0.932327,roc 0.980612, loss 0.043196, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.0189 train phase of epoch 35: precision 0.932107,roc 0.980626, loss 0.043140, acc 0, ECE 0 #edges 376470, #graphs 94 time: 130.7795s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 130.7805s\n",
      "94\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.929131,roc 0.979329, loss 0.044209, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0036 test phase of epoch 35: precision 0.937430,roc 0.985825, loss 0.037810, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 36 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 36: precision 0.925068,roc 0.977919, loss 0.045326, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 36: precision 0.929862,roc 0.979815, loss 0.043548, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 36: precision 0.930894,roc 0.980235, loss 0.043397, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 36: precision 0.931875,roc 0.980661, loss 0.042921, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.0189 train phase of epoch 36: precision 0.931996,roc 0.980717, loss 0.042882, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.6068s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.6068s\n",
      "94\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0037 dev phase of epoch 36: precision 0.928805,roc 0.979146, loss 0.044384, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0037 test phase of epoch 36: precision 0.937587,roc 0.985679, loss 0.038905, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 37 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 37: precision 0.932582,roc 0.980131, loss 0.043571, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 37: precision 0.932434,roc 0.980911, loss 0.042826, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 37: precision 0.933562,roc 0.981448, loss 0.042344, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 37: precision 0.932192,roc 0.980847, loss 0.043041, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.0189 train phase of epoch 37: precision 0.932104,roc 0.980699, loss 0.043111, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.9090s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.9090s\n",
      "94\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.929355,roc 0.979396, loss 0.044329, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0038 test phase of epoch 37: precision 0.937160,roc 0.985742, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 38 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 38: precision 0.928286,roc 0.979104, loss 0.044486, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 38: precision 0.931858,roc 0.980225, loss 0.043071, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 38: precision 0.931584,roc 0.980692, loss 0.043041, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 38: precision 0.932062,roc 0.980747, loss 0.042903, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.0189 train phase of epoch 38: precision 0.932177,roc 0.980772, loss 0.042844, acc 0, ECE 0 #edges 376470, #graphs 94 time: 163.1690s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 163.1700s\n",
      "94\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0039 dev phase of epoch 38: precision 0.927643,roc 0.978850, loss 0.044418, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0039 test phase of epoch 38: precision 0.934802,roc 0.985053, loss 0.039059, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 39 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 39: precision 0.931084,roc 0.980119, loss 0.043902, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 39: precision 0.931361,roc 0.980604, loss 0.043358, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 39: precision 0.932250,roc 0.980758, loss 0.042917, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 39: precision 0.931936,roc 0.980683, loss 0.042773, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.0189 train phase of epoch 39: precision 0.931975,roc 0.980667, loss 0.042876, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.6058s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.6058s\n",
      "94\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0040 test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 40 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 40: precision 0.929479,roc 0.980580, loss 0.042462, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 40: precision 0.932577,roc 0.980794, loss 0.042194, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 40: precision 0.931939,roc 0.980557, loss 0.042820, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 40: precision 0.932438,roc 0.980728, loss 0.042830, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.01701 train phase of epoch 40: precision 0.932516,roc 0.980770, loss 0.042827, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.4016s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.4026s\n",
      "94\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0041 dev phase of epoch 40: precision 0.928570,roc 0.979103, loss 0.044598, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0041 test phase of epoch 40: precision 0.939152,roc 0.986423, loss 0.036789, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 41 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 41: precision 0.927991,roc 0.979182, loss 0.044374, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 41: precision 0.928962,roc 0.979379, loss 0.044199, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 41: precision 0.930728,roc 0.980114, loss 0.043497, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 41: precision 0.931949,roc 0.980724, loss 0.042816, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.01701 train phase of epoch 41: precision 0.932129,roc 0.980767, loss 0.042768, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.2652s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.2652s\n",
      "94\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.929659,roc 0.979359, loss 0.044288, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0042 test phase of epoch 41: precision 0.939415,roc 0.986230, loss 0.037867, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 42 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 42: precision 0.932628,roc 0.981207, loss 0.042146, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 42: precision 0.932303,roc 0.980534, loss 0.042738, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 42: precision 0.933175,roc 0.980999, loss 0.042628, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 42: precision 0.932655,roc 0.980869, loss 0.042690, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.01701 train phase of epoch 42: precision 0.932658,roc 0.980849, loss 0.042681, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.9978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.9978s\n",
      "94\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0043 dev phase of epoch 42: precision 0.928985,roc 0.979346, loss 0.044204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0043 test phase of epoch 42: precision 0.939583,roc 0.986250, loss 0.037558, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 43 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 43: precision 0.932111,roc 0.980260, loss 0.042819, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 43: precision 0.932832,roc 0.981231, loss 0.041875, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 43: precision 0.932053,roc 0.980817, loss 0.042517, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 43: precision 0.932781,roc 0.981109, loss 0.042457, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.01701 train phase of epoch 43: precision 0.932703,roc 0.980927, loss 0.042626, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.2777s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.2792s\n",
      "94\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.926043,roc 0.978269, loss 0.045890, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0044 test phase of epoch 43: precision 0.930479,roc 0.983766, loss 0.042449, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 44 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 44: precision 0.931838,roc 0.980369, loss 0.043393, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 44: precision 0.930369,roc 0.980379, loss 0.043561, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 44: precision 0.931475,roc 0.980112, loss 0.043455, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 44: precision 0.931923,roc 0.980644, loss 0.042970, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.01701 train phase of epoch 44: precision 0.931952,roc 0.980662, loss 0.042965, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.9127s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.9137s\n",
      "94\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0045 dev phase of epoch 44: precision 0.928477,roc 0.978928, loss 0.044481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0045 test phase of epoch 44: precision 0.938154,roc 0.985886, loss 0.037750, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 45 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 45: precision 0.932127,roc 0.981028, loss 0.042162, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 45: precision 0.933080,roc 0.980914, loss 0.042729, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 45: precision 0.932128,roc 0.980292, loss 0.042875, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 45: precision 0.932063,roc 0.980711, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.01701 train phase of epoch 45: precision 0.932230,roc 0.980743, loss 0.042734, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.8153s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.8162s\n",
      "94\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.929982,roc 0.979576, loss 0.044306, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0046 test phase of epoch 45: precision 0.940102,roc 0.986497, loss 0.037062, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 9707.0963s\n",
      "INFO:root:Val set results: dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n",
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 39, 'loss': 0.044183875706289295, 'roc': 0.979261082488716, 'ap': 0.9294045831413663, 'acc': 0.9144180239816505, 'ECE': 0.0}\n",
      "0.044183875706289295 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\3', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=91, out_features=6, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "        (hyp_act): HypAct(c_in=tensor([0.5400]), c_out=tensor([0.5400]))\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=6, out_features=3, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 575.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025E86B4F5C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.699890,roc 0.905855, loss 0.117826, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.754548,roc 0.928505, loss 0.094275, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.785427,roc 0.939060, loss 0.083692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.809014,roc 0.946615, loss 0.076380, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.811132,roc 0.947169, loss 0.075821, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.8982s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.8992s\n",
      "94\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.886454,roc 0.968286, loss 0.055301, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.883248,roc 0.973268, loss 0.053643, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.894002,roc 0.968854, loss 0.055443, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.898143,roc 0.970899, loss 0.053501, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.900882,roc 0.972394, loss 0.051751, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.903094,roc 0.972999, loss 0.051234, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.903256,roc 0.973070, loss 0.051152, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.2036s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.2046s\n",
      "94\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.909695,roc 0.974522, loss 0.049983, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.917142,roc 0.981753, loss 0.042254, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908742,roc 0.975563, loss 0.049584, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.910825,roc 0.975128, loss 0.049545, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.913516,roc 0.975607, loss 0.049034, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.912789,roc 0.975447, loss 0.048667, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.912889,roc 0.975472, loss 0.048600, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.9977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.9977s\n",
      "94\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.912360,roc 0.974228, loss 0.050477, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.927856,roc 0.983560, loss 0.041039, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.916478,roc 0.976890, loss 0.047610, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.915519,roc 0.976807, loss 0.048224, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.915475,roc 0.976289, loss 0.048181, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.917554,roc 0.976668, loss 0.047621, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.917384,roc 0.976481, loss 0.047758, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.8388s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.8403s\n",
      "94\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.919194,roc 0.977019, loss 0.047013, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.933753,roc 0.985321, loss 0.040557, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.918453,roc 0.977354, loss 0.045974, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.919787,roc 0.977516, loss 0.046429, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.920075,roc 0.977571, loss 0.046447, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.919695,roc 0.977106, loss 0.047188, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.919735,roc 0.977172, loss 0.047120, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.5253s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.5253s\n",
      "94\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.919944,roc 0.976849, loss 0.047087, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.929579,roc 0.983959, loss 0.040950, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.924591,roc 0.977884, loss 0.045665, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.918008,roc 0.976500, loss 0.047571, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.919046,roc 0.976532, loss 0.047534, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.920042,roc 0.977111, loss 0.047026, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.920202,roc 0.977141, loss 0.046989, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.5995s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.5995s\n",
      "94\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.920473,roc 0.976894, loss 0.047031, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.928248,roc 0.983571, loss 0.041973, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.926087,roc 0.978031, loss 0.045376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.924063,roc 0.977875, loss 0.045891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.922620,roc 0.977865, loss 0.045863, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.923983,roc 0.978384, loss 0.045608, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.923873,roc 0.978373, loss 0.045630, acc 0, ECE 0 #edges 376470, #graphs 94 time: 154.8029s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 154.8039s\n",
      "94\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.921675,roc 0.977217, loss 0.046616, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.930926,roc 0.984117, loss 0.041589, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.920068,roc 0.977544, loss 0.047681, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.919624,roc 0.976906, loss 0.047704, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.922168,roc 0.977575, loss 0.046721, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.923635,roc 0.978108, loss 0.046093, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.923438,roc 0.978110, loss 0.046044, acc 0, ECE 0 #edges 376470, #graphs 94 time: 155.3914s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 155.3924s\n",
      "94\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.924766,roc 0.977949, loss 0.046116, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.936422,roc 0.985460, loss 0.039343, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.923381,roc 0.977988, loss 0.045783, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.923844,roc 0.977927, loss 0.045979, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.924776,roc 0.978401, loss 0.045799, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.925366,roc 0.978524, loss 0.045378, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.925172,roc 0.978536, loss 0.045386, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.4559s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.4719s\n",
      "94\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.923575,roc 0.977656, loss 0.046691, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.935454,roc 0.985331, loss 0.038306, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.927470,roc 0.978751, loss 0.046000, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.925828,roc 0.978639, loss 0.045442, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.926629,roc 0.978779, loss 0.045129, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.925996,roc 0.978882, loss 0.044922, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.926047,roc 0.978886, loss 0.044969, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.5172s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.5172s\n",
      "94\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.925007,roc 0.978370, loss 0.045559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.937513,roc 0.985978, loss 0.038086, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.926836,roc 0.978727, loss 0.045174, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.924990,roc 0.978712, loss 0.045514, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.925455,roc 0.979040, loss 0.045060, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.925179,roc 0.978594, loss 0.045381, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.925373,roc 0.978675, loss 0.045343, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.9717s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.9717s\n",
      "94\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.921853,roc 0.977168, loss 0.046559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.931596,roc 0.984285, loss 0.039886, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.927489,roc 0.980205, loss 0.044214, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.926322,roc 0.979426, loss 0.044953, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.927023,roc 0.979416, loss 0.044822, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.927026,roc 0.979111, loss 0.044942, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.926614,roc 0.979026, loss 0.045024, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.6908s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.6918s\n",
      "94\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.925192,roc 0.978129, loss 0.045928, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.937971,roc 0.985901, loss 0.038226, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.925443,roc 0.979437, loss 0.044991, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.923839,roc 0.978177, loss 0.045636, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.925824,roc 0.978959, loss 0.044997, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.927227,roc 0.979156, loss 0.044783, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.927325,roc 0.979207, loss 0.044671, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.1957s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.1967s\n",
      "94\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.923752,roc 0.977912, loss 0.046007, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.937105,roc 0.985925, loss 0.037962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.926453,roc 0.979476, loss 0.044447, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.924849,roc 0.979063, loss 0.044977, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.925078,roc 0.978880, loss 0.045221, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.925495,roc 0.978622, loss 0.045273, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.925899,roc 0.978792, loss 0.045073, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.5397s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.5397s\n",
      "94\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.924780,roc 0.978051, loss 0.045857, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.936083,roc 0.985493, loss 0.038347, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.931247,roc 0.979959, loss 0.043788, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.929874,roc 0.979013, loss 0.044570, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.927344,roc 0.978967, loss 0.044692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.928655,roc 0.979582, loss 0.044206, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.928302,roc 0.979509, loss 0.044281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.3925s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.3925s\n",
      "94\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.925907,roc 0.978364, loss 0.045497, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.935931,roc 0.985331, loss 0.039242, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.932318,roc 0.980364, loss 0.043333, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.929457,roc 0.980276, loss 0.043569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.929547,roc 0.980297, loss 0.043656, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.928898,roc 0.979784, loss 0.043973, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.928861,roc 0.979708, loss 0.044025, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.7705s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.7715s\n",
      "94\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.925628,roc 0.978142, loss 0.046315, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.938819,roc 0.986135, loss 0.037580, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.927789,roc 0.980180, loss 0.043439, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.928608,roc 0.979859, loss 0.043964, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.929083,roc 0.979751, loss 0.044185, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.928308,roc 0.979550, loss 0.044186, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.928386,roc 0.979542, loss 0.044169, acc 0, ECE 0 #edges 376470, #graphs 94 time: 162.3349s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 162.3359s\n",
      "94\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.922175,roc 0.976995, loss 0.046316, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.927051,roc 0.982967, loss 0.041845, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.925896,roc 0.978122, loss 0.045541, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.926613,roc 0.979498, loss 0.044599, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.928072,roc 0.979913, loss 0.043936, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.928050,roc 0.979497, loss 0.044178, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.927875,roc 0.979385, loss 0.044371, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.5149s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.5159s\n",
      "94\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.924821,roc 0.977939, loss 0.045956, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.931192,roc 0.983973, loss 0.040779, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.926647,roc 0.977765, loss 0.046211, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.929779,roc 0.979402, loss 0.044847, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.930845,roc 0.980203, loss 0.043795, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.929203,roc 0.979738, loss 0.044082, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.929457,roc 0.979804, loss 0.044002, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.1637s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.1647s\n",
      "94\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.924995,roc 0.977992, loss 0.045723, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.937402,roc 0.985714, loss 0.038561, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.935712,roc 0.981556, loss 0.041977, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.931404,roc 0.980353, loss 0.043131, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.931376,roc 0.980198, loss 0.043484, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.929875,roc 0.979849, loss 0.043997, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.929774,roc 0.979867, loss 0.044013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.0281s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.0281s\n",
      "94\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.926919,roc 0.978550, loss 0.046085, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.936626,roc 0.985463, loss 0.038288, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.927619,roc 0.979881, loss 0.043880, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.927112,roc 0.979629, loss 0.044205, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.929350,roc 0.979788, loss 0.044134, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.929780,roc 0.979975, loss 0.043748, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.929806,roc 0.979968, loss 0.043701, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.1148s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.1148s\n",
      "94\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.926661,roc 0.978617, loss 0.045100, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.938909,roc 0.986317, loss 0.037703, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.931971,roc 0.979845, loss 0.044513, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.930206,roc 0.979174, loss 0.044595, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.931357,roc 0.980145, loss 0.043748, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.930195,roc 0.980106, loss 0.043584, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.930207,roc 0.980100, loss 0.043645, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.0695s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.0695s\n",
      "94\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.926538,roc 0.978421, loss 0.045529, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.940997,roc 0.986705, loss 0.036933, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.932076,roc 0.980795, loss 0.043752, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.931904,roc 0.980570, loss 0.043528, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.930706,roc 0.980350, loss 0.043337, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.931507,roc 0.980359, loss 0.043333, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.930535,roc 0.980213, loss 0.043503, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.0069s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.0069s\n",
      "94\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.928262,roc 0.979045, loss 0.044699, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.936973,roc 0.985608, loss 0.038156, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.932504,roc 0.981691, loss 0.042062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.928881,roc 0.980198, loss 0.043523, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.929297,roc 0.980358, loss 0.043763, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.930537,roc 0.980141, loss 0.043778, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.930737,roc 0.980197, loss 0.043744, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.0662s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.0672s\n",
      "94\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.927300,roc 0.978773, loss 0.044810, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.934895,roc 0.985112, loss 0.038742, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.931391,roc 0.979825, loss 0.043862, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.931725,roc 0.980221, loss 0.043690, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.930735,roc 0.979829, loss 0.044202, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.929720,roc 0.979843, loss 0.044048, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.929754,roc 0.979847, loss 0.044011, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.8451s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.8451s\n",
      "94\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.927743,roc 0.979066, loss 0.044603, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.939747,roc 0.986478, loss 0.037275, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.934329,roc 0.981575, loss 0.042078, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.930988,roc 0.980254, loss 0.043246, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.931583,roc 0.980298, loss 0.043233, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.930389,roc 0.980052, loss 0.043611, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.930247,roc 0.980124, loss 0.043553, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.9438s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.9438s\n",
      "94\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.923557,roc 0.977307, loss 0.046068, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.929055,roc 0.983351, loss 0.040976, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.927603,roc 0.979307, loss 0.044376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.928710,roc 0.979908, loss 0.044328, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.930332,roc 0.980645, loss 0.043258, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.930592,roc 0.980196, loss 0.043472, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.930551,roc 0.980222, loss 0.043459, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.7007s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.7017s\n",
      "94\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.926872,roc 0.978587, loss 0.045182, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.940054,roc 0.986547, loss 0.036962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.929238,roc 0.978010, loss 0.044892, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.929800,roc 0.979498, loss 0.044036, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.930448,roc 0.980185, loss 0.043367, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.930937,roc 0.980403, loss 0.043373, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.930805,roc 0.980218, loss 0.043531, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.3386s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.3386s\n",
      "94\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.927760,roc 0.978966, loss 0.044921, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.936044,roc 0.985301, loss 0.038568, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.929558,roc 0.978960, loss 0.044258, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.929652,roc 0.979778, loss 0.043849, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.930798,roc 0.980231, loss 0.043328, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.930750,roc 0.980201, loss 0.043533, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.930826,roc 0.980258, loss 0.043499, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.1062s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.1072s\n",
      "94\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.928678,roc 0.979220, loss 0.044770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.940396,roc 0.986648, loss 0.036741, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 29 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 29: precision 0.933008,roc 0.981551, loss 0.041741, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 29: precision 0.933408,roc 0.981564, loss 0.041958, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 29: precision 0.930852,roc 0.980214, loss 0.043615, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 29: precision 0.931251,roc 0.980514, loss 0.043241, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.0189 train phase of epoch 29: precision 0.931119,roc 0.980426, loss 0.043281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.9263s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.9273s\n",
      "94\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.928682,roc 0.979232, loss 0.044330, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0030 test phase of epoch 29: precision 0.937848,roc 0.985911, loss 0.038645, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 30 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 30: precision 0.929850,roc 0.979006, loss 0.044312, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 30: precision 0.930621,roc 0.979883, loss 0.043705, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 30: precision 0.930285,roc 0.979892, loss 0.043745, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 30: precision 0.931124,roc 0.980349, loss 0.043149, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.0189 train phase of epoch 30: precision 0.931080,roc 0.980416, loss 0.043164, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.2772s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.2782s\n",
      "94\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0031 dev phase of epoch 30: precision 0.926824,roc 0.978445, loss 0.045343, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0031 test phase of epoch 30: precision 0.936435,roc 0.985353, loss 0.038667, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 31 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 31: precision 0.930094,roc 0.979053, loss 0.043863, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 31: precision 0.931971,roc 0.980384, loss 0.042809, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 31: precision 0.931218,roc 0.980481, loss 0.043057, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 31: precision 0.931038,roc 0.980489, loss 0.043204, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.0189 train phase of epoch 31: precision 0.930708,roc 0.980300, loss 0.043388, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.7752s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.7752s\n",
      "94\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.928031,roc 0.979022, loss 0.044448, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0032 test phase of epoch 31: precision 0.934858,roc 0.985214, loss 0.039423, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 32 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 32: precision 0.927956,roc 0.979417, loss 0.044533, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 32: precision 0.930984,roc 0.980836, loss 0.042804, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 32: precision 0.932786,roc 0.981326, loss 0.042322, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 32: precision 0.931355,roc 0.980446, loss 0.043301, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.0189 train phase of epoch 32: precision 0.931369,roc 0.980423, loss 0.043329, acc 0, ECE 0 #edges 376470, #graphs 94 time: 152.9479s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 152.9489s\n",
      "94\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0033 dev phase of epoch 32: precision 0.928526,roc 0.979127, loss 0.044701, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0033 test phase of epoch 32: precision 0.938379,roc 0.986185, loss 0.037147, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 33 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 33: precision 0.932710,roc 0.981158, loss 0.042866, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 33: precision 0.928811,roc 0.979832, loss 0.043891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 33: precision 0.929840,roc 0.979837, loss 0.043764, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 33: precision 0.931072,roc 0.980406, loss 0.043294, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.0189 train phase of epoch 33: precision 0.931176,roc 0.980445, loss 0.043248, acc 0, ECE 0 #edges 376470, #graphs 94 time: 150.2505s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 150.2515s\n",
      "94\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.929115,roc 0.979241, loss 0.044597, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0034 test phase of epoch 33: precision 0.937238,roc 0.985638, loss 0.038450, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 34 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 34: precision 0.929986,roc 0.980918, loss 0.042467, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 34: precision 0.930798,roc 0.980789, loss 0.042663, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 34: precision 0.931115,roc 0.980599, loss 0.042990, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 34: precision 0.930982,roc 0.980438, loss 0.043085, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.0189 train phase of epoch 34: precision 0.931208,roc 0.980482, loss 0.043056, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.3109s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.3119s\n",
      "94\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0035 dev phase of epoch 34: precision 0.927793,roc 0.978821, loss 0.045882, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0035 test phase of epoch 34: precision 0.939814,roc 0.986541, loss 0.036967, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 35 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 35: precision 0.934938,roc 0.979552, loss 0.044037, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 35: precision 0.931269,roc 0.979804, loss 0.044103, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 35: precision 0.931533,roc 0.980041, loss 0.043689, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 35: precision 0.932327,roc 0.980612, loss 0.043196, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.0189 train phase of epoch 35: precision 0.932107,roc 0.980626, loss 0.043140, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.5980s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.5990s\n",
      "94\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.929131,roc 0.979329, loss 0.044209, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0036 test phase of epoch 35: precision 0.937430,roc 0.985825, loss 0.037810, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 36 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 36: precision 0.925068,roc 0.977919, loss 0.045326, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 36: precision 0.929862,roc 0.979815, loss 0.043548, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 36: precision 0.930894,roc 0.980235, loss 0.043397, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 36: precision 0.931875,roc 0.980661, loss 0.042921, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.0189 train phase of epoch 36: precision 0.931996,roc 0.980717, loss 0.042882, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.6544s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.6554s\n",
      "94\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0037 dev phase of epoch 36: precision 0.928805,roc 0.979146, loss 0.044384, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0037 test phase of epoch 36: precision 0.937587,roc 0.985679, loss 0.038905, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 37 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 37: precision 0.932582,roc 0.980131, loss 0.043571, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 37: precision 0.932434,roc 0.980911, loss 0.042826, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 37: precision 0.933562,roc 0.981448, loss 0.042344, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 37: precision 0.932192,roc 0.980847, loss 0.043041, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.0189 train phase of epoch 37: precision 0.932104,roc 0.980699, loss 0.043111, acc 0, ECE 0 #edges 376470, #graphs 94 time: 162.8164s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 162.8164s\n",
      "94\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.929355,roc 0.979396, loss 0.044329, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0038 test phase of epoch 37: precision 0.937160,roc 0.985742, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 38 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 38: precision 0.928286,roc 0.979104, loss 0.044486, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 38: precision 0.931858,roc 0.980225, loss 0.043071, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 38: precision 0.931584,roc 0.980692, loss 0.043041, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 38: precision 0.932062,roc 0.980747, loss 0.042903, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.0189 train phase of epoch 38: precision 0.932177,roc 0.980772, loss 0.042844, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.9005s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.9015s\n",
      "94\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0039 dev phase of epoch 38: precision 0.927643,roc 0.978850, loss 0.044418, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0039 test phase of epoch 38: precision 0.934802,roc 0.985053, loss 0.039059, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 39 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 39: precision 0.931084,roc 0.980119, loss 0.043902, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 39: precision 0.931361,roc 0.980604, loss 0.043358, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 39: precision 0.932250,roc 0.980758, loss 0.042917, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 39: precision 0.931936,roc 0.980683, loss 0.042773, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.0189 train phase of epoch 39: precision 0.931975,roc 0.980667, loss 0.042876, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.6013s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.6023s\n",
      "94\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0040 test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 40 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 40: precision 0.929479,roc 0.980580, loss 0.042462, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 40: precision 0.932577,roc 0.980794, loss 0.042194, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 40: precision 0.931939,roc 0.980557, loss 0.042820, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 40: precision 0.932438,roc 0.980728, loss 0.042830, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.01701 train phase of epoch 40: precision 0.932516,roc 0.980770, loss 0.042827, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.3327s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.3327s\n",
      "94\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0041 dev phase of epoch 40: precision 0.928570,roc 0.979103, loss 0.044598, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0041 test phase of epoch 40: precision 0.939152,roc 0.986423, loss 0.036789, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 41 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 41: precision 0.927991,roc 0.979182, loss 0.044374, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 41: precision 0.928962,roc 0.979379, loss 0.044199, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 41: precision 0.930728,roc 0.980114, loss 0.043497, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 41: precision 0.931949,roc 0.980724, loss 0.042816, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.01701 train phase of epoch 41: precision 0.932129,roc 0.980767, loss 0.042768, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.2883s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.2883s\n",
      "94\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.929659,roc 0.979359, loss 0.044288, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0042 test phase of epoch 41: precision 0.939415,roc 0.986230, loss 0.037867, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 42 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 42: precision 0.932628,roc 0.981207, loss 0.042146, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 42: precision 0.932303,roc 0.980534, loss 0.042738, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 42: precision 0.933175,roc 0.980999, loss 0.042628, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 42: precision 0.932655,roc 0.980869, loss 0.042690, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.01701 train phase of epoch 42: precision 0.932658,roc 0.980849, loss 0.042681, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.8018s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.8018s\n",
      "94\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0043 dev phase of epoch 42: precision 0.928985,roc 0.979346, loss 0.044204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0043 test phase of epoch 42: precision 0.939583,roc 0.986250, loss 0.037558, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 43 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 43: precision 0.932111,roc 0.980260, loss 0.042819, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 43: precision 0.932832,roc 0.981231, loss 0.041875, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 43: precision 0.932053,roc 0.980817, loss 0.042517, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 43: precision 0.932781,roc 0.981109, loss 0.042457, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.01701 train phase of epoch 43: precision 0.932703,roc 0.980927, loss 0.042626, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.2585s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.2596s\n",
      "94\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.926043,roc 0.978269, loss 0.045890, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0044 test phase of epoch 43: precision 0.930479,roc 0.983766, loss 0.042449, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 44 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 44: precision 0.931838,roc 0.980369, loss 0.043393, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 44: precision 0.930369,roc 0.980379, loss 0.043561, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 44: precision 0.931475,roc 0.980112, loss 0.043455, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 44: precision 0.931923,roc 0.980644, loss 0.042970, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.01701 train phase of epoch 44: precision 0.931952,roc 0.980662, loss 0.042965, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.2660s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.2680s\n",
      "94\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0045 dev phase of epoch 44: precision 0.928477,roc 0.978928, loss 0.044481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0045 test phase of epoch 44: precision 0.938154,roc 0.985886, loss 0.037750, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 45 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 45: precision 0.932127,roc 0.981028, loss 0.042162, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 45: precision 0.933080,roc 0.980914, loss 0.042729, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 45: precision 0.932128,roc 0.980292, loss 0.042875, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 45: precision 0.932063,roc 0.980711, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.01701 train phase of epoch 45: precision 0.932230,roc 0.980743, loss 0.042734, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.9061s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.9071s\n",
      "94\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.929982,roc 0.979576, loss 0.044306, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0046 test phase of epoch 45: precision 0.940102,roc 0.986497, loss 0.037062, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 9805.7338s\n",
      "INFO:root:Val set results: dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n",
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 39, 'loss': 0.044183875706289295, 'roc': 0.979261082488716, 'ap': 0.9294045831413663, 'acc': 0.9144180239816505, 'ECE': 0.0}\n",
      "0.044183875706289295 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\4', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=91, out_features=6, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "        (hyp_act): HypAct(c_in=tensor([0.5400]), c_out=tensor([0.5400]))\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(in_features=6, out_features=3, c=tensor([0.5400]))\n",
      "        (agg): HypAgg(c=tensor([0.5400]))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 575.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025E86B4F5C8>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.699890,roc 0.905855, loss 0.117826, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.754548,roc 0.928505, loss 0.094275, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.785427,roc 0.939060, loss 0.083692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.809014,roc 0.946615, loss 0.076380, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.811132,roc 0.947169, loss 0.075821, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.6794s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.6804s\n",
      "94\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n",
      "86\n",
      "0.05530148930955539 0.8960862874894754 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.886454,roc 0.968286, loss 0.055301, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.883248,roc 0.973268, loss 0.053643, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.894002,roc 0.968854, loss 0.055443, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.898143,roc 0.970899, loss 0.053501, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.900882,roc 0.972394, loss 0.051751, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.903094,roc 0.972999, loss 0.051234, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.903256,roc 0.973070, loss 0.051152, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.8121s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.8131s\n",
      "94\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n",
      "86\n",
      "0.0499830681066651 0.897073425659786 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.909695,roc 0.974522, loss 0.049983, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.917142,roc 0.981753, loss 0.042254, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908742,roc 0.975563, loss 0.049584, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.910825,roc 0.975128, loss 0.049545, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.913516,roc 0.975607, loss 0.049034, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.912789,roc 0.975447, loss 0.048667, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.912889,roc 0.975472, loss 0.048600, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.2150s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.2150s\n",
      "94\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n",
      "86\n",
      "0.050476853810084536 0.8975350579217836 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.912360,roc 0.974228, loss 0.050477, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.927856,roc 0.983560, loss 0.041039, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.916478,roc 0.976890, loss 0.047610, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.915519,roc 0.976807, loss 0.048224, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.915475,roc 0.976289, loss 0.048181, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.917554,roc 0.976668, loss 0.047621, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.917384,roc 0.976481, loss 0.047758, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.7061s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.7061s\n",
      "94\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n",
      "86\n",
      "0.04701332393270029 0.9121621229277357 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.919194,roc 0.977019, loss 0.047013, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.933753,roc 0.985321, loss 0.040557, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.918453,roc 0.977354, loss 0.045974, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.919787,roc 0.977516, loss 0.046429, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.920075,roc 0.977571, loss 0.046447, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.919695,roc 0.977106, loss 0.047188, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.919735,roc 0.977172, loss 0.047120, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.4526s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.4526s\n",
      "94\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n",
      "86\n",
      "0.047086707444042364 0.9063118775948666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.919944,roc 0.976849, loss 0.047087, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.929579,roc 0.983959, loss 0.040950, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.924591,roc 0.977884, loss 0.045665, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.918008,roc 0.976500, loss 0.047571, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.919046,roc 0.976532, loss 0.047534, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.920042,roc 0.977111, loss 0.047026, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.920202,roc 0.977141, loss 0.046989, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.7331s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.7341s\n",
      "94\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n",
      "86\n",
      "0.04703087184587519 0.9107249658856658 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.920473,roc 0.976894, loss 0.047031, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.928248,roc 0.983571, loss 0.041973, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.926087,roc 0.978031, loss 0.045376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.924063,roc 0.977875, loss 0.045891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.922620,roc 0.977865, loss 0.045863, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.923983,roc 0.978384, loss 0.045608, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.923873,roc 0.978373, loss 0.045630, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.6979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.6989s\n",
      "94\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n",
      "86\n",
      "0.04661641348340379 0.909264582063119 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.921675,roc 0.977217, loss 0.046616, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.930926,roc 0.984117, loss 0.041589, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.920068,roc 0.977544, loss 0.047681, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.919624,roc 0.976906, loss 0.047704, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.922168,roc 0.977575, loss 0.046721, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.923635,roc 0.978108, loss 0.046093, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.923438,roc 0.978110, loss 0.046044, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.7655s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.7655s\n",
      "94\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n",
      "86\n",
      "0.04611591746872347 0.9064947884911301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.924766,roc 0.977949, loss 0.046116, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.936422,roc 0.985460, loss 0.039343, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.923381,roc 0.977988, loss 0.045783, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.923844,roc 0.977927, loss 0.045979, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.924776,roc 0.978401, loss 0.045799, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.925366,roc 0.978524, loss 0.045378, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.925172,roc 0.978536, loss 0.045386, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.8034s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.8044s\n",
      "94\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n",
      "86\n",
      "0.04669055432238522 0.9018523357431115 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.923575,roc 0.977656, loss 0.046691, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.935454,roc 0.985331, loss 0.038306, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.927470,roc 0.978751, loss 0.046000, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.925828,roc 0.978639, loss 0.045442, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.926629,roc 0.978779, loss 0.045129, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.925996,roc 0.978882, loss 0.044922, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.926047,roc 0.978886, loss 0.044969, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.1031s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.1041s\n",
      "94\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n",
      "86\n",
      "0.04555939732184881 0.9080016258746331 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.925007,roc 0.978370, loss 0.045559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.937513,roc 0.985978, loss 0.038086, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.926836,roc 0.978727, loss 0.045174, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.924990,roc 0.978712, loss 0.045514, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.925455,roc 0.979040, loss 0.045060, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.925179,roc 0.978594, loss 0.045381, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.925373,roc 0.978675, loss 0.045343, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.5544s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.5544s\n",
      "94\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n",
      "86\n",
      "0.046559161115097634 0.905870568765787 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.921853,roc 0.977168, loss 0.046559, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.931596,roc 0.984285, loss 0.039886, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.927489,roc 0.980205, loss 0.044214, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.926322,roc 0.979426, loss 0.044953, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.927023,roc 0.979416, loss 0.044822, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.927026,roc 0.979111, loss 0.044942, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.926614,roc 0.979026, loss 0.045024, acc 0, ECE 0 #edges 376470, #graphs 94 time: 158.4889s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 158.4889s\n",
      "94\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n",
      "86\n",
      "0.045927899769093686 0.9081555032952998 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.925192,roc 0.978129, loss 0.045928, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.937971,roc 0.985901, loss 0.038226, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.925443,roc 0.979437, loss 0.044991, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.923839,roc 0.978177, loss 0.045636, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.925824,roc 0.978959, loss 0.044997, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.927227,roc 0.979156, loss 0.044783, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.927325,roc 0.979207, loss 0.044671, acc 0, ECE 0 #edges 376470, #graphs 94 time: 164.5589s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 164.5599s\n",
      "94\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n",
      "86\n",
      "0.04600717010348223 0.9121476061899367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.923752,roc 0.977912, loss 0.046007, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.937105,roc 0.985925, loss 0.037962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.926453,roc 0.979476, loss 0.044447, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.924849,roc 0.979063, loss 0.044977, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.925078,roc 0.978880, loss 0.045221, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.925495,roc 0.978622, loss 0.045273, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.925899,roc 0.978792, loss 0.045073, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.0522s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.0522s\n",
      "94\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n",
      "86\n",
      "0.04585698504931732 0.9056528176988067 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.924780,roc 0.978051, loss 0.045857, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.936083,roc 0.985493, loss 0.038347, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.931247,roc 0.979959, loss 0.043788, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.929874,roc 0.979013, loss 0.044570, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.927344,roc 0.978967, loss 0.044692, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.928655,roc 0.979582, loss 0.044206, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.928302,roc 0.979509, loss 0.044281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.4951s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.4961s\n",
      "94\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n",
      "86\n",
      "0.045496837752992306 0.9132102313968004 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.925907,roc 0.978364, loss 0.045497, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.935931,roc 0.985331, loss 0.039242, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.932318,roc 0.980364, loss 0.043333, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.929457,roc 0.980276, loss 0.043569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.929547,roc 0.980297, loss 0.043656, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.928898,roc 0.979784, loss 0.043973, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.928861,roc 0.979708, loss 0.044025, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.5737s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.5747s\n",
      "94\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n",
      "86\n",
      "0.04631508186571709 0.8994832041343666 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.925628,roc 0.978142, loss 0.046315, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.938819,roc 0.986135, loss 0.037580, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.927789,roc 0.980180, loss 0.043439, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.928608,roc 0.979859, loss 0.043964, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.929083,roc 0.979751, loss 0.044185, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.928308,roc 0.979550, loss 0.044186, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.928386,roc 0.979542, loss 0.044169, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.5953s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.5963s\n",
      "94\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n",
      "86\n",
      "0.04631557841631964 0.9109717504282436 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.922175,roc 0.976995, loss 0.046316, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.927051,roc 0.982967, loss 0.041845, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.925896,roc 0.978122, loss 0.045541, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.926613,roc 0.979498, loss 0.044599, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.928072,roc 0.979913, loss 0.043936, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.928050,roc 0.979497, loss 0.044178, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.927875,roc 0.979385, loss 0.044371, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.9095s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.9256s\n",
      "94\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n",
      "86\n",
      "0.04595599651717065 0.9144499608048079 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.924821,roc 0.977939, loss 0.045956, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.931192,roc 0.983973, loss 0.040779, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.926647,roc 0.977765, loss 0.046211, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.929779,roc 0.979402, loss 0.044847, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.930845,roc 0.980203, loss 0.043795, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.929203,roc 0.979738, loss 0.044082, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.929457,roc 0.979804, loss 0.044002, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.4692s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.4702s\n",
      "94\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n",
      "86\n",
      "0.04572336608778634 0.911982115379032 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.924995,roc 0.977992, loss 0.045723, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.937402,roc 0.985714, loss 0.038561, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.935712,roc 0.981556, loss 0.041977, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.931404,roc 0.980353, loss 0.043131, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.931376,roc 0.980198, loss 0.043484, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.929875,roc 0.979849, loss 0.043997, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.929774,roc 0.979867, loss 0.044013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.6063s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.6073s\n",
      "94\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n",
      "86\n",
      "0.04608546026931904 0.897712162122928 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.926919,roc 0.978550, loss 0.046085, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.936626,roc 0.985463, loss 0.038288, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.927619,roc 0.979881, loss 0.043880, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.927112,roc 0.979629, loss 0.044205, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.929350,roc 0.979788, loss 0.044134, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.929780,roc 0.979975, loss 0.043748, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.929806,roc 0.979968, loss 0.043701, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.0313s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.0323s\n",
      "94\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n",
      "86\n",
      "0.045100452126146176 0.9154196788897597 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.926661,roc 0.978617, loss 0.045100, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.938909,roc 0.986317, loss 0.037703, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.931971,roc 0.979845, loss 0.044513, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.930206,roc 0.979174, loss 0.044595, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.931357,roc 0.980145, loss 0.043748, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.930195,roc 0.980106, loss 0.043584, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.930207,roc 0.980100, loss 0.043645, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.0511s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.0521s\n",
      "94\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n",
      "86\n",
      "0.0455291021844149 0.9083035740208463 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.926538,roc 0.978421, loss 0.045529, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.940997,roc 0.986705, loss 0.036933, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.932076,roc 0.980795, loss 0.043752, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.931904,roc 0.980570, loss 0.043528, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.930706,roc 0.980350, loss 0.043337, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.931507,roc 0.980359, loss 0.043333, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.930535,roc 0.980213, loss 0.043503, acc 0, ECE 0 #edges 376470, #graphs 94 time: 157.8194s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 157.8204s\n",
      "94\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n",
      "86\n",
      "0.044698899448602995 0.9097000841970795 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.928262,roc 0.979045, loss 0.044699, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.936973,roc 0.985608, loss 0.038156, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.932504,roc 0.981691, loss 0.042062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.928881,roc 0.980198, loss 0.043523, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.929297,roc 0.980358, loss 0.043763, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.930537,roc 0.980141, loss 0.043778, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.930737,roc 0.980197, loss 0.043744, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.7145s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.7155s\n",
      "94\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n",
      "86\n",
      "0.04481003520881698 0.9124292309032315 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.927300,roc 0.978773, loss 0.044810, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.934895,roc 0.985112, loss 0.038742, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.931391,roc 0.979825, loss 0.043862, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.931725,roc 0.980221, loss 0.043690, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.930735,roc 0.979829, loss 0.044202, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.929720,roc 0.979843, loss 0.044048, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.929754,roc 0.979847, loss 0.044011, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.4092s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.4092s\n",
      "94\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n",
      "86\n",
      "0.04460283127671709 0.9109659437331245 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.927743,roc 0.979066, loss 0.044603, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.939747,roc 0.986478, loss 0.037275, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.934329,roc 0.981575, loss 0.042078, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.930988,roc 0.980254, loss 0.043246, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.931583,roc 0.980298, loss 0.043233, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.930389,roc 0.980052, loss 0.043611, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.930247,roc 0.980124, loss 0.043553, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.8099s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.8109s\n",
      "94\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n",
      "86\n",
      "0.04606783426079453 0.9089103736608312 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.923557,roc 0.977307, loss 0.046068, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.929055,roc 0.983351, loss 0.040976, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.927603,roc 0.979307, loss 0.044376, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.928710,roc 0.979908, loss 0.044328, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.930332,roc 0.980645, loss 0.043258, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.930592,roc 0.980196, loss 0.043472, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.930551,roc 0.980222, loss 0.043459, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.1214s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.1224s\n",
      "94\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n",
      "86\n",
      "0.045182428084606416 0.9095229799959351 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.926872,roc 0.978587, loss 0.045182, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.940054,roc 0.986547, loss 0.036962, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.929238,roc 0.978010, loss 0.044892, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.929800,roc 0.979498, loss 0.044036, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.930448,roc 0.980185, loss 0.043367, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.930937,roc 0.980403, loss 0.043373, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.930805,roc 0.980218, loss 0.043531, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.4360s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.4360s\n",
      "94\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n",
      "86\n",
      "0.04492146913837495 0.9096449205934442 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.927760,roc 0.978966, loss 0.044921, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.936044,roc 0.985301, loss 0.038568, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.929558,roc 0.978960, loss 0.044258, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.929652,roc 0.979778, loss 0.043849, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.930798,roc 0.980231, loss 0.043328, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.930750,roc 0.980201, loss 0.043533, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.930826,roc 0.980258, loss 0.043499, acc 0, ECE 0 #edges 376470, #graphs 94 time: 162.5519s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 162.5529s\n",
      "94\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n",
      "86\n",
      "0.04476971884955472 0.9062567139912318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.928678,roc 0.979220, loss 0.044770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.940396,roc 0.986648, loss 0.036741, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 29 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 29: precision 0.933008,roc 0.981551, loss 0.041741, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 29: precision 0.933408,roc 0.981564, loss 0.041958, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 29: precision 0.930852,roc 0.980214, loss 0.043615, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 29: precision 0.931251,roc 0.980514, loss 0.043241, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0030 lr: 0.0189 train phase of epoch 29: precision 0.931119,roc 0.980426, loss 0.043281, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.7038s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.7058s\n",
      "94\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n",
      "86\n",
      "0.04433007973652796 0.9170949104317276 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0030 dev phase of epoch 29: precision 0.928682,roc 0.979232, loss 0.044330, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0030 test phase of epoch 29: precision 0.937848,roc 0.985911, loss 0.038645, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 30 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 30: precision 0.929850,roc 0.979006, loss 0.044312, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 30: precision 0.930621,roc 0.979883, loss 0.043705, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 30: precision 0.930285,roc 0.979892, loss 0.043745, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 30: precision 0.931124,roc 0.980349, loss 0.043149, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0031 lr: 0.0189 train phase of epoch 30: precision 0.931080,roc 0.980416, loss 0.043164, acc 0, ECE 0 #edges 376470, #graphs 94 time: 132.2774s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 132.2784s\n",
      "94\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n",
      "86\n",
      "0.04534283854493527 0.9098481549226257 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0031 dev phase of epoch 30: precision 0.926824,roc 0.978445, loss 0.045343, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0031 test phase of epoch 30: precision 0.936435,roc 0.985353, loss 0.038667, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 31 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 31: precision 0.930094,roc 0.979053, loss 0.043863, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 31: precision 0.931971,roc 0.980384, loss 0.042809, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 31: precision 0.931218,roc 0.980481, loss 0.043057, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 31: precision 0.931038,roc 0.980489, loss 0.043204, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0032 lr: 0.0189 train phase of epoch 31: precision 0.930708,roc 0.980300, loss 0.043388, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.3157s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.3177s\n",
      "94\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n",
      "86\n",
      "0.04444784525624394 0.9164735940539446 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0032 dev phase of epoch 31: precision 0.928031,roc 0.979022, loss 0.044448, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0032 test phase of epoch 31: precision 0.934858,roc 0.985214, loss 0.039423, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 32 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 32: precision 0.927956,roc 0.979417, loss 0.044533, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 32: precision 0.930984,roc 0.980836, loss 0.042804, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 32: precision 0.932786,roc 0.981326, loss 0.042322, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 32: precision 0.931355,roc 0.980446, loss 0.043301, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0033 lr: 0.0189 train phase of epoch 32: precision 0.931369,roc 0.980423, loss 0.043329, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.0411s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.0411s\n",
      "94\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n",
      "86\n",
      "0.044700658229899326 0.9102691403187874 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0033 dev phase of epoch 32: precision 0.928526,roc 0.979127, loss 0.044701, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0033 test phase of epoch 32: precision 0.938379,roc 0.986185, loss 0.037147, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 33 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 33: precision 0.932710,roc 0.981158, loss 0.042866, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 33: precision 0.928811,roc 0.979832, loss 0.043891, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 33: precision 0.929840,roc 0.979837, loss 0.043764, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 33: precision 0.931072,roc 0.980406, loss 0.043294, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0034 lr: 0.0189 train phase of epoch 33: precision 0.931176,roc 0.980445, loss 0.043248, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.4196s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.4206s\n",
      "94\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n",
      "86\n",
      "0.04459734168038904 0.9091194146851318 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0034 dev phase of epoch 33: precision 0.929115,roc 0.979241, loss 0.044597, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0034 test phase of epoch 33: precision 0.937238,roc 0.985638, loss 0.038450, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 34 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 34: precision 0.929986,roc 0.980918, loss 0.042467, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 34: precision 0.930798,roc 0.980789, loss 0.042663, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 34: precision 0.931115,roc 0.980599, loss 0.042990, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 34: precision 0.930982,roc 0.980438, loss 0.043085, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0035 lr: 0.0189 train phase of epoch 34: precision 0.931208,roc 0.980482, loss 0.043056, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.4037s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.4047s\n",
      "94\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n",
      "86\n",
      "0.045882036764217655 0.8985221960920938 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0035 dev phase of epoch 34: precision 0.927793,roc 0.978821, loss 0.045882, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0035 test phase of epoch 34: precision 0.939814,roc 0.986541, loss 0.036967, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 35 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 35: precision 0.934938,roc 0.979552, loss 0.044037, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 35: precision 0.931269,roc 0.979804, loss 0.044103, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 35: precision 0.931533,roc 0.980041, loss 0.043689, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 35: precision 0.932327,roc 0.980612, loss 0.043196, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0036 lr: 0.0189 train phase of epoch 35: precision 0.932107,roc 0.980626, loss 0.043140, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.6099s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.6099s\n",
      "94\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n",
      "86\n",
      "0.044209242658665104 0.910777226141741 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0036 dev phase of epoch 35: precision 0.929131,roc 0.979329, loss 0.044209, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0036 test phase of epoch 35: precision 0.937430,roc 0.985825, loss 0.037810, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 36 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 36: precision 0.925068,roc 0.977919, loss 0.045326, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 36: precision 0.929862,roc 0.979815, loss 0.043548, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 36: precision 0.930894,roc 0.980235, loss 0.043397, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 36: precision 0.931875,roc 0.980661, loss 0.042921, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0037 lr: 0.0189 train phase of epoch 36: precision 0.931996,roc 0.980717, loss 0.042882, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.9676s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.9686s\n",
      "94\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n",
      "86\n",
      "0.044383893086997056 0.917280724675551 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0037 dev phase of epoch 36: precision 0.928805,roc 0.979146, loss 0.044384, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0037 test phase of epoch 36: precision 0.937587,roc 0.985679, loss 0.038905, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 37 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 37: precision 0.932582,roc 0.980131, loss 0.043571, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 37: precision 0.932434,roc 0.980911, loss 0.042826, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 37: precision 0.933562,roc 0.981448, loss 0.042344, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 37: precision 0.932192,roc 0.980847, loss 0.043041, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0038 lr: 0.0189 train phase of epoch 37: precision 0.932104,roc 0.980699, loss 0.043111, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.4042s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.4052s\n",
      "94\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n",
      "86\n",
      "0.04432948378853858 0.9089800540022644 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0038 dev phase of epoch 37: precision 0.929355,roc 0.979396, loss 0.044329, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0038 test phase of epoch 37: precision 0.937160,roc 0.985742, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 38 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 38: precision 0.928286,roc 0.979104, loss 0.044486, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 38: precision 0.931858,roc 0.980225, loss 0.043071, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 38: precision 0.931584,roc 0.980692, loss 0.043041, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 38: precision 0.932062,roc 0.980747, loss 0.042903, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0039 lr: 0.0189 train phase of epoch 38: precision 0.932177,roc 0.980772, loss 0.042844, acc 0, ECE 0 #edges 376470, #graphs 94 time: 159.9089s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 159.9089s\n",
      "94\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n",
      "86\n",
      "0.044418164149741465 0.9152541880788554 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0039 dev phase of epoch 38: precision 0.927643,roc 0.978850, loss 0.044418, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0039 test phase of epoch 38: precision 0.934802,roc 0.985053, loss 0.039059, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 39 LR:  [0.0189]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 39: precision 0.931084,roc 0.980119, loss 0.043902, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 39: precision 0.931361,roc 0.980604, loss 0.043358, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 39: precision 0.932250,roc 0.980758, loss 0.042917, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 39: precision 0.931936,roc 0.980683, loss 0.042773, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0040 lr: 0.0189 train phase of epoch 39: precision 0.931975,roc 0.980667, loss 0.042876, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.3542s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.3542s\n",
      "94\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n",
      "86\n",
      "0.044183875706289295 0.9144180239816505 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0040 dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0040 test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 40 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 40: precision 0.929479,roc 0.980580, loss 0.042462, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 40: precision 0.932577,roc 0.980794, loss 0.042194, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 40: precision 0.931939,roc 0.980557, loss 0.042820, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 40: precision 0.932438,roc 0.980728, loss 0.042830, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0041 lr: 0.01701 train phase of epoch 40: precision 0.932516,roc 0.980770, loss 0.042827, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.3198s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.3208s\n",
      "94\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n",
      "86\n",
      "0.04459825612780376 0.9120808291960631 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0041 dev phase of epoch 40: precision 0.928570,roc 0.979103, loss 0.044598, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0041 test phase of epoch 40: precision 0.939152,roc 0.986423, loss 0.036789, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 41 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 41: precision 0.927991,roc 0.979182, loss 0.044374, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 41: precision 0.928962,roc 0.979379, loss 0.044199, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 41: precision 0.930728,roc 0.980114, loss 0.043497, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 41: precision 0.931949,roc 0.980724, loss 0.042816, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0042 lr: 0.01701 train phase of epoch 41: precision 0.932129,roc 0.980767, loss 0.042768, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.7834s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.7834s\n",
      "94\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n",
      "86\n",
      "0.04428758006541297 0.9102313968005107 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0042 dev phase of epoch 41: precision 0.929659,roc 0.979359, loss 0.044288, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0042 test phase of epoch 41: precision 0.939415,roc 0.986230, loss 0.037867, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 42 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 42: precision 0.932628,roc 0.981207, loss 0.042146, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 42: precision 0.932303,roc 0.980534, loss 0.042738, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 42: precision 0.933175,roc 0.980999, loss 0.042628, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 42: precision 0.932655,roc 0.980869, loss 0.042690, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0043 lr: 0.01701 train phase of epoch 42: precision 0.932658,roc 0.980849, loss 0.042681, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.3732s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.3732s\n",
      "94\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n",
      "86\n",
      "0.04420374118616505 0.9141973695671106 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0043 dev phase of epoch 42: precision 0.928985,roc 0.979346, loss 0.044204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0043 test phase of epoch 42: precision 0.939583,roc 0.986250, loss 0.037558, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 43 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 43: precision 0.932111,roc 0.980260, loss 0.042819, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 43: precision 0.932832,roc 0.981231, loss 0.041875, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 43: precision 0.932053,roc 0.980817, loss 0.042517, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 43: precision 0.932781,roc 0.981109, loss 0.042457, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0044 lr: 0.01701 train phase of epoch 43: precision 0.932703,roc 0.980927, loss 0.042626, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.3158s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.3168s\n",
      "94\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n",
      "86\n",
      "0.04588981121902382 0.9213773480823387 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0044 dev phase of epoch 43: precision 0.926043,roc 0.978269, loss 0.045890, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0044 test phase of epoch 43: precision 0.930479,roc 0.983766, loss 0.042449, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 44 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 44: precision 0.931838,roc 0.980369, loss 0.043393, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 44: precision 0.930369,roc 0.980379, loss 0.043561, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 44: precision 0.931475,roc 0.980112, loss 0.043455, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 44: precision 0.931923,roc 0.980644, loss 0.042970, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0045 lr: 0.01701 train phase of epoch 44: precision 0.931952,roc 0.980662, loss 0.042965, acc 0, ECE 0 #edges 376470, #graphs 94 time: 161.8483s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 161.8493s\n",
      "94\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n",
      "86\n",
      "0.044481186523091076 0.9093545858374704 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0045 dev phase of epoch 44: precision 0.928477,roc 0.978928, loss 0.044481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0045 test phase of epoch 44: precision 0.938154,roc 0.985886, loss 0.037750, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 45 LR:  [0.01701]\n",
      "tensor([0.5400]) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 45: precision 0.932127,roc 0.981028, loss 0.042162, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 45: precision 0.933080,roc 0.980914, loss 0.042729, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 45: precision 0.932128,roc 0.980292, loss 0.042875, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 45: precision 0.932063,roc 0.980711, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0046 lr: 0.01701 train phase of epoch 45: precision 0.932230,roc 0.980743, loss 0.042734, acc 0, ECE 0 #edges 376470, #graphs 94 time: 170.0387s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 170.0397s\n",
      "94\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n",
      "86\n",
      "0.044305768329434815 0.9081090497343435 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0046 dev phase of epoch 45: precision 0.929982,roc 0.979576, loss 0.044306, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0046 test phase of epoch 45: precision 0.940102,roc 0.986497, loss 0.037062, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 9866.1490s\n",
      "INFO:root:Val set results: dev phase of epoch 39: precision 0.929405,roc 0.979261, loss 0.044184, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 39: precision 0.939833,roc 0.986297, loss 0.037709, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 39, 'loss': 0.044183875706289295, 'roc': 0.979261082488716, 'ap': 0.9294045831413663, 'acc': 0.9144180239816505, 'ECE': 0.0}\n",
      "0.044183875706289295 val mets\n",
      "FOLDERS\n",
      "['0', '1', '2', '3', '4']\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD08>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD48>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD88>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD08>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD48>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05AD88>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\scan_info.csv\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\3', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\3', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E96276C08>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05A8C8>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E96276708>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E96276C08>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B05A8C8>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E96276708>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\scan_info.csv\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\4', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=0.54, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_01_27_27_955087', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\4', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009F48>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009DC8>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009F08>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009F48>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009DC8>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B009F08>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\scan_info.csv\n",
      "NEXT LEVEL??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 ['C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', 'C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\3', 'C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_0.54c_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\4']\n",
      "tensor([0.5400]) layer of c 0\n",
      "0.54 listed c\n",
      "tensor([0.5400]) layer of c 1\n",
      "0.54 listed c\n",
      "2.0 1.0 0.54\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.54 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n",
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.075977  1.852352  2.089339  1.887098  1.375879  1.955221   \n",
      "1             1  1.157592  1.847374  2.161801  2.090289  1.568091  2.010437   \n",
      "2             2  1.269635  1.703498  1.981789  1.914679  1.544782  1.838967   \n",
      "3             3  1.147738  1.701507  2.419342  2.015172  1.642904  2.036224   \n",
      "4             4  0.996819  1.608146  1.703337  1.794180  1.340487  1.698647   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.117335  1.907155  1.727136  1.815575  1.697828  1.660246   \n",
      "176         176  1.229022  1.983242  2.092733  1.904365  1.290893  1.963388   \n",
      "177         177  1.140393  1.955762  2.171260  1.912329  1.257602  1.990973   \n",
      "178         178  1.273904  1.775038  1.839145  1.916806  1.268397  1.930194   \n",
      "179         179  1.274988  1.605351  1.764594  1.861998  1.271069  1.801824   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.280300  2.059061  1.619190  ...        0.425756         0.330573   \n",
      "1    1.310389  2.167028  1.745707  ...        0.369600         0.297823   \n",
      "2    1.284162  1.796758  1.788984  ...        0.409225         0.338635   \n",
      "3    1.121947  2.119742  1.620307  ...        0.364312         0.304617   \n",
      "4    1.123226  1.739922  1.523300  ...        0.458220         0.378856   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.993560  1.510665  1.332797  ...        0.482376         0.409650   \n",
      "176  1.479289  2.022871  1.797557  ...        0.445464         0.319645   \n",
      "177  1.456171  1.836434  1.721390  ...        0.427556         0.314958   \n",
      "178  1.368388  1.830987  1.817682  ...        0.416918         0.330419   \n",
      "179  1.293402  1.731754  1.919487  ...        0.422415         0.351880   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.395819         0.342424        0.344111       0.415455   \n",
      "1          0.342211         0.287717        0.304406       0.370789   \n",
      "2          0.389357         0.381430        0.372401       0.447095   \n",
      "3          0.394304         0.337691        0.306120       0.445622   \n",
      "4          0.427096         0.396179        0.408951       0.450389   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.457853         0.434984        0.412383       0.462694   \n",
      "176        0.354272         0.361543        0.361624       0.381787   \n",
      "177        0.361577         0.378865        0.348150       0.398208   \n",
      "178        0.382597         0.395638        0.371531       0.448892   \n",
      "179        0.386229         0.417869        0.408886       0.490276   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.294053        0.466757         0.348343        0.440872  \n",
      "1          0.231689        0.452749         0.329714        0.423363  \n",
      "2          0.343862        0.492398         0.355540        0.389770  \n",
      "3          0.268505        0.462640         0.294496        0.341587  \n",
      "4          0.368003        0.523783         0.410770        0.504837  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.403384        0.531301         0.445815        0.504665  \n",
      "176        0.343446        0.464874         0.329019        0.358117  \n",
      "177        0.359137        0.482878         0.358373        0.411564  \n",
      "178        0.372741        0.488973         0.391901        0.459788  \n",
      "179        0.376641        0.497927         0.396061        0.423199  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n",
      "passed manual model_dir\n",
      "tensor([0.5400]) layer of c 0\n",
      "0.54 listed c\n",
      "tensor([0.5400]) layer of c 1\n",
      "0.54 listed c\n",
      "2.0 1.0 0.54\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.54 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\3\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.075977  1.852352  2.089339  1.887098  1.375879  1.955221   \n",
      "1             1  1.157592  1.847374  2.161801  2.090289  1.568091  2.010437   \n",
      "2             2  1.269635  1.703498  1.981789  1.914679  1.544782  1.838967   \n",
      "3             3  1.147738  1.701507  2.419342  2.015172  1.642904  2.036224   \n",
      "4             4  0.996819  1.608146  1.703337  1.794180  1.340487  1.698647   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.117335  1.907155  1.727136  1.815575  1.697828  1.660246   \n",
      "176         176  1.229022  1.983242  2.092733  1.904365  1.290893  1.963388   \n",
      "177         177  1.140393  1.955762  2.171260  1.912329  1.257602  1.990973   \n",
      "178         178  1.273904  1.775038  1.839145  1.916806  1.268397  1.930194   \n",
      "179         179  1.274988  1.605351  1.764594  1.861998  1.271069  1.801824   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.280300  2.059061  1.619190  ...        0.425756         0.330573   \n",
      "1    1.310389  2.167028  1.745707  ...        0.369600         0.297823   \n",
      "2    1.284162  1.796758  1.788984  ...        0.409225         0.338635   \n",
      "3    1.121947  2.119742  1.620307  ...        0.364312         0.304617   \n",
      "4    1.123226  1.739922  1.523300  ...        0.458220         0.378856   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.993560  1.510665  1.332797  ...        0.482376         0.409650   \n",
      "176  1.479289  2.022871  1.797557  ...        0.445464         0.319645   \n",
      "177  1.456171  1.836434  1.721390  ...        0.427556         0.314958   \n",
      "178  1.368388  1.830987  1.817682  ...        0.416918         0.330419   \n",
      "179  1.293402  1.731754  1.919487  ...        0.422415         0.351880   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.395819         0.342424        0.344111       0.415455   \n",
      "1          0.342211         0.287717        0.304406       0.370789   \n",
      "2          0.389357         0.381430        0.372401       0.447095   \n",
      "3          0.394304         0.337691        0.306120       0.445622   \n",
      "4          0.427096         0.396179        0.408951       0.450389   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.457853         0.434984        0.412383       0.462694   \n",
      "176        0.354272         0.361543        0.361624       0.381787   \n",
      "177        0.361577         0.378865        0.348150       0.398208   \n",
      "178        0.382597         0.395638        0.371531       0.448892   \n",
      "179        0.386229         0.417869        0.408886       0.490276   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.294053        0.466757         0.348343        0.440872  \n",
      "1          0.231689        0.452749         0.329714        0.423363  \n",
      "2          0.343862        0.492398         0.355540        0.389770  \n",
      "3          0.268505        0.462640         0.294496        0.341587  \n",
      "4          0.368003        0.523783         0.410770        0.504837  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.403384        0.531301         0.445815        0.504665  \n",
      "176        0.343446        0.464874         0.329019        0.358117  \n",
      "177        0.359137        0.482878         0.358373        0.411564  \n",
      "178        0.372741        0.488973         0.391901        0.459788  \n",
      "179        0.376641        0.497927         0.396061        0.423199  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed manual model_dir\n",
      "tensor([0.5400]) layer of c 0\n",
      "0.54 listed c\n",
      "tensor([0.5400]) layer of c 1\n",
      "0.54 listed c\n",
      "2.0 1.0 0.54\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.54 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n",
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_0.54c_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\4\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.54 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.075977  1.852352  2.089339  1.887098  1.375879  1.955221   \n",
      "1             1  1.157592  1.847374  2.161801  2.090289  1.568091  2.010437   \n",
      "2             2  1.269635  1.703498  1.981789  1.914679  1.544782  1.838967   \n",
      "3             3  1.147738  1.701507  2.419342  2.015172  1.642904  2.036224   \n",
      "4             4  0.996819  1.608146  1.703337  1.794180  1.340487  1.698647   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.117335  1.907155  1.727136  1.815575  1.697828  1.660246   \n",
      "176         176  1.229022  1.983242  2.092733  1.904365  1.290893  1.963388   \n",
      "177         177  1.140393  1.955762  2.171260  1.912329  1.257602  1.990973   \n",
      "178         178  1.273904  1.775038  1.839145  1.916806  1.268397  1.930194   \n",
      "179         179  1.274988  1.605351  1.764594  1.861998  1.271069  1.801824   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.280300  2.059061  1.619190  ...        0.425756         0.330573   \n",
      "1    1.310389  2.167028  1.745707  ...        0.369600         0.297823   \n",
      "2    1.284162  1.796758  1.788984  ...        0.409225         0.338635   \n",
      "3    1.121947  2.119742  1.620307  ...        0.364312         0.304617   \n",
      "4    1.123226  1.739922  1.523300  ...        0.458220         0.378856   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.993560  1.510665  1.332797  ...        0.482376         0.409650   \n",
      "176  1.479289  2.022871  1.797557  ...        0.445464         0.319645   \n",
      "177  1.456171  1.836434  1.721390  ...        0.427556         0.314958   \n",
      "178  1.368388  1.830987  1.817682  ...        0.416918         0.330419   \n",
      "179  1.293402  1.731754  1.919487  ...        0.422415         0.351880   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.395819         0.342424        0.344111       0.415455   \n",
      "1          0.342211         0.287717        0.304406       0.370789   \n",
      "2          0.389357         0.381430        0.372401       0.447095   \n",
      "3          0.394304         0.337691        0.306120       0.445622   \n",
      "4          0.427096         0.396179        0.408951       0.450389   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.457853         0.434984        0.412383       0.462694   \n",
      "176        0.354272         0.361543        0.361624       0.381787   \n",
      "177        0.361577         0.378865        0.348150       0.398208   \n",
      "178        0.382597         0.395638        0.371531       0.448892   \n",
      "179        0.386229         0.417869        0.408886       0.490276   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.294053        0.466757         0.348343        0.440872  \n",
      "1          0.231689        0.452749         0.329714        0.423363  \n",
      "2          0.343862        0.492398         0.355540        0.389770  \n",
      "3          0.268505        0.462640         0.294496        0.341587  \n",
      "4          0.368003        0.523783         0.410770        0.504837  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.403384        0.531301         0.445815        0.504665  \n",
      "176        0.343446        0.464874         0.329019        0.358117  \n",
      "177        0.359137        0.482878         0.358373        0.411564  \n",
      "178        0.372741        0.488973         0.391901        0.459788  \n",
      "179        0.376641        0.497927         0.396061        0.423199  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n",
      "tensor([0.5400]) AVERAGE C\n",
      "out stat dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgnn\\lib\\site-packages\\pandas\\core\\frame.py:9138: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Scan Index_'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  sort=sort,\n",
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 153) og shape\n",
      "(180, 153) DF SHAPE\n",
      "(180, 153) DF SHAPE\n",
      "(180, 153) DF SHAPE\n",
      "(180, 90) conccat\n",
      "(180, 90) SHAPE\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0                 49.0          22.0  ...        0.425756         0.330573   \n",
      "1                 49.0          22.0  ...          0.3696         0.297823   \n",
      "2                  NaN           NaN  ...        0.409225         0.338635   \n",
      "3                  NaN           NaN  ...        0.364312         0.304617   \n",
      "4                115.0          21.0  ...         0.45822         0.378856   \n",
      "..                 ...           ...  ...             ...              ...   \n",
      "175               45.0          22.0  ...        0.482376          0.40965   \n",
      "176               74.0          21.0  ...        0.445464         0.319645   \n",
      "177               74.0          21.0  ...        0.427556         0.314958   \n",
      "178               50.0          22.0  ...        0.416918         0.330419   \n",
      "179               50.0          22.0  ...        0.422415          0.35188   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.395819         0.342424        0.344111       0.415455   \n",
      "1          0.342211         0.287717        0.304406       0.370789   \n",
      "2          0.389357          0.38143        0.372401       0.447095   \n",
      "3          0.394304         0.337691         0.30612       0.445622   \n",
      "4          0.427096         0.396179        0.408951       0.450389   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.457853         0.434984        0.412383       0.462694   \n",
      "176        0.354272         0.361543        0.361624       0.381787   \n",
      "177        0.361577         0.378865         0.34815       0.398208   \n",
      "178        0.382597         0.395638        0.371531       0.448892   \n",
      "179        0.386229         0.417869        0.408886       0.490276   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.294053        0.466757         0.348343        0.440872  \n",
      "1          0.231689        0.452749         0.329714        0.423363  \n",
      "2          0.343862        0.492398          0.35554         0.38977  \n",
      "3          0.268505         0.46264         0.294496        0.341587  \n",
      "4          0.368003        0.523783          0.41077        0.504837  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.403384        0.531301         0.445815        0.504665  \n",
      "176        0.343446        0.464874         0.329019        0.358117  \n",
      "177        0.359137        0.482878         0.358373        0.411564  \n",
      "178        0.372741        0.488973         0.391901        0.459788  \n",
      "179        0.376641        0.497927         0.396061        0.423199  \n",
      "\n",
      "[180 rows x 154 columns] avg stat df\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n",
      "None C VAL\n",
      "lp should match manual\n",
      "lp 3\n",
      "compase\n",
      "C: None, ID: 0, PLV 1\n",
      "C: None, ID: 0, PLV 1\n",
      "\n",
      "\n",
      "HGCN_full_findc_plv_dp model\n",
      "HGCN_full_findc_plv_dp model\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study dir\n",
      "we are in here??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\0', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025EA13D1B48>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.671630,roc 0.891829, loss 0.139282, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.729332,roc 0.916978, loss 0.108898, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.766206,roc 0.930656, loss 0.093883, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.792186,roc 0.939968, loss 0.084392, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.794460,roc 0.940612, loss 0.083729, acc 0, ECE 0 #edges 376470, #graphs 94 time: 164.6724s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 164.6724s\n",
      "94\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.880277,roc 0.968807, loss 0.055159, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.875916,roc 0.974972, loss 0.052003, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.9601], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.883635,roc 0.968241, loss 0.056408, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.892244,roc 0.971220, loss 0.053569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.896914,roc 0.972899, loss 0.051688, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.900342,roc 0.973557, loss 0.051493, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.900449,roc 0.973607, loss 0.051404, acc 0, ECE 0 #edges 376470, #graphs 94 time: 156.3940s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 156.3940s\n",
      "94\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.911088,roc 0.975541, loss 0.050926, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.921168,roc 0.983459, loss 0.047355, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.6995], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908931,roc 0.976678, loss 0.049663, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.913676,roc 0.976629, loss 0.049291, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.916450,roc 0.977051, loss 0.049160, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.915941,roc 0.976959, loss 0.048572, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.916062,roc 0.976995, loss 0.048472, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.3662s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.3672s\n",
      "94\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.919609,roc 0.977378, loss 0.048204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.932831,roc 0.985469, loss 0.038421, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5776], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.919102,roc 0.978162, loss 0.047595, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.920569,roc 0.978796, loss 0.047946, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.920169,roc 0.978220, loss 0.047490, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.922422,roc 0.978612, loss 0.046780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.922312,roc 0.978452, loss 0.047030, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.6259s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.6259s\n",
      "94\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.924732,roc 0.978791, loss 0.047767, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.940509,roc 0.986835, loss 0.045662, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5723], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.925256,roc 0.979590, loss 0.044650, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.925834,roc 0.979645, loss 0.045557, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.926080,roc 0.979725, loss 0.045511, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.926051,roc 0.979384, loss 0.045930, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.926111,roc 0.979453, loss 0.045837, acc 0, ECE 0 #edges 376470, #graphs 94 time: 171.8727s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 171.8737s\n",
      "94\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.926024,roc 0.979138, loss 0.045467, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.935971,roc 0.985705, loss 0.040673, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5111], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.933000,roc 0.980998, loss 0.043194, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.927107,roc 0.979603, loss 0.045642, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.927102,roc 0.979301, loss 0.045922, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.927157,roc 0.979600, loss 0.045780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.927337,roc 0.979635, loss 0.045737, acc 0, ECE 0 #edges 376470, #graphs 94 time: 176.4284s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 176.4294s\n",
      "94\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.926450,roc 0.978878, loss 0.045481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.934554,roc 0.985150, loss 0.040826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5272], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.931087,roc 0.979764, loss 0.044553, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.929970,roc 0.979889, loss 0.045021, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.928904,roc 0.979985, loss 0.044841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.930325,roc 0.980492, loss 0.044651, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.930251,roc 0.980491, loss 0.044724, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.5971s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.5971s\n",
      "94\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.927383,roc 0.979228, loss 0.046171, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.935883,roc 0.985460, loss 0.045299, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5544], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.926801,roc 0.979847, loss 0.046055, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.926795,roc 0.979361, loss 0.045870, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.928499,roc 0.979813, loss 0.045442, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.929911,roc 0.980272, loss 0.044923, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.929824,roc 0.980294, loss 0.044858, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.3504s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.3508s\n",
      "94\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.929021,roc 0.979452, loss 0.045848, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.940898,roc 0.986558, loss 0.037853, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5341], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.929918,roc 0.980228, loss 0.043967, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.930286,roc 0.980094, loss 0.044785, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.931247,roc 0.980609, loss 0.044406, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.931715,roc 0.980664, loss 0.044045, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.931468,roc 0.980650, loss 0.044082, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.0705s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.0715s\n",
      "94\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.928308,roc 0.979352, loss 0.046570, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.940079,roc 0.986428, loss 0.037076, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5372], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.933569,roc 0.980816, loss 0.045062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.932375,roc 0.980824, loss 0.044440, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.932745,roc 0.980853, loss 0.044193, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.932086,roc 0.980914, loss 0.044177, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.932090,roc 0.980908, loss 0.044262, acc 0, ECE 0 #edges 376470, #graphs 94 time: 176.8646s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 176.8646s\n",
      "94\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.929072,roc 0.979929, loss 0.044457, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.941326,roc 0.987007, loss 0.038693, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5257], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.932050,roc 0.980592, loss 0.044208, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.930996,roc 0.980735, loss 0.044576, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.931774,roc 0.981092, loss 0.044122, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.931266,roc 0.980654, loss 0.044258, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.931497,roc 0.980740, loss 0.044185, acc 0, ECE 0 #edges 376470, #graphs 94 time: 160.4135s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 160.4145s\n",
      "94\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.928302,roc 0.979565, loss 0.045482, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.940334,roc 0.986622, loss 0.037260, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5440], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.934764,roc 0.982606, loss 0.042502, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.932206,roc 0.981417, loss 0.043679, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.932668,roc 0.981375, loss 0.043621, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.932352,roc 0.980961, loss 0.044220, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.932006,roc 0.980891, loss 0.044318, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.5219s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.5219s\n",
      "94\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.930473,roc 0.980083, loss 0.045475, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.942672,roc 0.987141, loss 0.041339, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5344], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.932019,roc 0.981622, loss 0.043549, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.929843,roc 0.980338, loss 0.044418, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.931081,roc 0.980848, loss 0.043841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.932414,roc 0.980980, loss 0.043709, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.932607,roc 0.981056, loss 0.043612, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.0540s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.0550s\n",
      "94\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.930319,roc 0.980076, loss 0.046392, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.944844,roc 0.987797, loss 0.040937, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5670], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.932979,roc 0.981609, loss 0.043293, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.931262,roc 0.981218, loss 0.043779, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.930872,roc 0.980849, loss 0.044042, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.931611,roc 0.980721, loss 0.044222, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.931976,roc 0.980874, loss 0.044022, acc 0, ECE 0 #edges 376470, #graphs 94 time: 170.4448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 170.4458s\n",
      "94\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.929702,roc 0.979867, loss 0.044757, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.943853,roc 0.987519, loss 0.036773, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5431], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.937452,roc 0.982031, loss 0.042583, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.935577,roc 0.981047, loss 0.043382, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.933202,roc 0.980978, loss 0.043611, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.934177,roc 0.981479, loss 0.043300, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.934027,roc 0.981466, loss 0.043316, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.4910s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.4920s\n",
      "94\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.931763,roc 0.980419, loss 0.044167, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.943387,roc 0.987357, loss 0.037938, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5570], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.938924,roc 0.982515, loss 0.042361, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.936399,roc 0.982529, loss 0.042307, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.936370,roc 0.982534, loss 0.042449, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.935162,roc 0.981856, loss 0.042898, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.935114,roc 0.981781, loss 0.042948, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.5114s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.5114s\n",
      "94\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.929000,roc 0.979554, loss 0.047563, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.942478,roc 0.987071, loss 0.036982, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5391], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.931838,roc 0.981641, loss 0.043025, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.932958,roc 0.981384, loss 0.043615, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.934106,roc 0.981469, loss 0.043548, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.933578,roc 0.981353, loss 0.043439, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.933702,roc 0.981358, loss 0.043412, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.6233s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.6243s\n",
      "94\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.927906,roc 0.979136, loss 0.045145, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.935241,roc 0.985264, loss 0.040671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5619], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.931598,roc 0.980176, loss 0.044244, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.931926,roc 0.981304, loss 0.043816, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.933452,roc 0.981701, loss 0.043004, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.933533,roc 0.981333, loss 0.043249, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.933478,roc 0.981257, loss 0.043547, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.6893s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.6893s\n",
      "94\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.931355,roc 0.980246, loss 0.045348, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.939950,roc 0.986420, loss 0.041686, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5805], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.931032,roc 0.979563, loss 0.046369, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.933611,roc 0.980908, loss 0.044839, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.935178,roc 0.981790, loss 0.043488, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.933956,roc 0.981455, loss 0.043585, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.934231,roc 0.981521, loss 0.043504, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.9242s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.9242s\n",
      "94\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.929642,roc 0.979690, loss 0.044987, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.942843,roc 0.987234, loss 0.038093, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5692], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.940124,roc 0.983005, loss 0.041183, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.936686,roc 0.982093, loss 0.042260, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.936904,roc 0.982011, loss 0.042707, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.935068,roc 0.981657, loss 0.043046, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.934939,roc 0.981680, loss 0.043013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.9221s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.9231s\n",
      "94\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.931707,roc 0.980416, loss 0.044062, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.941689,roc 0.986854, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5756], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.932111,roc 0.981520, loss 0.043975, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.931860,roc 0.981273, loss 0.044022, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.934570,roc 0.981586, loss 0.043507, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.934825,roc 0.981688, loss 0.043183, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.934844,roc 0.981674, loss 0.043154, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.0803s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.0813s\n",
      "94\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.931222,roc 0.980189, loss 0.044402, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.945014,roc 0.987798, loss 0.036996, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5727], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.937264,roc 0.981588, loss 0.044556, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.935113,roc 0.981002, loss 0.043944, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.936361,roc 0.981899, loss 0.043206, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.934821,roc 0.981724, loss 0.043002, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.934846,roc 0.981728, loss 0.043028, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.1789s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.1799s\n",
      "94\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.930796,roc 0.979984, loss 0.044959, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.945855,roc 0.987860, loss 0.035872, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5460], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.936245,roc 0.982334, loss 0.042768, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.936509,roc 0.982230, loss 0.042908, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.935433,roc 0.981994, loss 0.042816, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.936353,roc 0.982027, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.935397,roc 0.981892, loss 0.042881, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.7669s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.7679s\n",
      "94\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5577], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.938260,roc 0.983492, loss 0.040722, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.933423,roc 0.981720, loss 0.042746, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.933944,roc 0.981954, loss 0.042814, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.935149,roc 0.981761, loss 0.042801, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.935198,roc 0.981771, loss 0.042825, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.1717s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.1727s\n",
      "94\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.930117,roc 0.979870, loss 0.044789, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.939414,roc 0.986149, loss 0.037456, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5598], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.937162,roc 0.981710, loss 0.043120, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.936743,roc 0.981999, loss 0.042721, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.936038,roc 0.981692, loss 0.042968, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.934857,roc 0.981640, loss 0.042885, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.934945,roc 0.981665, loss 0.042804, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.5861s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.5881s\n",
      "94\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.930535,roc 0.980201, loss 0.045816, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.944617,roc 0.987737, loss 0.035768, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5438], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.939249,roc 0.983306, loss 0.041201, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.935466,roc 0.981752, loss 0.042648, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.936331,roc 0.981920, loss 0.042569, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.935433,roc 0.981802, loss 0.042535, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.935253,roc 0.981862, loss 0.042498, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.2510s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.2510s\n",
      "94\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.928698,roc 0.979129, loss 0.047734, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.936418,roc 0.985521, loss 0.045692, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.6062], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.931898,roc 0.980494, loss 0.044801, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.933224,roc 0.981422, loss 0.043974, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.934948,roc 0.982167, loss 0.042811, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.935449,roc 0.981834, loss 0.043015, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.935359,roc 0.981846, loss 0.042982, acc 0, ECE 0 #edges 376470, #graphs 94 time: 170.8168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 170.8188s\n",
      "94\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.927580,roc 0.978998, loss 0.047792, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.941843,roc 0.986917, loss 0.036826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5359], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.931428,roc 0.978989, loss 0.044659, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.932449,roc 0.980528, loss 0.043634, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.933959,roc 0.981475, loss 0.042718, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.934760,roc 0.981821, loss 0.042547, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.934716,roc 0.981679, loss 0.042660, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.6259s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.6259s\n",
      "94\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.931150,roc 0.980224, loss 0.044420, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.941901,roc 0.986971, loss 0.036822, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5419], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.933818,roc 0.980390, loss 0.042987, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.934916,roc 0.981549, loss 0.042527, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.935592,roc 0.981871, loss 0.042142, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.935662,roc 0.981876, loss 0.042321, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.935717,roc 0.981925, loss 0.042295, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.8859s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.8859s\n",
      "94\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.931579,roc 0.980424, loss 0.044686, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.944422,roc 0.987746, loss 0.035666, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 6369.3339s\n",
      "INFO:root:Val set results: dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n",
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 22, 'loss': 0.0437703710221931, 'roc': 0.9805947664299266, 'ap': 0.9324662764985167, 'acc': 0.9134163690735417, 'ECE': 0.0}\n",
      "0.0437703710221931 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\1', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025E86B4F348>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.671630,roc 0.891829, loss 0.139282, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.729332,roc 0.916978, loss 0.108898, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.766206,roc 0.930656, loss 0.093883, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.792186,roc 0.939968, loss 0.084392, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.794460,roc 0.940612, loss 0.083729, acc 0, ECE 0 #edges 376470, #graphs 94 time: 181.0258s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 181.0258s\n",
      "94\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.880277,roc 0.968807, loss 0.055159, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.875916,roc 0.974972, loss 0.052003, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.9601], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.883635,roc 0.968241, loss 0.056408, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.892244,roc 0.971220, loss 0.053569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.896914,roc 0.972899, loss 0.051688, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.900342,roc 0.973557, loss 0.051493, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.900449,roc 0.973607, loss 0.051404, acc 0, ECE 0 #edges 376470, #graphs 94 time: 169.4359s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 169.4369s\n",
      "94\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.911088,roc 0.975541, loss 0.050926, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.921168,roc 0.983459, loss 0.047355, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.6995], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908931,roc 0.976678, loss 0.049663, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.913676,roc 0.976629, loss 0.049291, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.916450,roc 0.977051, loss 0.049160, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.915941,roc 0.976959, loss 0.048572, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.916062,roc 0.976995, loss 0.048472, acc 0, ECE 0 #edges 376470, #graphs 94 time: 168.8517s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 168.8517s\n",
      "94\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.919609,roc 0.977378, loss 0.048204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.932831,roc 0.985469, loss 0.038421, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5776], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.919102,roc 0.978162, loss 0.047595, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.920569,roc 0.978796, loss 0.047946, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.920169,roc 0.978220, loss 0.047490, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.922422,roc 0.978612, loss 0.046780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.922312,roc 0.978452, loss 0.047030, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.5374s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.5384s\n",
      "94\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.924732,roc 0.978791, loss 0.047767, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.940509,roc 0.986835, loss 0.045662, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5723], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.925256,roc 0.979590, loss 0.044650, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.925834,roc 0.979645, loss 0.045557, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.926080,roc 0.979725, loss 0.045511, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.926051,roc 0.979384, loss 0.045930, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.926111,roc 0.979453, loss 0.045837, acc 0, ECE 0 #edges 376470, #graphs 94 time: 175.0589s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 175.0599s\n",
      "94\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.926024,roc 0.979138, loss 0.045467, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.935971,roc 0.985705, loss 0.040673, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5111], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.933000,roc 0.980998, loss 0.043194, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.927107,roc 0.979603, loss 0.045642, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.927102,roc 0.979301, loss 0.045922, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.927157,roc 0.979600, loss 0.045780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.927337,roc 0.979635, loss 0.045737, acc 0, ECE 0 #edges 376470, #graphs 94 time: 165.9751s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 165.9751s\n",
      "94\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.926450,roc 0.978878, loss 0.045481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.934554,roc 0.985150, loss 0.040826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5272], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.931087,roc 0.979764, loss 0.044553, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.929970,roc 0.979889, loss 0.045021, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.928904,roc 0.979985, loss 0.044841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.930325,roc 0.980492, loss 0.044651, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.930251,roc 0.980491, loss 0.044724, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.8372s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.8372s\n",
      "94\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.927383,roc 0.979228, loss 0.046171, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.935883,roc 0.985460, loss 0.045299, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5544], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.926801,roc 0.979847, loss 0.046055, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.926795,roc 0.979361, loss 0.045870, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.928499,roc 0.979813, loss 0.045442, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.929911,roc 0.980272, loss 0.044923, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.929824,roc 0.980294, loss 0.044858, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.8883s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.8893s\n",
      "94\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.929021,roc 0.979452, loss 0.045848, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.940898,roc 0.986558, loss 0.037853, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5341], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.929918,roc 0.980228, loss 0.043967, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.930286,roc 0.980094, loss 0.044785, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.931247,roc 0.980609, loss 0.044406, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.931715,roc 0.980664, loss 0.044045, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.931468,roc 0.980650, loss 0.044082, acc 0, ECE 0 #edges 376470, #graphs 94 time: 175.6398s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 175.6398s\n",
      "94\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.928308,roc 0.979352, loss 0.046570, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.940079,roc 0.986428, loss 0.037076, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5372], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.933569,roc 0.980816, loss 0.045062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.932375,roc 0.980824, loss 0.044440, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.932745,roc 0.980853, loss 0.044193, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.932086,roc 0.980914, loss 0.044177, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.932090,roc 0.980908, loss 0.044262, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.7536s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.7697s\n",
      "94\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.929072,roc 0.979929, loss 0.044457, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.941326,roc 0.987007, loss 0.038693, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5257], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.932050,roc 0.980592, loss 0.044208, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.930996,roc 0.980735, loss 0.044576, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.931774,roc 0.981092, loss 0.044122, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.931266,roc 0.980654, loss 0.044258, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.931497,roc 0.980740, loss 0.044185, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.4823s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.4833s\n",
      "94\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.928302,roc 0.979565, loss 0.045482, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.940334,roc 0.986622, loss 0.037260, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5440], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.934764,roc 0.982606, loss 0.042502, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.932206,roc 0.981417, loss 0.043679, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.932668,roc 0.981375, loss 0.043621, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.932352,roc 0.980961, loss 0.044220, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.932006,roc 0.980891, loss 0.044318, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.3445s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.3455s\n",
      "94\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.930473,roc 0.980083, loss 0.045475, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.942672,roc 0.987141, loss 0.041339, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5344], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.932019,roc 0.981622, loss 0.043549, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.929843,roc 0.980338, loss 0.044418, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.931081,roc 0.980848, loss 0.043841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.932414,roc 0.980980, loss 0.043709, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.932607,roc 0.981056, loss 0.043612, acc 0, ECE 0 #edges 376470, #graphs 94 time: 174.6135s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 174.6151s\n",
      "94\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.930319,roc 0.980076, loss 0.046392, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.944844,roc 0.987797, loss 0.040937, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5670], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.932979,roc 0.981609, loss 0.043293, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.931262,roc 0.981218, loss 0.043779, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.930872,roc 0.980849, loss 0.044042, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.931611,roc 0.980721, loss 0.044222, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.931976,roc 0.980874, loss 0.044022, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.9358s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.9358s\n",
      "94\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.929702,roc 0.979867, loss 0.044757, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.943853,roc 0.987519, loss 0.036773, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5431], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.937452,roc 0.982031, loss 0.042583, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.935577,roc 0.981047, loss 0.043382, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.933202,roc 0.980978, loss 0.043611, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.934177,roc 0.981479, loss 0.043300, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.934027,roc 0.981466, loss 0.043316, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.4658s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.4668s\n",
      "94\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.931763,roc 0.980419, loss 0.044167, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.943387,roc 0.987357, loss 0.037938, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5570], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.938924,roc 0.982515, loss 0.042361, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.936399,roc 0.982529, loss 0.042307, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.936370,roc 0.982534, loss 0.042449, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.935162,roc 0.981856, loss 0.042898, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.935114,roc 0.981781, loss 0.042948, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.7491s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.7491s\n",
      "94\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.929000,roc 0.979554, loss 0.047563, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.942478,roc 0.987071, loss 0.036982, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5391], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.931838,roc 0.981641, loss 0.043025, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.932958,roc 0.981384, loss 0.043615, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.934106,roc 0.981469, loss 0.043548, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.933578,roc 0.981353, loss 0.043439, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.933702,roc 0.981358, loss 0.043412, acc 0, ECE 0 #edges 376470, #graphs 94 time: 175.8379s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 175.8389s\n",
      "94\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.927906,roc 0.979136, loss 0.045145, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.935241,roc 0.985264, loss 0.040671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5619], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.931598,roc 0.980176, loss 0.044244, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.931926,roc 0.981304, loss 0.043816, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.933452,roc 0.981701, loss 0.043004, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.933533,roc 0.981333, loss 0.043249, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.933478,roc 0.981257, loss 0.043547, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.4245s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.4245s\n",
      "94\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.931355,roc 0.980246, loss 0.045348, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.939950,roc 0.986420, loss 0.041686, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5805], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.931032,roc 0.979563, loss 0.046369, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.933611,roc 0.980908, loss 0.044839, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.935178,roc 0.981790, loss 0.043488, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.933956,roc 0.981455, loss 0.043585, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.934231,roc 0.981521, loss 0.043504, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.1653s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.1653s\n",
      "94\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.929642,roc 0.979690, loss 0.044987, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.942843,roc 0.987234, loss 0.038093, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5692], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.940124,roc 0.983005, loss 0.041183, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.936686,roc 0.982093, loss 0.042260, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.936904,roc 0.982011, loss 0.042707, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.935068,roc 0.981657, loss 0.043046, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.934939,roc 0.981680, loss 0.043013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.6403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.6413s\n",
      "94\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.931707,roc 0.980416, loss 0.044062, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.941689,roc 0.986854, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5756], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.932111,roc 0.981520, loss 0.043975, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.931860,roc 0.981273, loss 0.044022, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.934570,roc 0.981586, loss 0.043507, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.934825,roc 0.981688, loss 0.043183, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.934844,roc 0.981674, loss 0.043154, acc 0, ECE 0 #edges 376470, #graphs 94 time: 175.6510s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 175.6510s\n",
      "94\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.931222,roc 0.980189, loss 0.044402, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.945014,roc 0.987798, loss 0.036996, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5727], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.937264,roc 0.981588, loss 0.044556, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.935113,roc 0.981002, loss 0.043944, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.936361,roc 0.981899, loss 0.043206, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.934821,roc 0.981724, loss 0.043002, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.934846,roc 0.981728, loss 0.043028, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.7431s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.7431s\n",
      "94\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.930796,roc 0.979984, loss 0.044959, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.945855,roc 0.987860, loss 0.035872, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5460], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.936245,roc 0.982334, loss 0.042768, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.936509,roc 0.982230, loss 0.042908, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.935433,roc 0.981994, loss 0.042816, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.936353,roc 0.982027, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.935397,roc 0.981892, loss 0.042881, acc 0, ECE 0 #edges 376470, #graphs 94 time: 166.1113s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 166.1123s\n",
      "94\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5577], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.938260,roc 0.983492, loss 0.040722, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.933423,roc 0.981720, loss 0.042746, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.933944,roc 0.981954, loss 0.042814, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.935149,roc 0.981761, loss 0.042801, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.935198,roc 0.981771, loss 0.042825, acc 0, ECE 0 #edges 376470, #graphs 94 time: 167.0609s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 167.0609s\n",
      "94\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.930117,roc 0.979870, loss 0.044789, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.939414,roc 0.986149, loss 0.037456, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5598], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.937162,roc 0.981710, loss 0.043120, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.936743,roc 0.981999, loss 0.042721, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.936038,roc 0.981692, loss 0.042968, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.934857,roc 0.981640, loss 0.042885, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.934945,roc 0.981665, loss 0.042804, acc 0, ECE 0 #edges 376470, #graphs 94 time: 130.5111s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 130.5111s\n",
      "94\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.930535,roc 0.980201, loss 0.045816, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.944617,roc 0.987737, loss 0.035768, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5438], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.939249,roc 0.983306, loss 0.041201, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.935466,roc 0.981752, loss 0.042648, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.936331,roc 0.981920, loss 0.042569, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.935433,roc 0.981802, loss 0.042535, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.935253,roc 0.981862, loss 0.042498, acc 0, ECE 0 #edges 376470, #graphs 94 time: 115.0437s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 115.0447s\n",
      "94\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.928698,roc 0.979129, loss 0.047734, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.936418,roc 0.985521, loss 0.045692, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.6062], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.931898,roc 0.980494, loss 0.044801, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.933224,roc 0.981422, loss 0.043974, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.934948,roc 0.982167, loss 0.042811, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.935449,roc 0.981834, loss 0.043015, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.935359,roc 0.981846, loss 0.042982, acc 0, ECE 0 #edges 376470, #graphs 94 time: 114.3781s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 114.3781s\n",
      "94\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.927580,roc 0.978998, loss 0.047792, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.941843,roc 0.986917, loss 0.036826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5359], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.931428,roc 0.978989, loss 0.044659, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.932449,roc 0.980528, loss 0.043634, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.933959,roc 0.981475, loss 0.042718, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.934760,roc 0.981821, loss 0.042547, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.934716,roc 0.981679, loss 0.042660, acc 0, ECE 0 #edges 376470, #graphs 94 time: 112.8354s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 112.8354s\n",
      "94\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.931150,roc 0.980224, loss 0.044420, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.941901,roc 0.986971, loss 0.036822, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5419], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.933818,roc 0.980390, loss 0.042987, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.934916,roc 0.981549, loss 0.042527, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.935592,roc 0.981871, loss 0.042142, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.935662,roc 0.981876, loss 0.042321, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.935717,roc 0.981925, loss 0.042295, acc 0, ECE 0 #edges 376470, #graphs 94 time: 110.1187s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 110.1197s\n",
      "94\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.931579,roc 0.980424, loss 0.044686, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.944422,roc 0.987746, loss 0.035666, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 6053.8508s\n",
      "INFO:root:Val set results: dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n",
      "INFO:root:Using: cpu\n",
      "INFO:root:Using seed 1234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 22, 'loss': 0.0437703710221931, 'roc': 0.9805947664299266, 'ap': 0.9324662764985167, 'acc': 0.9134163690735417, 'ECE': 0.0}\n",
      "0.0437703710221931 val mets\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 study directory!\n",
      "meg ARG DATASET\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, fermi_freq=-1, fermi_use=0, gamma=0.9, grad_clip=100, hyp_act=False, is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LPModel(\n",
      "  (encoder): HGCN(\n",
      "    (layers): Sequential(\n",
      "      (0): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=91, out_features=6, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (hyp_act): HypAct(\n",
      "          c_in=Parameter containing:\n",
      "          tensor([1.], requires_grad=True), c_out=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "      (1): HyperbolicGraphConvolution(\n",
      "        (linear): HypLinear(\n",
      "          in_features=6, out_features=3, c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "        (agg): HypAgg(\n",
      "          c=Parameter containing:\n",
      "          tensor([1.], requires_grad=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dc): FermiDiracDecoder()\n",
      ")\n",
      "INFO:root:Total number of parameters: 578.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "-1 ARG FREQ\n",
      "[91, 6] dims\n",
      "[91, 6, 3] dims after\n",
      "[91, 6, 3] dims\n",
      "[<function selu at 0x0000025EBF108F78>, <function selu at 0x0000025EBF108F78>] acts\n",
      "[True, False] uise acts\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "gn NORMAL TYPE\n",
      "True USE AGG\n",
      "frechet agg True\n",
      "no pruner\n",
      "no trial\n",
      "FermiDiracDecoder()\n",
      "Parameter containing:\n",
      "tensor(1., requires_grad=True) t\n",
      "<generator object Module.parameters at 0x0000025E86B4FE48>\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 0 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True) MODEL C\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 0: precision 0.671630,roc 0.891829, loss 0.139282, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 0: precision 0.729332,roc 0.916978, loss 0.108898, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 0: precision 0.766206,roc 0.930656, loss 0.093883, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 0: precision 0.792186,roc 0.939968, loss 0.084392, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0001 lr: 0.021 train phase of epoch 0: precision 0.794460,roc 0.940612, loss 0.083729, acc 0, ECE 0 #edges 376470, #graphs 94 time: 143.9539s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 143.9554s\n",
      "94\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n",
      "86\n",
      "0.055158991847515416 0.8965885666173098 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0001 dev phase of epoch 0: precision 0.880277,roc 0.968807, loss 0.055159, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0001 test phase of epoch 0: precision 0.875916,roc 0.974972, loss 0.052003, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 1 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.9601], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 1: precision 0.883635,roc 0.968241, loss 0.056408, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 1: precision 0.892244,roc 0.971220, loss 0.053569, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 1: precision 0.896914,roc 0.972899, loss 0.051688, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 1: precision 0.900342,roc 0.973557, loss 0.051493, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0002 lr: 0.021 train phase of epoch 1: precision 0.900449,roc 0.973607, loss 0.051404, acc 0, ECE 0 #edges 376470, #graphs 94 time: 137.1687s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 137.1687s\n",
      "94\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n",
      "86\n",
      "0.05092577622468199 0.919986644601225 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0002 dev phase of epoch 1: precision 0.911088,roc 0.975541, loss 0.050926, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0002 test phase of epoch 1: precision 0.921168,roc 0.983459, loss 0.047355, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 2 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.6995], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 2: precision 0.908931,roc 0.976678, loss 0.049663, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 2: precision 0.913676,roc 0.976629, loss 0.049291, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 2: precision 0.916450,roc 0.977051, loss 0.049160, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 2: precision 0.915941,roc 0.976959, loss 0.048572, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0003 lr: 0.021 train phase of epoch 2: precision 0.916062,roc 0.976995, loss 0.048472, acc 0, ECE 0 #edges 376470, #graphs 94 time: 136.0921s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 136.0931s\n",
      "94\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n",
      "86\n",
      "0.048204388246102264 0.8936881224051333 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0003 dev phase of epoch 2: precision 0.919609,roc 0.977378, loss 0.048204, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0003 test phase of epoch 2: precision 0.932831,roc 0.985469, loss 0.038421, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 3 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5776], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 3: precision 0.919102,roc 0.978162, loss 0.047595, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 3: precision 0.920569,roc 0.978796, loss 0.047946, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 3: precision 0.920169,roc 0.978220, loss 0.047490, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 3: precision 0.922422,roc 0.978612, loss 0.046780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0004 lr: 0.021 train phase of epoch 3: precision 0.922312,roc 0.978452, loss 0.047030, acc 0, ECE 0 #edges 376470, #graphs 94 time: 133.3404s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 133.3414s\n",
      "94\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n",
      "86\n",
      "0.047767026504556616 0.9245361902273322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0004 dev phase of epoch 3: precision 0.924732,roc 0.978791, loss 0.047767, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0004 test phase of epoch 3: precision 0.940509,roc 0.986835, loss 0.045662, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 4 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5723], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 4: precision 0.925256,roc 0.979590, loss 0.044650, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 4: precision 0.925834,roc 0.979645, loss 0.045557, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 4: precision 0.926080,roc 0.979725, loss 0.045511, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 4: precision 0.926051,roc 0.979384, loss 0.045930, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0005 lr: 0.021 train phase of epoch 4: precision 0.926111,roc 0.979453, loss 0.045837, acc 0, ECE 0 #edges 376470, #graphs 94 time: 107.9119s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 107.9119s\n",
      "94\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n",
      "86\n",
      "0.045467089786048874 0.9126527886653311 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0005 dev phase of epoch 4: precision 0.926024,roc 0.979138, loss 0.045467, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0005 test phase of epoch 4: precision 0.935971,roc 0.985705, loss 0.040673, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 5 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5111], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 5: precision 0.933000,roc 0.980998, loss 0.043194, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 5: precision 0.927107,roc 0.979603, loss 0.045642, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 5: precision 0.927102,roc 0.979301, loss 0.045922, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 5: precision 0.927157,roc 0.979600, loss 0.045780, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0006 lr: 0.021 train phase of epoch 5: precision 0.927337,roc 0.979635, loss 0.045737, acc 0, ECE 0 #edges 376470, #graphs 94 time: 108.1808s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 108.1808s\n",
      "94\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n",
      "86\n",
      "0.04548110436071867 0.912069215805824 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0006 dev phase of epoch 5: precision 0.926450,roc 0.978878, loss 0.045481, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0006 test phase of epoch 5: precision 0.934554,roc 0.985150, loss 0.040826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 6 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5272], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 6: precision 0.931087,roc 0.979764, loss 0.044553, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 6: precision 0.929970,roc 0.979889, loss 0.045021, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 6: precision 0.928904,roc 0.979985, loss 0.044841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 6: precision 0.930325,roc 0.980492, loss 0.044651, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0007 lr: 0.021 train phase of epoch 6: precision 0.930251,roc 0.980491, loss 0.044724, acc 0, ECE 0 #edges 376470, #graphs 94 time: 120.1100s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 120.1260s\n",
      "94\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n",
      "86\n",
      "0.046171187625035984 0.9226228841854662 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0007 dev phase of epoch 6: precision 0.927383,roc 0.979228, loss 0.046171, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0007 test phase of epoch 6: precision 0.935883,roc 0.985460, loss 0.045299, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 7 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5544], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 7: precision 0.926801,roc 0.979847, loss 0.046055, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 7: precision 0.926795,roc 0.979361, loss 0.045870, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 7: precision 0.928499,roc 0.979813, loss 0.045442, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 7: precision 0.929911,roc 0.980272, loss 0.044923, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0008 lr: 0.021 train phase of epoch 7: precision 0.929824,roc 0.980294, loss 0.044858, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.4272s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.4282s\n",
      "94\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n",
      "86\n",
      "0.04584780339750832 0.8992567430247075 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0008 dev phase of epoch 7: precision 0.929021,roc 0.979452, loss 0.045848, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0008 test phase of epoch 7: precision 0.940898,roc 0.986558, loss 0.037853, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 8 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5341], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 8: precision 0.929918,roc 0.980228, loss 0.043967, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 8: precision 0.930286,roc 0.980094, loss 0.044785, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 8: precision 0.931247,roc 0.980609, loss 0.044406, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 8: precision 0.931715,roc 0.980664, loss 0.044045, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0009 lr: 0.021 train phase of epoch 8: precision 0.931468,roc 0.980650, loss 0.044082, acc 0, ECE 0 #edges 376470, #graphs 94 time: 109.9932s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 109.9942s\n",
      "94\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n",
      "86\n",
      "0.04657036249696085 0.8947130040937201 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0009 dev phase of epoch 8: precision 0.928308,roc 0.979352, loss 0.046570, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0009 test phase of epoch 8: precision 0.940079,roc 0.986428, loss 0.037076, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 9 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5372], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 9: precision 0.933569,roc 0.980816, loss 0.045062, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 9: precision 0.932375,roc 0.980824, loss 0.044440, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 9: precision 0.932745,roc 0.980853, loss 0.044193, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 9: precision 0.932086,roc 0.980914, loss 0.044177, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0010 lr: 0.021 train phase of epoch 9: precision 0.932090,roc 0.980908, loss 0.044262, acc 0, ECE 0 #edges 376470, #graphs 94 time: 109.9268s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 109.9278s\n",
      "94\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n",
      "86\n",
      "0.04445654420573911 0.9166332781697301 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0010 dev phase of epoch 9: precision 0.929072,roc 0.979929, loss 0.044457, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0010 test phase of epoch 9: precision 0.941326,roc 0.987007, loss 0.038693, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 10 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5257], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 10: precision 0.932050,roc 0.980592, loss 0.044208, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 10: precision 0.930996,roc 0.980735, loss 0.044576, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 10: precision 0.931774,roc 0.981092, loss 0.044122, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 10: precision 0.931266,roc 0.980654, loss 0.044258, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0011 lr: 0.021 train phase of epoch 10: precision 0.931497,roc 0.980740, loss 0.044185, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.0895s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.0905s\n",
      "94\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n",
      "86\n",
      "0.04548150063631076 0.9020671834625322 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0011 dev phase of epoch 10: precision 0.928302,roc 0.979565, loss 0.045482, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0011 test phase of epoch 10: precision 0.940334,roc 0.986622, loss 0.037260, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 11 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5440], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 11: precision 0.934764,roc 0.982606, loss 0.042502, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 11: precision 0.932206,roc 0.981417, loss 0.043679, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 11: precision 0.932668,roc 0.981375, loss 0.043621, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 11: precision 0.932352,roc 0.980961, loss 0.044220, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0012 lr: 0.021 train phase of epoch 11: precision 0.932006,roc 0.980891, loss 0.044318, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.1291s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.1301s\n",
      "94\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n",
      "86\n",
      "0.04547472691380083 0.925201056818512 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0012 dev phase of epoch 11: precision 0.930473,roc 0.980083, loss 0.045475, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0012 test phase of epoch 11: precision 0.942672,roc 0.987141, loss 0.041339, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 12 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5344], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 12: precision 0.932019,roc 0.981622, loss 0.043549, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 12: precision 0.929843,roc 0.980338, loss 0.044418, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 12: precision 0.931081,roc 0.980848, loss 0.043841, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 12: precision 0.932414,roc 0.980980, loss 0.043709, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0013 lr: 0.021 train phase of epoch 12: precision 0.932607,roc 0.981056, loss 0.043612, acc 0, ECE 0 #edges 376470, #graphs 94 time: 120.8586s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 120.8596s\n",
      "94\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n",
      "86\n",
      "0.046392108616583716 0.926417559446041 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0013 dev phase of epoch 12: precision 0.930319,roc 0.980076, loss 0.046392, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0013 test phase of epoch 12: precision 0.944844,roc 0.987797, loss 0.040937, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 13 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5670], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 13: precision 0.932979,roc 0.981609, loss 0.043293, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 13: precision 0.931262,roc 0.981218, loss 0.043779, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 13: precision 0.930872,roc 0.980849, loss 0.044042, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 13: precision 0.931611,roc 0.980721, loss 0.044222, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0014 lr: 0.021 train phase of epoch 13: precision 0.931976,roc 0.980874, loss 0.044022, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.4942s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.4942s\n",
      "94\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n",
      "86\n",
      "0.044757029246802686 0.9091513515082896 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0014 dev phase of epoch 13: precision 0.929702,roc 0.979867, loss 0.044757, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0014 test phase of epoch 13: precision 0.943853,roc 0.987519, loss 0.036773, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 14 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5431], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 14: precision 0.937452,roc 0.982031, loss 0.042583, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 14: precision 0.935577,roc 0.981047, loss 0.043382, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 14: precision 0.933202,roc 0.980978, loss 0.043611, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 14: precision 0.934177,roc 0.981479, loss 0.043300, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0015 lr: 0.021 train phase of epoch 14: precision 0.934027,roc 0.981466, loss 0.043316, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.4750s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.4760s\n",
      "94\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n",
      "86\n",
      "0.04416652526589044 0.9157013036030542 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0015 dev phase of epoch 14: precision 0.931763,roc 0.980419, loss 0.044167, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0015 test phase of epoch 14: precision 0.943387,roc 0.987357, loss 0.037938, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 15 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5570], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 15: precision 0.938924,roc 0.982515, loss 0.042361, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 15: precision 0.936399,roc 0.982529, loss 0.042307, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 15: precision 0.936370,roc 0.982534, loss 0.042449, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 15: precision 0.935162,roc 0.981856, loss 0.042898, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0016 lr: 0.021 train phase of epoch 15: precision 0.935114,roc 0.981781, loss 0.042948, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.4302s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.4312s\n",
      "94\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n",
      "86\n",
      "0.047562704734594216 0.8870568765786954 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0016 dev phase of epoch 15: precision 0.929000,roc 0.979554, loss 0.047563, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0016 test phase of epoch 15: precision 0.942478,roc 0.987071, loss 0.036982, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 16 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5391], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 16: precision 0.931838,roc 0.981641, loss 0.043025, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 16: precision 0.932958,roc 0.981384, loss 0.043615, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 16: precision 0.934106,roc 0.981469, loss 0.043548, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 16: precision 0.933578,roc 0.981353, loss 0.043439, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0017 lr: 0.021 train phase of epoch 16: precision 0.933702,roc 0.981358, loss 0.043412, acc 0, ECE 0 #edges 376470, #graphs 94 time: 112.4737s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 112.4747s\n",
      "94\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n",
      "86\n",
      "0.045145384515678594 0.9153325784629676 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0017 dev phase of epoch 16: precision 0.927906,roc 0.979136, loss 0.045145, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0017 test phase of epoch 16: precision 0.935241,roc 0.985264, loss 0.040671, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 17 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5619], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 17: precision 0.931598,roc 0.980176, loss 0.044244, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 17: precision 0.931926,roc 0.981304, loss 0.043816, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 17: precision 0.933452,roc 0.981701, loss 0.043004, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 17: precision 0.933533,roc 0.981333, loss 0.043249, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0018 lr: 0.021 train phase of epoch 17: precision 0.933478,roc 0.981257, loss 0.043547, acc 0, ECE 0 #edges 376470, #graphs 94 time: 110.8462s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 110.8462s\n",
      "94\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n",
      "86\n",
      "0.045347839752643046 0.9246320006968034 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0018 dev phase of epoch 17: precision 0.931355,roc 0.980246, loss 0.045348, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0018 test phase of epoch 17: precision 0.939950,roc 0.986420, loss 0.041686, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 18 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5805], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 18: precision 0.931032,roc 0.979563, loss 0.046369, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 18: precision 0.933611,roc 0.980908, loss 0.044839, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 18: precision 0.935178,roc 0.981790, loss 0.043488, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 18: precision 0.933956,roc 0.981455, loss 0.043585, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0019 lr: 0.021 train phase of epoch 18: precision 0.934231,roc 0.981521, loss 0.043504, acc 0, ECE 0 #edges 376470, #graphs 94 time: 115.3516s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 115.3516s\n",
      "94\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n",
      "86\n",
      "0.044987151429457015 0.9174287954010973 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0019 dev phase of epoch 18: precision 0.929642,roc 0.979690, loss 0.044987, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0019 test phase of epoch 18: precision 0.942843,roc 0.987234, loss 0.038093, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 19 LR:  [0.021]\n",
      "Parameter containing:\n",
      "tensor([0.5692], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 19: precision 0.940124,roc 0.983005, loss 0.041183, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 19: precision 0.936686,roc 0.982093, loss 0.042260, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 19: precision 0.936904,roc 0.982011, loss 0.042707, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 19: precision 0.935068,roc 0.981657, loss 0.043046, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0020 lr: 0.021 train phase of epoch 19: precision 0.934939,roc 0.981680, loss 0.043013, acc 0, ECE 0 #edges 376470, #graphs 94 time: 112.2702s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 112.2702s\n",
      "94\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n",
      "86\n",
      "0.04406237787543101 0.912507621287344 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0020 dev phase of epoch 19: precision 0.931707,roc 0.980416, loss 0.044062, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0020 test phase of epoch 19: precision 0.941689,roc 0.986854, loss 0.037671, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 20 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5756], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 20: precision 0.932111,roc 0.981520, loss 0.043975, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 20: precision 0.931860,roc 0.981273, loss 0.044022, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 20: precision 0.934570,roc 0.981586, loss 0.043507, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 20: precision 0.934825,roc 0.981688, loss 0.043183, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0021 lr: 0.0189 train phase of epoch 20: precision 0.934844,roc 0.981674, loss 0.043154, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.1877s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.2047s\n",
      "94\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n",
      "86\n",
      "0.04440215605906903 0.9171936242487589 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0021 dev phase of epoch 20: precision 0.931222,roc 0.980189, loss 0.044402, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0021 test phase of epoch 20: precision 0.945014,roc 0.987798, loss 0.036996, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 21 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5727], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 21: precision 0.937264,roc 0.981588, loss 0.044556, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 21: precision 0.935113,roc 0.981002, loss 0.043944, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 21: precision 0.936361,roc 0.981899, loss 0.043206, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 21: precision 0.934821,roc 0.981724, loss 0.043002, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0022 lr: 0.0189 train phase of epoch 21: precision 0.934846,roc 0.981728, loss 0.043028, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.0502s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.0502s\n",
      "94\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n",
      "86\n",
      "0.04495865714132514 0.9048747205527974 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0022 dev phase of epoch 21: precision 0.930796,roc 0.979984, loss 0.044959, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0022 test phase of epoch 21: precision 0.945855,roc 0.987860, loss 0.035872, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 22 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5460], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 22: precision 0.936245,roc 0.982334, loss 0.042768, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 22: precision 0.936509,roc 0.982230, loss 0.042908, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 22: precision 0.935433,roc 0.981994, loss 0.042816, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 22: precision 0.936353,roc 0.982027, loss 0.042715, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0023 lr: 0.0189 train phase of epoch 22: precision 0.935397,roc 0.981892, loss 0.042881, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.5358s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.5378s\n",
      "94\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n",
      "86\n",
      "0.0437703710221931 0.9134163690735417 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0023 dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0023 test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 23 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5577], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 23: precision 0.938260,roc 0.983492, loss 0.040722, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 23: precision 0.933423,roc 0.981720, loss 0.042746, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 23: precision 0.933944,roc 0.981954, loss 0.042814, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 23: precision 0.935149,roc 0.981761, loss 0.042801, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0024 lr: 0.0189 train phase of epoch 23: precision 0.935198,roc 0.981771, loss 0.042825, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.2639s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.2639s\n",
      "94\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n",
      "86\n",
      "0.0447889472051424 0.9073019191127367 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0024 dev phase of epoch 23: precision 0.930117,roc 0.979870, loss 0.044789, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0024 test phase of epoch 23: precision 0.939414,roc 0.986149, loss 0.037456, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 24 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5598], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 24: precision 0.937162,roc 0.981710, loss 0.043120, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 24: precision 0.936743,roc 0.981999, loss 0.042721, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 24: precision 0.936038,roc 0.981692, loss 0.042968, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 24: precision 0.934857,roc 0.981640, loss 0.042885, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0025 lr: 0.0189 train phase of epoch 24: precision 0.934945,roc 0.981665, loss 0.042804, acc 0, ECE 0 #edges 376470, #graphs 94 time: 113.4110s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 113.4110s\n",
      "94\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n",
      "86\n",
      "0.045816203020897416 0.894582353453532 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0025 dev phase of epoch 24: precision 0.930535,roc 0.980201, loss 0.045816, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0025 test phase of epoch 24: precision 0.944617,roc 0.987737, loss 0.035768, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 25 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5438], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 25: precision 0.939249,roc 0.983306, loss 0.041201, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 25: precision 0.935466,roc 0.981752, loss 0.042648, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 25: precision 0.936331,roc 0.981920, loss 0.042569, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 25: precision 0.935433,roc 0.981802, loss 0.042535, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0026 lr: 0.0189 train phase of epoch 25: precision 0.935253,roc 0.981862, loss 0.042498, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.6981s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.6981s\n",
      "94\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n",
      "86\n",
      "0.04773402830217668 0.9262056150741806 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0026 dev phase of epoch 25: precision 0.928698,roc 0.979129, loss 0.047734, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0026 test phase of epoch 25: precision 0.936418,roc 0.985521, loss 0.045692, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 26 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.6062], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 26: precision 0.931898,roc 0.980494, loss 0.044801, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 26: precision 0.933224,roc 0.981422, loss 0.043974, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 26: precision 0.934948,roc 0.982167, loss 0.042811, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 26: precision 0.935449,roc 0.981834, loss 0.043015, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0027 lr: 0.0189 train phase of epoch 26: precision 0.935359,roc 0.981846, loss 0.042982, acc 0, ECE 0 #edges 376470, #graphs 94 time: 110.9537s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 110.9537s\n",
      "94\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n",
      "86\n",
      "0.047791515963177565 0.8875765757918882 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0027 dev phase of epoch 26: precision 0.927580,roc 0.978998, loss 0.047792, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0027 test phase of epoch 26: precision 0.941843,roc 0.986917, loss 0.036826, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 27 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5359], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 27: precision 0.931428,roc 0.978989, loss 0.044659, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 27: precision 0.932449,roc 0.980528, loss 0.043634, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 27: precision 0.933959,roc 0.981475, loss 0.042718, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 27: precision 0.934760,roc 0.981821, loss 0.042547, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0028 lr: 0.0189 train phase of epoch 27: precision 0.934716,roc 0.981679, loss 0.042660, acc 0, ECE 0 #edges 376470, #graphs 94 time: 111.2037s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 111.2037s\n",
      "94\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n",
      "86\n",
      "0.044419753808507385 0.9084545480939521 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0028 dev phase of epoch 27: precision 0.931150,roc 0.980224, loss 0.044420, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0028 test phase of epoch 27: precision 0.941901,roc 0.986971, loss 0.036822, acc 0, ECE 0 #edges 8010, #graphs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.0 1.0 FERMI (non-adjusting) epoch: 28 LR:  [0.0189]\n",
      "Parameter containing:\n",
      "tensor([0.5419], requires_grad=True) MODEL C\n",
      "2\n",
      "reset\n",
      "94 train length\n",
      "23\n",
      "train phase of epoch 28: precision 0.933818,roc 0.980390, loss 0.042987, acc 0, ECE 0 #edges 92115, #graphs 23\n",
      "46\n",
      "train phase of epoch 28: precision 0.934916,roc 0.981549, loss 0.042527, acc 0, ECE 0 #edges 184230, #graphs 46\n",
      "69\n",
      "train phase of epoch 28: precision 0.935592,roc 0.981871, loss 0.042142, acc 0, ECE 0 #edges 276345, #graphs 69\n",
      "92\n",
      "train phase of epoch 28: precision 0.935662,roc 0.981876, loss 0.042321, acc 0, ECE 0 #edges 368460, #graphs 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 0029 lr: 0.0189 train phase of epoch 28: precision 0.935717,roc 0.981925, loss 0.042295, acc 0, ECE 0 #edges 376470, #graphs 94 time: 110.4466s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "training epoch done in  time: 110.4476s\n",
      "94\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n",
      "86\n",
      "0.04468612777098392 0.9023981650843425 loss acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dev Epoch: 0029 dev phase of epoch 28: precision 0.931579,roc 0.980424, loss 0.044686, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test Epoch: 0029 test phase of epoch 28: precision 0.944422,roc 0.987746, loss 0.035666, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Early stopping\n",
      "INFO:root:Optimization Finished!\n",
      "INFO:root:Total time elapsed: 4379.1874s\n",
      "INFO:root:Val set results: dev phase of epoch 22: precision 0.932466,roc 0.980595, loss 0.043770, acc 0, ECE 0 #edges 344430, #graphs 86\n",
      "INFO:root:Test set results: test phase of epoch 22: precision 0.942251,roc 0.987042, loss 0.037135, acc 0, ECE 0 #edges 8010, #graphs 2\n",
      "INFO:root:Saved model in C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'prefix': 'dev', 'epoch': 22, 'loss': 0.0437703710221931, 'roc': 0.9805947664299266, 'ap': 0.9324662764985167, 'acc': 0.9134163690735417, 'ECE': 0.0}\n",
      "0.0437703710221931 val mets\n",
      "FOLDERS\n",
      "['0', '1', '2']\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\0', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\0', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B508>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B548>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B588>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B508>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B548>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9B13B588>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\scan_info.csv\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\1', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\1', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n",
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF12C8>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF1308>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF1348>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF12C8>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF1308>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACF1348>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\scan_info.csv\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0)\n",
      "in here \n",
      "graph DATA NAME\n",
      "Names            ['Left Precentral gyrus']\n",
      "Nicknames                       ['lPreCG']\n",
      "Index                                    0\n",
      "X                                 -0.03893\n",
      "Y                                -0.006961\n",
      "Z                                  0.04964\n",
      "Source Count                            32\n",
      "DMN Pct                                0.0\n",
      "pDMN Pct                               0.0\n",
      "aDMN Pct                               0.0\n",
      "DAN Pct                             0.3125\n",
      "FPN Pct                            0.09375\n",
      "VN Pct                                 0.0\n",
      "VAN Pct                             0.5625\n",
      "SN Pct                                 0.0\n",
      "SMN Pct                             0.1875\n",
      "DMN Rank                                37\n",
      "pDMN Rank                               26\n",
      "aDMN Rank                               13\n",
      "DAN Rank                                 8\n",
      "FPN Rank                                29\n",
      "VN Rank                                 19\n",
      "VAN Rank                                 3\n",
      "SN Rank                                 23\n",
      "SMN Rank                                 8\n",
      "RoiID                                  0_r\n",
      "node_index                               0\n",
      "BalancedName             Precentralgyrus']\n",
      "pDMN Pct Bal                           0.0\n",
      "aDMN Pct Bal                           0.0\n",
      "DAN Pct Bal                       0.322917\n",
      "FPN Pct Bal                        0.23206\n",
      "VN Pct Bal                             0.0\n",
      "VAN Pct Bal                       0.503472\n",
      "SN Pct Bal                             0.0\n",
      "SMN Pct Bal                       0.149306\n",
      "pDMN Rank Bal                           29\n",
      "aDMN Rank Bal                           15\n",
      "DAN Rank Bal                             5\n",
      "FPN Rank Bal                            17\n",
      "VN Rank Bal                             21\n",
      "VAN Rank Bal                             3\n",
      "SN Rank Bal                             27\n",
      "SMN Rank Bal                             7\n",
      "Name: 0, dtype: object\n",
      "    Index         X         Y         Z\n",
      "0       0 -0.038930 -0.006961  0.049640\n",
      "1       1  0.041101 -0.009550  0.050810\n",
      "2       2 -0.018773  0.033490  0.040954\n",
      "3       3  0.021603  0.029910  0.042504\n",
      "4       4 -0.016825  0.045919 -0.014719\n",
      "..    ...       ...       ...       ...\n",
      "85     85  0.057160 -0.038566 -0.002775\n",
      "86     86 -0.036744  0.013301 -0.035367\n",
      "87     87  0.044040  0.013247 -0.033518\n",
      "88     88 -0.050036 -0.029292 -0.024519\n",
      "89     89  0.053382 -0.032139 -0.023731\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "Namespace(act='selu', adj_threshold=0.329, all_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_all_MEG_0.329.json', alpha=0.2, band='alpha', batch_size=8, bias=1, c=None, criteria_dict={'CogTr': 1}, cuda=0, currently_training=False, data_root='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG', dataset='meg', dev_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_valid_MEG_0.329.json', device='cpu', dim=6, distributed_method='None', double_precision=1, dropout=0, edge_type=-1, epochs=80, eval_freq=2, feat_dim=91, fermi_freq=-1, fermi_use=0, frech_B_dict={}, frech_B_list=[], frechet_B=91, gamma=0.9, grad_clip=100, hyp_act=False, idxs_dict={'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]}, indx_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_MEG_0.329_latestindx.json', is_inductive=1, is_regression=0, local_agg=0, local_rank=None, log_freq=5, lr=0.021, lr_reduce_freq=20, manifold='PoincareBall', max_per_epoch=-1, metric='plv', min_epochs=2, model='HGCN', momentum=0.999, n_classes=2, n_heads=2, name='2023_03_09_11_06_01_198858', normalization=0, normalize_adj=1, normalize_feats=1, normalize_id_treatment='raw', num_feature=91, num_layers=2, optimizer='RiemannianAdam', output_act=None, output_agg=True, output_dim=3, patience=6, pos_weight=0, pretrained_embeddings=None, print_epoch=True, prop_idx=0, r=2, raw_atlas_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/AALtemplate_balanced.csv', raw_clinical_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.clinical.csv', raw_scan_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG/MEG.ROIs.npy', refresh_data=1, save=1, save_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2', save_id='', save_model=False, seed=1234, split_seed=1234, stretch_loss=95, stretch_pct=95, study_dir='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8', sweep_c=0, t=1, task='lp', test_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_test_MEG_0.329.json', test_prop=0.01, train_file='C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\data/MEG\\\\meg_train_MEG_0.329.json', train_noise_level=0.01, train_noise_num=0, train_noise_prob=0.5, train_only=0, use_att=0, use_batch=0, use_beta=0, use_ciplv=0, use_coords=0, use_degree=0, use_feats=1, use_frechet_agg=1, use_identity=0, use_norm=0, use_plv=1, use_pretrained=0, use_region=0, use_val=1, use_virtual=1, use_volume=0, use_weight=True, use_weighted_loss=1, val_prop=0.2, val_sub=1, weight_decay=0.0) ARGS\n",
      "reading data...\n",
      "False USE EXCLUDE\n",
      "1 USE Val\n",
      "SUB GROUP\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n",
      "(88, 64)\n",
      "(92, 64)\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] VALID INDEX\n",
      "\n",
      "\n",
      " now\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "92 86 2 lengths\n",
      "180 unique lenths\n",
      "94 86 2 lengths after add test to train\n",
      "180 Cinical shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} DICT\n",
      "94 2 86 length\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} index me\n",
      "(180, 90, 90) RIGHTOUT DATA\n",
      "0.3309338126375074 80\n",
      "0.32764641825358093 79\n",
      "0.32456669569015506 78\n",
      "0.316118533987748 75\n",
      "0.34999029636383056 85\n",
      "dict_keys(['mm_strech', 'ms_norm', 'identity', 'add_noise', 'pca_transform']) keys\n",
      "parsing scans as graphs...\n",
      "0.9092297727387129 new standard\n",
      "-0.1811374533330851 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "0.8646270454984698 new standard\n",
      "-0.2442406948795043 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "535\n",
      "0.9785014624547117 new standard\n",
      "0.031826183271803386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "801\n",
      "0.9706735082258283 new standard\n",
      "0.023199741496544034 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "1.0093352598062335 new standard\n",
      "0.12432307130148496 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9379439837131297 new standard\n",
      "-0.0810079259947177 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "670\n",
      "1.0407009675795544 new standard\n",
      "0.04494108232744479 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "879\n",
      "1.0063859679200218 new standard\n",
      "-0.027681833944268337 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "1.0472690330241727 new standard\n",
      "-0.013822756049024578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "842\n",
      "1.0238731519989963 new standard\n",
      "-0.03443549171613136 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.019546661133258 new standard\n",
      "0.14236841830020766 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "936\n",
      "1.069920683647229 new standard\n",
      "0.07620973164827574 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "875\n",
      "1.0301969878797297 new standard\n",
      "-0.21628940667608101 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "629\n",
      "0.9768840108535556 new standard\n",
      "-0.2223481528631915 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "606\n",
      "1.0101376812646923 new standard\n",
      "0.0332657695011596 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.001487926538489 new standard\n",
      "0.0061323299778354885 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "0.8929927097612052 new standard\n",
      "-0.04740354115872966 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "0.9479306366508965 new standard\n",
      "0.0011479075472369672 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "719\n",
      "0.996782072847683 new standard\n",
      "-0.005283957027782085 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "776\n",
      "0.98351809451723 new standard\n",
      "0.011957098262920327 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "798\n",
      "0.970750978030027 new standard\n",
      "-0.048194537669841955 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "745\n",
      "1.0144843097714553 new standard\n",
      "-0.05098809348901711 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "743\n",
      "0.9801579906113378 new standard\n",
      "-0.1554983040495631 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "646\n",
      "1.0183939887715212 new standard\n",
      "-0.05952872459682859 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "775\n",
      "1.0580418378367984 new standard\n",
      "0.03347706009790587 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0305137255588281 new standard\n",
      "0.032636727737185386 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "880\n",
      "1.055282336240629 new standard\n",
      "0.041288660366966684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0393955518328046 new standard\n",
      "0.030625111915013246 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0081931053116127 new standard\n",
      "-0.09636824496505161 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "757\n",
      "0.9060634298790643 new standard\n",
      "-0.2509472824946094 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "537\n",
      "1.0308276553025806 new standard\n",
      "0.1660867177933505 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "958\n",
      "0.978961926294935 new standard\n",
      "0.15653742608027987 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0162950247239226 new standard\n",
      "-0.10628920123454888 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "0.982116154849723 new standard\n",
      "-0.1266007682110595 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "675\n",
      "1.0567365821802654 new standard\n",
      "0.11304661434900602 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "844\n",
      "1.0346985201714334 new standard\n",
      "0.16948365043647007 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "955\n",
      "1.0108997316264121 new standard\n",
      "0.04957905335441075 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.0005626361337954 new standard\n",
      "0.03341713700632601 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "827\n",
      "1.0150879215032103 new standard\n",
      "0.12745809652529502 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.030287537571438 new standard\n",
      "0.21641621583575213 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "978\n",
      "0.9653457462456264 new standard\n",
      "-0.03709184328770149 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "768\n",
      "0.9943998167842109 new standard\n",
      "0.1159397560972421 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "931\n",
      "0.9607632415634426 new standard\n",
      "0.08117599697748222 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "868\n",
      "0.9937631997867223 new standard\n",
      "0.09547327796011003 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "861\n",
      "0.9611099986254018 new standard\n",
      "-0.1565225922903988 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "642\n",
      "0.9717407424337116 new standard\n",
      "-0.12607182412169238 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "671\n",
      "1.0030837857732373 new standard\n",
      "-0.008326141634326266 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "0.9822759578281333 new standard\n",
      "-0.020938145862439812 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "1.0332044970474852 new standard\n",
      "0.23279836652626512 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9120658392053763 new standard\n",
      "-0.07455560194639019 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "0.9765099367631486 new standard\n",
      "0.06849173845783794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "851\n",
      "0.9994779247736818 new standard\n",
      "-0.02744305524359765 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9850342617435395 new standard\n",
      "0.006658444364167538 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "791\n",
      "0.9947008325175134 new standard\n",
      "0.06081144347067954 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9523045836421433 new standard\n",
      "0.08287235148740657 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "788\n",
      "0.9661209119511777 new standard\n",
      "-0.012434400105012806 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "0.9960618115563692 new standard\n",
      "0.15440889043190273 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "877\n",
      "1.0116515092961105 new standard\n",
      "0.28467225427225856 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1135\n",
      "1.0203262399674258 new standard\n",
      "0.08160476311653554 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "1.0336992621081789 new standard\n",
      "0.06438931114957709 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "1.0756018739789066 new standard\n",
      "0.06182738623797306 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "866\n",
      "1.010497779943612 new standard\n",
      "0.03258751411136219 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0097307020947717 new standard\n",
      "-0.04169153980890757 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "754\n",
      "1.0536792731697595 new standard\n",
      "0.12925030675687926 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "943\n",
      "0.9682324835819338 new standard\n",
      "-0.018926692977606997 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "750\n",
      "0.9760477081885651 new standard\n",
      "-0.07883133840644344 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "700\n",
      "1.1006871328247403 new standard\n",
      "0.17476506135539452 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1051\n",
      "1.0920418876238762 new standard\n",
      "0.07417822338440071 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0091441662714957 new standard\n",
      "-0.15503073413291618 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "655\n",
      "1.0248664600841668 new standard\n",
      "-0.13203437656298173 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "688\n",
      "1.0535819305918936 new standard\n",
      "0.05014056664111156 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "832\n",
      "1.0633857983805861 new standard\n",
      "0.23049671456773022 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1061\n",
      "1.1148124741569534 new standard\n",
      "0.2629520166717638 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1143\n",
      "1.059024722833291 new standard\n",
      "0.1275187597403194 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "917\n",
      "1.1162528861325929 new standard\n",
      "0.0474306932883651 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "853\n",
      "1.1110306217776278 new standard\n",
      "0.056748194581184096 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "856\n",
      "1.0105337782104284 new standard\n",
      "0.03458741978118298 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "773\n",
      "1.0023413408216144 new standard\n",
      "0.09997722790111463 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "865\n",
      "1.0754685025112856 new standard\n",
      "0.3150236429862767 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1208\n",
      "1.0498452817820154 new standard\n",
      "0.11779412388058917 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "0.9908249804758774 new standard\n",
      "0.06316531009841515 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "0.9791472312246202 new standard\n",
      "-0.0300147232185239 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "769\n",
      "0.9056074377073795 new standard\n",
      "0.14785989173438252 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "862\n",
      "0.8671744339709007 new standard\n",
      "0.02964359063788442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "0.9887967990316481 new standard\n",
      "-0.033645661854955884 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "786\n",
      "1.048368050716384 new standard\n",
      "-0.012663617098782503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "826\n",
      "1.0218546235650454 new standard\n",
      "0.197495861844412 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "974\n",
      "1.0607172527271291 new standard\n",
      "0.20774441299973062 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "983\n",
      "1.0111896477814968 new standard\n",
      "0.023923579244375485 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "1.0118978421970084 new standard\n",
      "0.1185066016482186 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.0087561811634043 new standard\n",
      "-0.03579563951182526 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "815\n",
      "0.9748544717385463 new standard\n",
      "-0.1512823306722081 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "640\n",
      "train: 100 %      \n",
      "1.0125972124563805 new standard\n",
      "0.007268004804833867 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "790\n",
      "1.0377718685550228 new standard\n",
      "0.06267408419545599 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "847\n",
      "1.0064077433898644 new standard\n",
      "0.10341085018850676 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "869\n",
      "1.038314158704773 new standard\n",
      "0.16534576769753578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "922\n",
      "1.0152894682968883 new standard\n",
      "0.3334979991203962 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1112\n",
      "1.0178009479079477 new standard\n",
      "0.26893643233393577 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1003\n",
      "0.8703731491962305 new standard\n",
      "0.20407359021856836 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "888\n",
      "0.9106995919915682 new standard\n",
      "0.19993974238600679 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "908\n",
      "0.9725602489630392 new standard\n",
      "-0.18151908862493696 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "0.9869565496881305 new standard\n",
      "-0.08610327753629067 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "755\n",
      "0.9563146788782537 new standard\n",
      "0.08155762866336014 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "821\n",
      "1.0004528957422782 new standard\n",
      "0.19530459523424312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "967\n",
      "1.1241455827519282 new standard\n",
      "0.18997066651419794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "990\n",
      "1.0676072273060289 new standard\n",
      "0.3984144196367255 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1246\n",
      "0.8954237248673742 new standard\n",
      "-0.13451775575964886 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "617\n",
      "0.9135198584666142 new standard\n",
      "-0.07365273737182017 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "666\n",
      "1.0383885021218584 new standard\n",
      "-0.005760635022510202 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "841\n",
      "1.0602282140935755 new standard\n",
      "-0.046530152879152006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "748\n",
      "1.0080181954113612 new standard\n",
      "-0.0005703850064404914 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "793\n",
      "0.9824683855867954 new standard\n",
      "0.04627271044048573 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n",
      "1.046770149531313 new standard\n",
      "0.10758167377629714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "951\n",
      "1.118389549328012 new standard\n",
      "0.149557671539578 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1002\n",
      "1.0340414906534046 new standard\n",
      "0.03527327782492707 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "873\n",
      "1.0413953950071622 new standard\n",
      "0.09078374310677124 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "929\n",
      "0.9750575990361728 new standard\n",
      "-0.039568723055150974 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "758\n",
      "0.9984103678244771 new standard\n",
      "-0.08511153381181542 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "716\n",
      "1.036338812999806 new standard\n",
      "0.012157864846431839 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "805\n",
      "1.056406719722139 new standard\n",
      "-0.008122319818256419 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "825\n",
      "1.0306544908189375 new standard\n",
      "-0.06211550911195302 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "1.0214581329441443 new standard\n",
      "0.026497899136699286 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "855\n",
      "0.973129938183229 new standard\n",
      "0.18339826199893647 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.0475045661773412 new standard\n",
      "0.475429292151695 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1322\n",
      "0.9905606111506337 new standard\n",
      "-0.08534924882225106 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "735\n",
      "0.9972533652425827 new standard\n",
      "-0.193593295479362 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "608\n",
      "1.029597273199852 new standard\n",
      "-0.09893639103088699 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "705\n",
      "0.9803642220925743 new standard\n",
      "-0.08635734588531951 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "729\n",
      "1.0043466700727528 new standard\n",
      "-0.03089429258543383 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "739\n",
      "0.9613393720267627 new standard\n",
      "0.031298578947558414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "794\n",
      "0.9531806134851092 new standard\n",
      "-0.15794748718307253 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "651\n",
      "0.980061271122322 new standard\n",
      "-0.10930680145899184 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "695\n",
      "0.9890101315914421 new standard\n",
      "-0.01454645420785553 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "763\n",
      "1.1043438464144628 new standard\n",
      "0.16058998212552986 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "991\n",
      "1.072199655868836 new standard\n",
      "0.04857909908984349 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0097892149133616 new standard\n",
      "0.03369254228514735 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "808\n",
      "1.0095817662080082 new standard\n",
      "-0.0703547433759683 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "762\n",
      "1.042572521825957 new standard\n",
      "0.0872445063491945 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "914\n",
      "0.9819772183995533 new standard\n",
      "-0.020708534192729385 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "799\n",
      "0.9644553642357842 new standard\n",
      "0.030098172039000455 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "810\n",
      "1.017563156983918 new standard\n",
      "0.03245532056829923 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "834\n",
      "1.0262390654752107 new standard\n",
      "0.014323567710658961 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "830\n",
      "1.0671673166604163 new standard\n",
      "0.02512343607410581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "893\n",
      "1.1080619804308594 new standard\n",
      "0.08942355376556779 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "950\n",
      "1.0224227397036358 new standard\n",
      "0.06973873236178516 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "1.011455050833746 new standard\n",
      "0.1299679726242312 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "940\n",
      "1.073470439204209 new standard\n",
      "-0.06094334927039511 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "730\n",
      "0.9778995997609293 new standard\n",
      "0.003375920598037684 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "777\n",
      "0.9941562756486371 new standard\n",
      "-0.06910248610696036 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "760\n",
      "1.0125286655231245 new standard\n",
      "-0.06537930671924899 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "778\n",
      "0.9412600403636379 new standard\n",
      "-0.19387976930368225 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "647\n",
      "1.027328998586978 new standard\n",
      "-0.061882993997553794 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "779\n",
      "1.1349121130224322 new standard\n",
      "0.357975446945868 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1267\n",
      "1.0884816153353432 new standard\n",
      "0.3948557313861588 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1302\n",
      "0.9725105825265076 new standard\n",
      "0.01865444271031581 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "812\n",
      "1.0050045819691726 new standard\n",
      "0.13850669933485762 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "867\n",
      "1.059611865213206 new standard\n",
      "0.04323235859590714 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "883\n",
      "1.1143162446314068 new standard\n",
      "0.08645954262595802 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "941\n",
      "1.0207538019260982 new standard\n",
      "0.030011426467185662 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "838\n",
      "1.0223105736813476 new standard\n",
      "0.07286355972464603 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "872\n",
      "1.117852400521776 new standard\n",
      "0.19514093631665816 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "1116\n",
      "1.082470578908853 new standard\n",
      "0.05513388719356918 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "921\n",
      "0.928276263542243 new standard\n",
      "-0.2603300106871503 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "558\n",
      "0.9867134915361729 new standard\n",
      "-0.1005946439681006 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "696\n",
      "0.9058191550547513 new standard\n",
      "-0.3425840389637315 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "496\n",
      "0.9392742761258921 new standard\n",
      "-0.26328142463867205 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "556\n",
      "0.982706726974923 new standard\n",
      "-0.14283895106767214 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "654\n",
      "0.9638047913865534 new standard\n",
      "-0.07703334506603277 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "706\n",
      "0.9656774472504323 new standard\n",
      "-0.05471341928295052 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "721\n",
      "1.0064351835989889 new standard\n",
      "0.08096425208597095 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "0.9758408535515135 new standard\n",
      "0.11149326817336414 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "854\n",
      "1.0195171832106837 new standard\n",
      "0.1317096815745789 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "916\n",
      "0.9692943333784476 new standard\n",
      "-0.13969022646432744 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "669\n",
      "1.0437708317148353 new standard\n",
      "0.06512742407905442 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "859\n",
      "0.9992476328918001 new standard\n",
      "-0.14925670513132852 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "676\n",
      "1.0188731404124747 new standard\n",
      "-0.06905816410806866 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "759\n",
      "1.0434566855102587 new standard\n",
      "-0.10505411651403024 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "724\n",
      "1.0469580248653776 new standard\n",
      "-0.16026009957627677 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "663\n",
      "valid: 100 %      \n",
      "0.9614430417804307 new standard\n",
      "-0.11676266139218934 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "680\n",
      "1.0418046928193223 new standard\n",
      "-0.10092028914456828 new mean\n",
      "(90, 90) FEATS SHOULD BE HIGH\n",
      "692\n",
      "test: 100 %      \n",
      "180 unique ids\n",
      "180 Final count\n",
      "train SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "dev SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "test SPLIT\n",
      "True HAS TRAIN ONLY\n",
      "0 USES TRAIN ONLY\n",
      "[0, 1] SELF INDICES\n",
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '0', '1'] dta set indices\n",
      "what the hell\n",
      "94 2 86\n",
      "[('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACFC8>), ('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACE88>), ('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACF08>)]\n",
      "('test', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACFC8>) ss\n",
      "('train', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACE88>) ss\n",
      "('dev', <torch.utils.data.dataloader.DataLoader object at 0x0000025E9ACACF08>) ss\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\0_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\1_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\83_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\19_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\45_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\38_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\16_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\56_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\84_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\87_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\36_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\77_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\2_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\80_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\3_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\75_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\26_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\4_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\52_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\50_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\62_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\71_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\44_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\55_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\7_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\41_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\43_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\74_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\30_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\15_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\14_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\54_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\68_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\60_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\17_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\91_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\82_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\9_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\39_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\47_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\67_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\18_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\42_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\49_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\37_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\20_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\88_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\78_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\13_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\92_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\8_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\25_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\24_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\29_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\79_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\61_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\11_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\10_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\81_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\73_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\48_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\76_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\32_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\23_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\27_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\22_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\85_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\28_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\5_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\58_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\33_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\72_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\63_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\40_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\86_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\65_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\53_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\35_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\21_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\89_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\34_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\31_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\69_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\57_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\51_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\6_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\93_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\59_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\70_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\12_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\90_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\66_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\46_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\64_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\98_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\136_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\128_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\114_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\137_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\164_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\178_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\102_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\100_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\158_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\123_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\122_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\147_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\140_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\157_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\166_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\96_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\113_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\125_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\161_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\162_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\172_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\103_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\138_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\171_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\112_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\142_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\115_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\179_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\155_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\110_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\169_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\175_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\139_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\167_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\177_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\130_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\165_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\126_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\104_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\94_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\107_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\116_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\144_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\152_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\156_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\129_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\174_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\97_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\149_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\95_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\105_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\160_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\146_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\150_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\118_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\134_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\143_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\127_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\154_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\153_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\132_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\148_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\101_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\168_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\133_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\109_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\173_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\163_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\99_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\108_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\106_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\120_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\119_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\124_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\111_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\170_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\131_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\117_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\121_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\176_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\151_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\145_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\135_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\159_embeddings.csv SAVE EMBEDDINGS!\n",
      "torch.Size([91, 91]) SHAPE!!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\141_embeddings.csv SAVE EMBEDDINGS!\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\scan_info.csv\n",
      "NEXT LEVEL??\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8 ['C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\0', 'C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\1', 'C:\\\\Users\\\\coleb\\\\OneDrive\\\\Desktop\\\\Fall 2021\\\\Neuro\\\\hyperBrain\\\\study\\\\meg\\\\lp\\\\pats_CogTr1\\\\L3\\\\HGCN_full_findc_plv_dp\\\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\\\2']\n",
      "Parameter containing:\n",
      "tensor([1.2205]) layer of c 0\n",
      "0.5577076856617261 listed c\n",
      "Parameter containing:\n",
      "tensor([0.3773]) layer of c 1\n",
      "0.5577076856617261 listed c\n",
      "2.0 1.0 0.5577076856617261\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.5577076856617261 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n",
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\0\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.040698  1.699854  2.032733  1.831628  1.368461  1.937508   \n",
      "1             1  1.139934  1.748153  2.163836  2.102232  1.612611  2.013538   \n",
      "2             2  1.218442  1.574436  1.863240  1.804658  1.546573  1.825026   \n",
      "3             3  1.136294  1.520441  2.355491  1.938465  1.704526  2.050562   \n",
      "4             4  0.991812  1.608562  1.692677  1.793024  1.285761  1.716246   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.033898  1.863406  1.633290  1.741696  1.561662  1.637369   \n",
      "176         176  1.142565  1.967133  1.989223  1.770910  1.281174  1.859407   \n",
      "177         177  1.055147  1.974635  2.041919  1.769433  1.216218  1.884710   \n",
      "178         178  1.170384  1.658767  1.791603  1.829042  1.237865  1.877998   \n",
      "179         179  1.226609  1.415269  1.662928  1.726371  1.245547  1.757167   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.241384  1.995840  1.622187  ...        0.431109         0.334996   \n",
      "1    1.248741  2.101808  1.693724  ...        0.363691         0.296345   \n",
      "2    1.305946  1.771358  1.761872  ...        0.424073         0.347976   \n",
      "3    1.154386  2.090906  1.599313  ...        0.373070         0.304061   \n",
      "4    1.110407  1.684298  1.539363  ...        0.467669         0.375789   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.968169  1.441188  1.319473  ...        0.501929         0.416176   \n",
      "176  1.436045  2.022799  1.725409  ...        0.460872         0.340405   \n",
      "177  1.388983  1.784555  1.608967  ...        0.451430         0.339468   \n",
      "178  1.327610  1.735258  1.750589  ...        0.423769         0.337389   \n",
      "179  1.333439  1.642342  1.870821  ...        0.440066         0.365172   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.403550         0.350342        0.352381       0.430940   \n",
      "1          0.345019         0.292394        0.305362       0.384976   \n",
      "2          0.400156         0.383306        0.384164       0.454135   \n",
      "3          0.399628         0.327723        0.311648       0.449622   \n",
      "4          0.426468         0.400867        0.418179       0.466099   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.467435         0.453729        0.429876       0.481677   \n",
      "176        0.372814         0.364002        0.383951       0.398671   \n",
      "177        0.388747         0.396815        0.379774       0.429406   \n",
      "178        0.389751         0.405340        0.386610       0.468523   \n",
      "179        0.397715         0.439323        0.427922       0.501379   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.301700        0.463764         0.340849        0.430156  \n",
      "1          0.234596        0.446763         0.326619        0.418688  \n",
      "2          0.333127        0.496061         0.340781        0.373206  \n",
      "3          0.245744        0.458217         0.276361        0.320944  \n",
      "4          0.389495        0.514700         0.412658        0.515954  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.433972        0.538617         0.454139        0.516828  \n",
      "176        0.326952        0.478784         0.319184        0.332476  \n",
      "177        0.370029        0.495512         0.365699        0.414875  \n",
      "178        0.375024        0.492350         0.388138        0.449412  \n",
      "179        0.386047        0.502801         0.389734        0.402423  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n",
      "passed manual model_dir\n",
      "Parameter containing:\n",
      "tensor([1.2205]) layer of c 0\n",
      "0.5577076856617261 listed c\n",
      "Parameter containing:\n",
      "tensor([0.3773]) layer of c 1\n",
      "0.5577076856617261 listed c\n",
      "2.0 1.0 0.5577076856617261\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.5577076856617261 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\1\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.040698  1.699854  2.032733  1.831628  1.368461  1.937508   \n",
      "1             1  1.139934  1.748153  2.163836  2.102232  1.612611  2.013538   \n",
      "2             2  1.218442  1.574436  1.863240  1.804658  1.546573  1.825026   \n",
      "3             3  1.136294  1.520441  2.355491  1.938465  1.704526  2.050562   \n",
      "4             4  0.991812  1.608562  1.692677  1.793024  1.285761  1.716246   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.033898  1.863406  1.633290  1.741696  1.561662  1.637369   \n",
      "176         176  1.142565  1.967133  1.989223  1.770910  1.281174  1.859407   \n",
      "177         177  1.055147  1.974635  2.041919  1.769433  1.216218  1.884710   \n",
      "178         178  1.170384  1.658767  1.791603  1.829042  1.237865  1.877998   \n",
      "179         179  1.226609  1.415269  1.662928  1.726371  1.245547  1.757167   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.241384  1.995840  1.622187  ...        0.431109         0.334996   \n",
      "1    1.248741  2.101808  1.693724  ...        0.363691         0.296345   \n",
      "2    1.305946  1.771358  1.761872  ...        0.424073         0.347976   \n",
      "3    1.154386  2.090906  1.599313  ...        0.373070         0.304061   \n",
      "4    1.110407  1.684298  1.539363  ...        0.467669         0.375789   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.968169  1.441188  1.319473  ...        0.501929         0.416176   \n",
      "176  1.436045  2.022799  1.725409  ...        0.460872         0.340405   \n",
      "177  1.388983  1.784555  1.608967  ...        0.451430         0.339468   \n",
      "178  1.327610  1.735258  1.750589  ...        0.423769         0.337389   \n",
      "179  1.333439  1.642342  1.870821  ...        0.440066         0.365172   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.403550         0.350342        0.352381       0.430940   \n",
      "1          0.345019         0.292394        0.305362       0.384976   \n",
      "2          0.400156         0.383306        0.384164       0.454135   \n",
      "3          0.399628         0.327723        0.311648       0.449622   \n",
      "4          0.426468         0.400867        0.418179       0.466099   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.467435         0.453729        0.429876       0.481677   \n",
      "176        0.372814         0.364002        0.383951       0.398671   \n",
      "177        0.388747         0.396815        0.379774       0.429406   \n",
      "178        0.389751         0.405340        0.386610       0.468523   \n",
      "179        0.397715         0.439323        0.427922       0.501379   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.301700        0.463764         0.340849        0.430156  \n",
      "1          0.234596        0.446763         0.326619        0.418688  \n",
      "2          0.333127        0.496061         0.340781        0.373206  \n",
      "3          0.245744        0.458217         0.276361        0.320944  \n",
      "4          0.389495        0.514700         0.412658        0.515954  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.433972        0.538617         0.454139        0.516828  \n",
      "176        0.326952        0.478784         0.319184        0.332476  \n",
      "177        0.370029        0.495512         0.365699        0.414875  \n",
      "178        0.375024        0.492350         0.388138        0.449412  \n",
      "179        0.386047        0.502801         0.389734        0.402423  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n",
      "passed manual model_dir\n",
      "Parameter containing:\n",
      "tensor([1.2205]) layer of c 0\n",
      "0.5577076856617261 listed c\n",
      "Parameter containing:\n",
      "tensor([0.3773]) layer of c 1\n",
      "0.5577076856617261 listed c\n",
      "2.0 1.0 0.5577076856617261\n",
      "r t c\n",
      "alpha BANDS\n",
      "0 ID please?\n",
      "1 PLV\n",
      "0 graph norm?\n",
      "{'train': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 0, 1], 'valid': [94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], 'test': [0, 1], 'all': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]} ARGUMENT\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179} All scans?\n",
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\embedding_stats_Functional Net_PCTt0.29.csv out dir\n",
      "0.5577076856617261 C\n",
      "2.0 R\n",
      "1.0 T\n",
      "making bin rank thresh -1 bc not using binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDMN Bin    10\n",
      "aDMN Bin     6\n",
      "DAN Bin      6\n",
      "FPN Bin     12\n",
      "VN Bin      12\n",
      "VAN Bin     14\n",
      "SN Bin      12\n",
      "SMN Bin      4\n",
      "dtype: int64 eyyy\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\0_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\hyperbolic_learning_master\\utils\\utils.py:140: RuntimeWarning: invalid value encountered in arccosh\n",
      "  dist = np.arccosh(-1*hyperboloid_dot(u, v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\1_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\2_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\3_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\4_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\5_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\6_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\7_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\8_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\9_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\10_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\11_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\12_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\13_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\14_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\15_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\16_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\17_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\18_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\19_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\20_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\21_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\22_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\23_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\24_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\25_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\26_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\27_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\28_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\29_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\30_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\31_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\32_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\33_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\34_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\35_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\36_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\37_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\38_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\39_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\40_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\41_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\42_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\43_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\44_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\45_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\46_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\47_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\48_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\49_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\50_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\51_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\52_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\53_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\54_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\55_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\56_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\57_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\58_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\59_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\60_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\61_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\62_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\63_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\64_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\65_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\66_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\67_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\68_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\69_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\70_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\71_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\72_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\73_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\74_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\75_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\76_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\77_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\78_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\79_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\80_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\81_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\82_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\83_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\84_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\85_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\86_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\87_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\88_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\89_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\90_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\91_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\92_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\93_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\94_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\95_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\96_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\97_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\98_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\99_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\100_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\101_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\102_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\103_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\104_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\105_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\106_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\107_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\108_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\109_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\110_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\111_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\112_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\113_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\114_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\115_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\116_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\117_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\118_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\119_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\120_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\121_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\122_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\123_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\124_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\125_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\126_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\127_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\128_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\129_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\130_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\131_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\132_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\133_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\134_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\135_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\136_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\137_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\138_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\139_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\140_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\141_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\142_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\143_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\144_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\145_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\146_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\147_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\148_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\149_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\150_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\151_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\152_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\153_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\154_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\155_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\156_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\157_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\158_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\159_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\160_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\161_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\162_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\163_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\164_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\165_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\166_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\167_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\168_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\169_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\170_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\171_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\172_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\173_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\174_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\175_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\176_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\177_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\178_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "Reading Embedding: C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\pats_CogTr1\\L3\\HGCN_full_findc_plv_dp\\e80_p6_lr0.021_val_excl_group_strchinp95_strchloss95_b8\\2\\embeddings\\179_embeddings.csv\n",
      "3 NATURAL DIM\n",
      "0.5577076856617261 CCCCCCCC\n",
      "[2 8 5 3 6 7 1 0 4]\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBNET LABELS\n",
      "Functional Net LABEL\n",
      "(54, 3) EMBEDDING SHAPE\n",
      "['pDMN Pct', 'aDMN Pct', 'DAN Pct', 'FPN Pct', 'VN Pct', 'VAN Pct', 'SN Pct', 'SMN Pct'] subnet pct\n",
      "(54, 35) EMB SHAPE\n",
      "{0: 'pDMN', 1: 'aDMN', 2: 'DAN', 3: 'FPN', 4: 'VN', 5: 'VAN', 6: 'SN', 7: 'SMN'} SUBMEEEEEEEEEEEt\n",
      "FEATES\n",
      "still using binary weight, even though pcts used to make inclusion\n",
      "['pDMN', 'aDMN', 'DAN', 'FPN', 'VN', 'VAN', 'SN', 'SMN'] ABESL\n",
      "(180, 1) (180, 8)\n",
      "     Scan Index  pDMN_Rad  aDMN_Rad   DAN_Rad   FPN_Rad    VN_Rad   VAN_Rad  \\\n",
      "0             0  1.040698  1.699854  2.032733  1.831628  1.368461  1.937508   \n",
      "1             1  1.139934  1.748153  2.163836  2.102232  1.612611  2.013538   \n",
      "2             2  1.218442  1.574436  1.863240  1.804658  1.546573  1.825026   \n",
      "3             3  1.136294  1.520441  2.355491  1.938465  1.704526  2.050562   \n",
      "4             4  0.991812  1.608562  1.692677  1.793024  1.285761  1.716246   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "175         175  1.033898  1.863406  1.633290  1.741696  1.561662  1.637369   \n",
      "176         176  1.142565  1.967133  1.989223  1.770910  1.281174  1.859407   \n",
      "177         177  1.055147  1.974635  2.041919  1.769433  1.216218  1.884710   \n",
      "178         178  1.170384  1.658767  1.791603  1.829042  1.237865  1.877998   \n",
      "179         179  1.226609  1.415269  1.662928  1.726371  1.245547  1.757167   \n",
      "\n",
      "       SN_Rad   SMN_Rad  pDMN_Coh  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0    1.241384  1.995840  1.622187  ...        0.431109         0.334996   \n",
      "1    1.248741  2.101808  1.693724  ...        0.363691         0.296345   \n",
      "2    1.305946  1.771358  1.761872  ...        0.424073         0.347976   \n",
      "3    1.154386  2.090906  1.599313  ...        0.373070         0.304061   \n",
      "4    1.110407  1.684298  1.539363  ...        0.467669         0.375789   \n",
      "..        ...       ...       ...  ...             ...              ...   \n",
      "175  0.968169  1.441188  1.319473  ...        0.501929         0.416176   \n",
      "176  1.436045  2.022799  1.725409  ...        0.460872         0.340405   \n",
      "177  1.388983  1.784555  1.608967  ...        0.451430         0.339468   \n",
      "178  1.327610  1.735258  1.750589  ...        0.423769         0.337389   \n",
      "179  1.333439  1.642342  1.870821  ...        0.440066         0.365172   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0          0.403550         0.350342        0.352381       0.430940   \n",
      "1          0.345019         0.292394        0.305362       0.384976   \n",
      "2          0.400156         0.383306        0.384164       0.454135   \n",
      "3          0.399628         0.327723        0.311648       0.449622   \n",
      "4          0.426468         0.400867        0.418179       0.466099   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.467435         0.453729        0.429876       0.481677   \n",
      "176        0.372814         0.364002        0.383951       0.398671   \n",
      "177        0.388747         0.396815        0.379774       0.429406   \n",
      "178        0.389751         0.405340        0.386610       0.468523   \n",
      "179        0.397715         0.439323        0.427922       0.501379   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0          0.301700        0.463764         0.340849        0.430156  \n",
      "1          0.234596        0.446763         0.326619        0.418688  \n",
      "2          0.333127        0.496061         0.340781        0.373206  \n",
      "3          0.245744        0.458217         0.276361        0.320944  \n",
      "4          0.389495        0.514700         0.412658        0.515954  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.433972        0.538617         0.454139        0.516828  \n",
      "176        0.326952        0.478784         0.319184        0.332476  \n",
      "177        0.370029        0.495512         0.365699        0.414875  \n",
      "178        0.375024        0.492350         0.388138        0.449412  \n",
      "179        0.386047        0.502801         0.389734        0.402423  \n",
      "\n",
      "[180 rows x 89 columns]\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  post_sem_fluency_name  \\\n",
      "0                 49.0          22.0  ...                   24.0   \n",
      "1                 49.0          22.0  ...                   24.0   \n",
      "2                  NaN           NaN  ...                   21.0   \n",
      "3                  NaN           NaN  ...                   21.0   \n",
      "4                115.0          21.0  ...                   15.0   \n",
      "..                 ...           ...  ...                    ...   \n",
      "175               45.0          22.0  ...                   19.0   \n",
      "176               74.0          21.0  ...                   28.0   \n",
      "177               74.0          21.0  ...                   28.0   \n",
      "178               50.0          22.0  ...                   24.0   \n",
      "179               50.0          22.0  ...                   24.0   \n",
      "\n",
      "     post_TMT_A_hits  post_TMT_A_time  post_TMT_B_hits  post_TMT_B_time  \\\n",
      "0               24.0             44.0             24.0             77.0   \n",
      "1               24.0             44.0             24.0             77.0   \n",
      "2               24.0             43.0             20.0             89.0   \n",
      "3               24.0             43.0             20.0             89.0   \n",
      "4               24.0             55.0             24.0             97.0   \n",
      "..               ...              ...              ...              ...   \n",
      "175             24.0             41.0             24.0             89.0   \n",
      "176             24.0             54.0             24.0             88.0   \n",
      "177             24.0             54.0             24.0             88.0   \n",
      "178             24.0             53.0             24.0             69.0   \n",
      "179             24.0             53.0             24.0             69.0   \n",
      "\n",
      "     post_RBMT_profile  post_RBMT_global  age  sex  APOE  \n",
      "0                 22.0              11.0   70    1  33.0  \n",
      "1                 22.0              11.0   70    1  33.0  \n",
      "2                 24.0              12.0   72    1  33.0  \n",
      "3                 24.0              12.0   72    1  33.0  \n",
      "4                  NaN              10.0   78    2  34.0  \n",
      "..                 ...               ...  ...  ...   ...  \n",
      "175               24.0              12.0   67    1  33.0  \n",
      "176               23.0              11.0   65    2  33.0  \n",
      "177               23.0              11.0   65    2  33.0  \n",
      "178               24.0              12.0   69    2  33.0  \n",
      "179               24.0              12.0   69    2  33.0  \n",
      "\n",
      "[180 rows x 64 columns]\n",
      "tensor([0.3773]) AVERAGE C\n",
      "out stat dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 153) og shape\n",
      "(180, 153) DF SHAPE\n",
      "(180, 153) DF SHAPE\n",
      "(180, 153) DF SHAPE\n",
      "(180, 90) conccat\n",
      "(180, 90) SHAPE\n",
      "     Pre  Scan Index        ID  CogTr  diagnosis  pre_MMSE  pre_7MS  pre_BNT  \\\n",
      "0      1           0  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "1      0           1  UMEC-002      1          1      30.0     89.0     60.0   \n",
      "2      1           2  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "3      0           3  UMEC-020      1          1      30.0     79.0      NaN   \n",
      "4      1           4  UMEC-022      1          1      29.0     62.0     49.0   \n",
      "..   ...         ...       ...    ...        ...       ...      ...      ...   \n",
      "175    0         175  UMEC-213      2          2      29.0     73.0     57.0   \n",
      "176    1         176  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "177    0         177  UMEC-214      2          2      30.0     89.0     54.0   \n",
      "178    1         178  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "179    0         179  UMEC-216      2          2      30.0     74.0     56.0   \n",
      "\n",
      "     pre_RSF_copy_time  pre_RSF_copy  ...  FPN_VN_Btwprob  FPN_VAN_Btwprob  \\\n",
      "0                 49.0          22.0  ...        0.431109         0.334996   \n",
      "1                 49.0          22.0  ...        0.363691         0.296345   \n",
      "2                  NaN           NaN  ...        0.424073         0.347976   \n",
      "3                  NaN           NaN  ...         0.37307         0.304061   \n",
      "4                115.0          21.0  ...        0.467669         0.375789   \n",
      "..                 ...           ...  ...             ...              ...   \n",
      "175               45.0          22.0  ...        0.501929         0.416176   \n",
      "176               74.0          21.0  ...        0.460872         0.340405   \n",
      "177               74.0          21.0  ...         0.45143         0.339468   \n",
      "178               50.0          22.0  ...        0.423769         0.337389   \n",
      "179               50.0          22.0  ...        0.440066         0.365172   \n",
      "\n",
      "     FPN_SN_Btwprob  FPN_SMN_Btwprob  VN_VAN_Btwprob  VN_SN_Btwprob  \\\n",
      "0           0.40355         0.350342        0.352381        0.43094   \n",
      "1          0.345019         0.292394        0.305362       0.384976   \n",
      "2          0.400156         0.383306        0.384164       0.454135   \n",
      "3          0.399628         0.327723        0.311648       0.449622   \n",
      "4          0.426468         0.400867        0.418179       0.466099   \n",
      "..              ...              ...             ...            ...   \n",
      "175        0.467435         0.453729        0.429876       0.481677   \n",
      "176        0.372814         0.364002        0.383951       0.398671   \n",
      "177        0.388747         0.396815        0.379774       0.429406   \n",
      "178        0.389751          0.40534         0.38661       0.468523   \n",
      "179        0.397715         0.439323        0.427922       0.501379   \n",
      "\n",
      "     VN_SMN_Btwprob  VAN_SN_Btwprob  VAN_SMN_Btwprob  SN_SMN_Btwprob  \n",
      "0            0.3017        0.463764         0.340849        0.430156  \n",
      "1          0.234596        0.446763         0.326619        0.418688  \n",
      "2          0.333127        0.496061         0.340781        0.373206  \n",
      "3          0.245744        0.458217         0.276361        0.320944  \n",
      "4          0.389495          0.5147         0.412658        0.515954  \n",
      "..              ...             ...              ...             ...  \n",
      "175        0.433972        0.538617         0.454139        0.516828  \n",
      "176        0.326952        0.478784         0.319184        0.332476  \n",
      "177        0.370029        0.495512         0.365699        0.414875  \n",
      "178        0.375024         0.49235         0.388138        0.449412  \n",
      "179        0.386047        0.502801         0.389734        0.402423  \n",
      "\n",
      "[180 rows x 154 columns] avg stat df\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n",
      "NEXT LEVEL??\n",
      "No successful embeddings\n",
      "NEXT LEVEL??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coleb\\anaconda3\\envs\\hgnn\\lib\\site-packages\\pandas\\core\\frame.py:9138: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Scan Index_'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "# the total number of validation runs that all should have\n",
    "NUM_VALIDATIONS=3\n",
    "criteria={'CogTr':1}\n",
    "# criteria={}\n",
    "set_args={'dataset':'meg',\n",
    "          'task':'lp',\n",
    "          'criteria_dict':criteria,'epochs':80}\n",
    "\n",
    "criteria=criteria\n",
    "output_dims=[3]\n",
    "arch_types_to_use=['full']\n",
    "input_types_to_use=['plv']\n",
    "curve_types_to_use=['setc','findc']\n",
    "# raise Exception('OBVIOUSLY WE SHOULD ADD \"CRITERIA INTO the folder name... dont want to mix those')\n",
    "for d in output_dims:\n",
    "    for i in input_types_to_use:\n",
    "        inp_dict=input_types[i]\n",
    "        for c_type in curve_types_to_use:\n",
    "#             print(c,'C')\n",
    "#             print(c_dict,'C DICT?')\n",
    "\n",
    "            c_dict=curve_types[c_type]\n",
    "#             print(c_dict,'')\n",
    "            c_val=c_dict['c']\n",
    "            print(c_val,'C VAL')\n",
    "            if c_val=='set':\n",
    "                c_set=BAND_TO_OPT_C['alpha']\n",
    "                c_dict['c']=c_set\n",
    "                \n",
    "            set_args = copy.deepcopy(set_args)\n",
    "            set_args['output_dim']=d\n",
    "            set_args.update(c_dict)\n",
    "            set_args.update(inp_dict)\n",
    "            args = parse_default_args(set_args)\n",
    "#             print(set_args['c'],set_args['use_identity'],set_args['use_plv'])\n",
    "            print('compase')\n",
    "            print('C: {}, ID: {}, PLV {}'.format(set_args['c'],set_args['use_identity'],set_args['use_plv']))\n",
    "            print('C: {}, ID: {}, PLV {}'.format(args.c,args.use_identity,args.use_plv))\n",
    "#             aka\n",
    "            complete_study_one_arg(args,NUM_VALIDATIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root_ds= r'C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\ds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514f4191",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_60728\\1542315227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "# complete_study_one_arg({},NUM_VALIDATIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bdbd527",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18836\\1275920457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdirs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NEXT LEVEL??'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     print(root,dirs,files)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdirs\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for (root,dirs,files) in os.walk(root_ds, topdown=True):\n",
    "    print('NEXT LEVEL??')\n",
    "#     print(root,dirs,files)\n",
    "    if not dirs :\n",
    "        continue\n",
    "    embedding_roots=[]\n",
    "#     full_dirs=p\n",
    "#         os.path.join(s,r) for r in os.listdir(s) if '.csv' not in r  and ('.json' not in r) ]\n",
    "    for d in dirs:\n",
    "        full_dir=os.path.join(root,d)\n",
    "        subfiles=os.listdir(full_dir)\n",
    "        if ('finish_train.txt' in subfiles) or ('model.pth' in subfiles):\n",
    "            embedding_roots.append(full_dir)\n",
    "    if embedding_roots:\n",
    "        print(root,embedding_roots)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ds= r'C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\ds\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ds=r'C:\\Users\\coleb\\OneDrive\\Desktop\\Fall 2021\\Neuro\\hyperBrain\\study\\meg\\lp\\all_pats\\L3\\HGCN_full_0.54c_plv_dp\\e100_p10_lr0.021_vpct0.3_tpct0.2_stretch98_b8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ed80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_res_df_study(root_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
